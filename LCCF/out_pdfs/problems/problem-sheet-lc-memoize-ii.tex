% !TeX program = xelatex
\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{microtype}
\usepackage{setspace}\setstretch{1.05}
\usepackage{fontspec}
\setmainfont{Latin Modern Roman}
\setmonofont{Latin Modern Mono}[BoldFont={Latin Modern Mono},ItalicFont={Latin Modern Mono}]
\usepackage{amsmath,mathtools,amsthm}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\usepackage{unicode-math}\setmathfont{Latin Modern Math}\allowdisplaybreaks[4]
% --- overflow and alignment slack ---
\setlength{\jot}{7pt}
\sloppy\emergencystretch=8em\hfuzz=1pt\vfuzz=2pt\raggedbottom
% --- breakable math helpers ---
\newenvironment{BreakableEquation}{\begin{equation}\begin{aligned}}{\end{aligned}\end{equation}}
\newenvironment{BreakableEquation*}{\begin{equation*}\begin{aligned}}{\end{aligned}\end{equation*}}
\newenvironment{tightalign}{\begingroup\small\allowdisplaybreaks\begin{align}}{\end{align}\endgroup}

\usepackage{xcolor}
\usepackage{xurl} % better URL wrapping
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue]{hyperref}
\usepackage{fancyhdr}
\pagestyle{fancy}\fancyhf{}\lhead{\nouppercase{\leftmark}}\rhead{\thepage}\setlength{\headheight}{26pt}
\usepackage{enumitem,booktabs,tabularx}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\renewcommand{\arraystretch}{1.1}
\setlength{\parindent}{0pt}\setlength{\parskip}{8pt plus 2pt minus 1pt}

% Listings + upquote (no shell-escape needed)
\usepackage{listings}
\usepackage{upquote}
\lstdefinestyle{crisp}{
  basicstyle=\ttfamily\footnotesize,
  frame=single,
  breaklines=true,
  breakatwhitespace=false, % allow breaks inside long tokens
  tabsize=4,
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny,
  numbersep=8pt,
  keepspaces=true,
  columns=fullflexible,
  backgroundcolor=\color{black!02},
  aboveskip=8pt,
  belowskip=8pt
}
% Guarantee that 'python' exists as a language for listings
\lstdefinelanguage{python}{
  morekeywords={def,return,class,if,elif,else,for,while,try,except,raise,assert,pass,break,continue,lambda,nonlocal,global,yield,import,from,as,with,True,False,None},
  sensitive=true,
  morecomment=[l]\#,
  morestring=[b]",
  morestring=[b]'
}
% minted shim (robust; no shell-escape; uses listings' own environment)
\lstnewenvironment{minted}[2][]{\lstset{style=crisp,language=#2,#1}}{}

\usepackage[most]{tcolorbox}
\tcbset{colback=white,colframe=black!15,boxrule=0.4pt,arc=2pt,left=6pt,right=6pt,top=6pt,bottom=6pt,before skip=10pt,after skip=10pt,breakable}
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection}{0.6em}{}
\titlespacing*{\section}{0pt}{*2.0}{*1.0}

% ===== CONSISTENCY TOOLKIT (macros) =====
\newlist{ledger}{enumerate}{1}
\setlist[ledger]{label=\textbullet,leftmargin=2em,itemsep=2pt,topsep=6pt}
\newcommand{\LEDGER}[1]{\textbf{ARITHMETIC LEDGER:}\par\begin{ledger}#1\end{ledger}}

\newlist{algosteps}{enumerate}{1}
\setlist[algosteps]{label=\arabic*.,leftmargin=2em,itemsep=2pt,topsep=6pt}

\newlist{bullets}{itemize}{1}
\setlist[bullets]{label=--,leftmargin=1.6em,itemsep=2pt,topsep=4pt}

\newcommand{\varmapStart}{\textbf{VARIABLE MAPPING:}\par\begin{bullets}}
\newcommand{\var}[2]{\item $#1$ — #2}
\newcommand{\varmapEnd}{\end{bullets}}

\newcommand{\LINE}[2]{\par\noindent\textbf{#1:}~#2\par}
\newcommand{\WHAT}[1]{\LINE{WHAT}{#1}}
\newcommand{\WHY}[1]{\LINE{WHY}{#1}}
\newcommand{\HOW}[1]{\LINE{HOW}{#1}}
\newcommand{\ELI}[1]{\LINE{ELI5}{#1}}
\newcommand{\STATEMENT}[1]{\LINE{STATEMENT}{#1}}
\newcommand{\BREAKDOWN}[1]{\LINE{PROBLEM BREAKDOWN}{#1}}
\newcommand{\MODEL}[1]{\LINE{CANONICAL MATHEMATICAL MODEL}{#1}}
\newcommand{\ASSUMPTIONS}[1]{\LINE{ASSUMPTIONS}{#1}}
\newcommand{\INVARIANTS}[1]{\LINE{INVARIANTS}{#1}}
\newcommand{\WHICHFORMULA}[1]{\LINE{WHICH FORMULA \& WHY}{#1}}
\newcommand{\GOVERN}[1]{\LINE{GOVERNING EQUATION(S)}{#1}}
\newcommand{\INPUTS}[1]{\LINE{INPUTS}{#1}}
\newcommand{\OUTPUTS}[1]{\LINE{OUTPUTS}{#1}}
\newcommand{\SAMPLES}[1]{\LINE{SAMPLES}{#1}}
\newcommand{\RESULT}[1]{\LINE{RESULT}{#1}}
\newcommand{\COMPLEXITY}[1]{\LINE{TIME/SPACE COMPLEXITY}{#1}}
\newcommand{\MEMORY}[1]{\LINE{MEMORY FOOTPRINT}{#1}}
\newcommand{\CORRECTNESS}[1]{\LINE{CORRECTNESS SKETCH}{#1}}
\newcommand{\OPTIMALITY}[1]{\LINE{OPTIMALITY}{#1}}
\newcommand{\FAILMODES}[1]{\LINE{FAILURE MODES}{#1}}
\newcommand{\VALIDATION}[1]{\LINE{VALIDATION}{#1}}
\newcommand{\UNITCHECK}[1]{\LINE{UNIT CHECK}{#1}}
\newcommand{\EDGECASES}[1]{\LINE{EDGE CASES}{#1}}
\newcommand{\CHECKLIST}[1]{\LINE{CHECKLIST}{#1}}
\newcommand{\DERIV}[1]{\LINE{DERIVATION}{#1}}
\newcommand{\LEMMAHEAD}[1]{\LINE{SUPPORTING LEMMA}{#1}}
\newcommand{\PITFALLS}[1]{\LINE{PITFALLS}{#1}}

\usepackage{etoolbox}\pretocmd{\section}{\clearpage}{}{}

\newcommand{\FormulaPage}[2]{%
  \clearpage
  \section*{Formula #1 — #2}%
  \addcontentsline{toc}{section}{Formula #1 — #2}%
}
\newcommand{\ApproachPage}[2]{%
  \clearpage
  \subsection*{Approach #1 — #2}%
  \addcontentsline{toc}{subsection}{Approach #1 — #2}%
}

\begin{document}
\title{Interview Problem Sheet — Memoize II}
\date{\today}
\author{}
\maketitle
\tableofcontents
\clearpage

% === Notes macro (BODY-ONLY; do not alter the preamble) ===
% Prints exactly N blank pages with empty headers/footers, then leaves you on the last blank page.
\newcommand{\NotePages}[1]{%
  \clearpage
  \begingroup
  \newcount\NPi \newcount\NPn
  \NPi=0 \NPn=#1
  \loop\ifnum\NPi<\NPn
    \advance\NPi by 1
    \mbox{}\thispagestyle{empty}%
    \ifnum\NPi<\NPn\clearpage\fi
  \repeat
  \endgroup
}

% ============ 1. Problem & Metadata (own page) ============
\section{Problem \& Metadata}
\LINE{PLATFORM}{LC}
\LINE{URL}{\url{https://leetcode.com/problems/memoize-ii/}}
\LINE{DIFFICULTY / RATING}{hard}
\STATEMENT{Given a function \texttt{fn}, return a \textbf{memoized} version of that function.

A \textbf{memoized} function is a function that will never be called twice with the same inputs. Instead it will return a cached value. \texttt{fn} can be any function and there are no constraints on what type of values it accepts. Inputs are considered identical if they are \texttt{===} to each other.

\textbf{Example 1:}

\texttt{Input:}

\texttt{getInputs = () => [[2,2],[2,2],[1,2]]}

\texttt{fn = function (a, b) \{ return a + b; \}}

\texttt{Output: [\{"val":4,"calls":1\},\{"val":4,"calls":1\},\{"val":3,"calls":2\}]}

\texttt{Explanation:}

\texttt{const inputs = getInputs();}

\texttt{const memoized = memoize(fn);}

\texttt{for (const arr of inputs) \{}

\quad\texttt{memoized(...arr);}

\texttt{\}}

For the inputs of \texttt{(2, 2)}: \texttt{2 + 2 = 4}, and it required a call to \texttt{fn()}. For the inputs of \texttt{(2, 2)}: \texttt{2 + 2 = 4}, but those inputs were seen before so no call to \texttt{fn()} was required. For the inputs of \texttt{(1, 2)}: \texttt{1 + 2 = 3}, and it required another call to \texttt{fn()} for a total of \texttt{2}.

\textbf{Example 2:}

\texttt{Input:}

\texttt{getInputs = () => [[\{\},\{\}],[\{\},\{\}],[\{\},\{\}]]}

\texttt{fn = function (a, b) \{ return (\{...\!a, ...\!b\}); \}}

\texttt{Output: [\{"val":\{\},"calls":1\},\{"val":\{\},"calls":2\},\{"val":\{\},"calls":3\}]}

\texttt{Explanation:}

Merging two empty objects will always result in an empty object. It may seem like there should only be \texttt{1} call to \texttt{fn()} because of cache-hits, however none of those objects are \texttt{===} to each other.

\textbf{Example 3:}

\texttt{Input:}

\texttt{getInputs = () => \{ const o = \{\}; return [[o,o],[o,o],[o,o]]; \}}

\texttt{fn = function (a, b) \{ return (\{...\!a, ...\!b\}); \}}

\texttt{Output: [\{"val":\{\},"calls":1\},\{"val":\{\},"calls":1\},\{"val":\{\},"calls":1\}]}

\texttt{Explanation:}

Merging two empty objects will always result in an empty object. The 2nd and 3rd function calls result in a cache-hit. This is because every object passed in is identical.

\textbf{Constraints:}
\begin{bullets}
\item $1 \le \text{inputs.length} \le 10^5$
\item $0 \le \text{inputs.flat().length} \le 10^5$
\item $\text{inputs}[i][j] \ne \text{NaN}$
\end{bullets}
}
\BREAKDOWN{Implement \texttt{memoize(fn)} that returns a wrapper caching results keyed by argument tuples where the equality is JS \texttt{===}: primitives compared by value and objects compared by reference identity. Ensure no duplicate calls for identical inputs.}
\ELI{Cache the function output for a specific set of inputs, where numbers/strings compare by value and objects compare by identity; return the cached result next time.}
\NotePages{3}

% ============ 2. IO Contract (own page) ============
\section{IO Contract}
\INPUTS{A function \texttt{fn}. When the returned memoized function is invoked with arguments \texttt{(...args)}, two argument lists are considered the same if and only if for every position:
\begin{bullets}
\item both are primitives with equal value and equal type (e.g., \texttt{1} vs \texttt{1}, \texttt{"a"} vs \texttt{"a"}, \texttt{true} vs \texttt{true}); and
\item or both are objects and are the exact same reference (identical). 
\end{bullets}
In this sheet, we provide a Python implementation that mirrors the JS \texttt{===} rules: numbers, strings, booleans, bytes, and \texttt{None} compare by value with type tag; other objects compare by identity using \texttt{id()}.}
\OUTPUTS{A function \texttt{memoized} that returns \texttt{fn(...args)} while avoiding recomputation for identical inputs. For demonstration, we expose \texttt{memoized.calls} as the number of underlying \texttt{fn} invocations performed so far.}
\SAMPLES{
Example A (primitives):
\begin{bullets}
\item Inputs: \texttt{[(2,2),(2,2),(1,2)]}; \texttt{fn(a,b)=a+b}
\item Outputs: \texttt{[\{"val":4,"calls":1\},\{"val":4,"calls":1\},\{"val":3,"calls":2\}]}
\end{bullets}
Example B (objects by identity):
\begin{bullets}
\item Inputs: three times \texttt{[\{\},\{\}]}, each \texttt{\{\}} a new object
\item Calls increase as \texttt{1,2,3} because distinct objects are not identical.
\end{bullets}
}
\NotePages{3}

% ============ 3. Canonical Mathematical Model (own page) ============
\section{Canonical Mathematical Model}
\MODEL{Let $\mathcal{A}$ be the set of finite argument tuples. Define an equivalence predicate $E((a_1,\ldots,a_k),(b_1,\ldots,b_k))$ that holds iff $k$ matches and for each $i$:
\begin{bullets}
\item if $a_i$ and $b_i$ are primitives, then $\text{type}(a_i)=\text{type}(b_i)$ and $a_i=b_i$;
\item else $a_i$ and $b_i$ are object references and $a_i$ and $b_i$ are the same identity.
\end{bullets}
We maintain a partial map (cache) $C$ from equivalence classes of $\mathcal{A}$ to return values.}
\varmapStart
\var{\mathcal{A}}{set of all finite argument tuples}
\var{E}{input-equivalence under JS \texttt{===} semantics}
\var{C}{cache mapping canonical keys to outputs}
\var{f}{the original function \texttt{fn}}
\var{g}{the memoized wrapper}
\varmapEnd
\GOVERN{
\[
\begin{aligned}
g(\vec{x}) &= 
\begin{cases}
C[\kappa(\vec{x})], & \text{if } \kappa(\vec{x}) \in \text{dom}(C),\\
C[\kappa(\vec{x})] \leftarrow f(\vec{x}), & \text{otherwise, then return it},
\end{cases}
\\
\kappa &: \mathcal{A} \to \text{Keys}, \quad \text{a canonical key builder consistent with } E.
\end{aligned}
\]
}
\ASSUMPTIONS{No input is NaN. For primitives, type tags are preserved to avoid collisions (e.g., \texttt{1} vs \texttt{True}). For floats, $-0$ and $+0$ are treated as equal, consistent with JS \texttt{===}.}
\INVARIANTS{
\begin{bullets}
\item Cache soundness: once $C[\kappa(\vec{x})]=v$, every later call with $E(\vec{x},\vec{y})$ returns $v$ without calling $f$.
\item Monotonicity: the domain of $C$ only grows; existing entries never change.
\item Call count: the number of underlying $f$ invocations equals $\lvert \text{dom}(C) \rvert$.
\end{bullets}
}
\NotePages{3}

% ============ 4. Approach A — Baseline (own page) ============
\section{Approach A — Baseline}
\ApproachPage{A}{Brute Force / Direct}
\WHICHFORMULA{Key by arguments directly if hashable; otherwise fall back to a string representation. This demonstrates basic memoization but may conflate distinct, structurally-equal objects.}
\ASSUMPTIONS{Inputs are often primitives or hashable; correctness on object identity is not guaranteed in this baseline due to \texttt{repr}-based fallback.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Build a key from \texttt{args} and sorted \texttt{kwargs} if hashable.
\item On \texttt{TypeError}, convert to a \texttt{repr}-based tuple key.
\item If key not present, compute and cache; else return cached value.
\end{algosteps}
\COMPLEXITY{For $k$ arguments, average-time keying is $O(k)$; lookup and insert are $O(1)$ expected in a hash map. Space is $O(M)$ for $M$ distinct keys.}
\[
\begin{aligned}
T_{\text{per call}}(k) &= O(k) + O(1) \\
S(M) &= O(M)
\end{aligned}
\]
\CORRECTNESS{Correct for primitives and hashables. May be incorrect under identity semantics for distinct but structurally-equal objects due to \texttt{repr} collisions.}
\EDGECASES{Unhashable objects; booleans vs integers; float $-0.0$ vs $0.0$; these are not robustly handled here.}
\textbf{Code (Baseline)}
\begin{minted}{python}
class Solution:
    def _safe_repr(self, x):
        try:
            return repr(x)
        except Exception:
            return f"<unrepr:{type(x).__name__}>"

    def memoize(self, fn):
        cache = {}

        def make_key(args, kwargs):
            # Try hashable tuple of args + sorted kwargs
            try:
                return ("H", args, tuple(sorted(kwargs.items())))
            except TypeError:
                # Fallback to repr-based key (NOT identity-safe for objects)
                return (
                    "R",
                    tuple(self._safe_repr(a) for a in args),
                    tuple(sorted((k, self._safe_repr(v)) for k, v in kwargs.items())),
                )

        def wrapper(*args, **kwargs):
            key = make_key(args, kwargs)
            if key in cache:
                return cache[key]
            wrapper.calls += 1
            out = fn(*args, **kwargs)
            cache[key] = out
            return out

        wrapper.calls = 0
        return wrapper


# --- Tests (Baseline) ---
def _test_baseline_numbers():
    sol = Solution()
    def add(a, b): return a + b
    memo = sol.memoize(add)
    inputs = [(2, 2), (2, 2), (1, 2)]
    out = []
    for a, b in inputs:
        out.append({"val": memo(a, b), "calls": memo.calls})
    assert out == [{"val": 4, "calls": 1}, {"val": 4, "calls": 1}, {"val": 3, "calls": 2}]

_test_baseline_numbers()
\end{minted}
\VALIDATION{Covers primitive caching. Avoids object identity cases that this baseline cannot handle correctly.}
\NotePages{3}

% ============ 5. Approach B — Improved (own page) ============
\section{Approach B — Improved}
\ApproachPage{B}{Optimized Data Structure / Pruning / DP}
\WHICHFORMULA{Construct identity-aware keys that match JS \texttt{===}: primitives are keyed by value with type tag; objects are keyed by identity using \texttt{id()}.}
\ASSUMPTIONS{No NaN among inputs. Include argument count in the key to avoid prefix collisions, and keep keywords sorted with converted values.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item For each argument, map it to a key element:
\begin{bullets}
\item primitives: \texttt{('P', type, value)} with $-0.0$ normalized to $0.0$;
\item objects: \texttt{('O', id(arg))}.
\end{bullets}
\item Build the overall key as a tuple: \texttt{('_argc_', k)}, each arg key element, and optional \texttt{('_kw_', ...)} for kwargs.
\item Memoize on this key in a hash map.
\end{algosteps}
\COMPLEXITY{Same $O(k)$ per call to build the key; expected $O(1)$ lookups/inserts; $O(M)$ space. It is now correct w.r.t. identity semantics.}
\[
\begin{aligned}
T_{\text{per call}}(k) &= O(k) \\
S(M) &= O(M)
\end{aligned}
\]
\CORRECTNESS{By construction, keys are equal iff arguments are \texttt{===} under the specified rules. Type tags prevent collisions like \texttt{1} vs \texttt{True}.}
\textbf{Code (Improved)}
\begin{minted}{python}
class Solution:
    def _elem_key(self, x):
        t = type(x)
        # Primitives by value with type tag (JS === type-sensitive)
        if t in (bool, int, float, str, bytes, type(None)):
            if isinstance(x, float):
                # Reject NaN per constraints; normalize -0.0 to +0.0
                if x != x:
                    raise ValueError("NaN not allowed by constraints")
                if x == 0.0:
                    x = 0.0
            return ("P", t.__name__, x)
        # Objects by identity
        return ("O", id(x))

    def memoize(self, fn):
        cache = {}

        def make_key(args, kwargs):
            parts = [("_argc_", len(args))]
            parts.extend(self._elem_key(a) for a in args)
            if kwargs:
                parts.append(("_kw_", tuple(sorted((k, self._elem_key(v)) for k, v in kwargs.items()))))
            return tuple(parts)

        def wrapper(*args, **kwargs):
            key = make_key(args, kwargs)
            if key in cache:
                return cache[key]
            wrapper.calls += 1
            out = fn(*args, **kwargs)
            cache[key] = out
            return out

        wrapper.calls = 0
        return wrapper


# --- Tests (Improved) ---
def _test_improved_examples():
    sol = Solution()

    # Example 1 (primitives)
    def add(a, b): return a + b
    memo1 = sol.memoize(add)
    inputs1 = [(2, 2), (2, 2), (1, 2)]
    out1 = [{"val": memo1(a, b), "calls": memo1.calls} for (a, b) in inputs1]
    assert out1 == [{"val": 4, "calls": 1}, {"val": 4, "calls": 1}, {"val": 3, "calls": 2}]

    # Example 2 (distinct objects -> no cache hits)
    def merge(a, b): return {**a, **b}
    memo2 = sol.memoize(merge)
    inputs2 = [({}, {}), ({}, {}), ({}, {})]  # all fresh objects
    out2 = [{"val": memo2(a, b), "calls": memo2.calls} for (a, b) in inputs2]
    assert out2 == [{"val": {}, "calls": 1}, {"val": {}, "calls": 2}, {"val": {}, "calls": 3}]

    # Example 3 (same object reference -> cache hits)
    o = {}
    memo3 = sol.memoize(merge)
    inputs3 = [(o, o), (o, o), (o, o)]
    out3 = [{"val": memo3(a, b), "calls": memo3.calls} for (a, b) in inputs3]
    assert out3 == [{"val": {}, "calls": 1}, {"val": {}, "calls": 1}, {"val": {}, "calls": 1}]

_test_improved_examples()
\end{minted}
\VALIDATION{Covers primitives, distinct object references, and repeated identical references. Also protects against NaN per constraints.}
\NotePages{3}

% ============ 6. Approach C — Optimal (own page) ============
\section{Approach C — Optimal}
\ApproachPage{C}{Provably Optimal Method}
\WHICHFORMULA{Use a trie of nested maps keyed by argument key-elements to avoid constructing long tuple keys and reduce hashing overhead. The end-node stores the cached value.}
\ASSUMPTIONS{Same identity-aware key elements as Approach B; include arity and a kwargs marker to avoid collisions.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Define \texttt{key\_elem} mapping each argument to a discriminated key as in Approach B.
\item Traverse a nested dict from the root using: \texttt{('_argc_', k)}, then each \texttt{key\_elem(arg)}, and finally an optional \texttt{('_kw_', ...)}.
\item If a terminal marker exists, return it; otherwise compute, store at terminal, and increment call count.
\end{algosteps}
\OPTIMALITY{This minimizes repeated hashing/allocations for long argument lists by sharing prefixes and doing $O(k)$ nested lookups. Lower bound is $\Omega(k)$ to at least read the arguments; the method is asymptotically tight.}
\COMPLEXITY{Per call $O(k)$ node traversals; expected $O(1)$ per step. Space $O(M)$ nodes for $M$ distinct argument sequences, with prefix sharing across calls.}
\[
\begin{aligned}
T_{\text{per call}}(k) &= O(k) \\
S(M) &= O(M)
\end{aligned}
\]
\textbf{Code (Final Submission)}
\begin{minted}{python}
class Solution:
    def memoize(self, fn):
        root = {}
        END = ("__END__",)

        def key_elem(x):
            t = type(x)
            if t in (bool, int, float, str, bytes, type(None)):
                if isinstance(x, float):
                    if x != x:
                        raise ValueError("NaN not allowed by constraints")
                    if x == 0.0:
                        x = 0.0  # normalize -0.0/+0.0
                return ("P", t.__name__, x)
            return ("O", id(x))

        def wrapper(*args, **kwargs):
            node = root
            # Path: arity, each arg key, optional kwargs
            path = [("_argc_", len(args))]
            for a in args:
                path.append(key_elem(a))
            if kwargs:
                path.append(("_kw_", tuple(sorted((k, key_elem(v)) for k, v in kwargs.items()))))
            # Traverse/create
            for k in path:
                if k not in node:
                    node[k] = {}
                node = node[k]
            # Terminal check
            if END in node:
                return node[END]
            wrapper.calls += 1
            res = fn(*args, **kwargs)
            node[END] = res
            return res

        wrapper.calls = 0
        return wrapper


# --- Tests (Final) ---
def _test_final():
    sol = Solution()

    # Example 1
    def add(a, b): return a + b
    m1 = sol.memoize(add)
    inputs1 = [(2, 2), (2, 2), (1, 2)]
    out1 = [{"val": m1(a, b), "calls": m1.calls} for (a, b) in inputs1]
    assert out1 == [{"val": 4, "calls": 1}, {"val": 4, "calls": 1}, {"val": 3, "calls": 2}]

    # Example 2
    def merge(a, b): return {**a, **b}
    m2 = sol.memoize(merge)
    inputs2 = [({}, {}), ({}, {}), ({}, {})]
    out2 = [{"val": m2(a, b), "calls": m2.calls} for (a, b) in inputs2]
    assert out2 == [{"val": {}, "calls": 1}, {"val": {}, "calls": 2}, {"val": {}, "calls": 3}]

    # Example 3
    o = {}
    m3 = sol.memoize(merge)
    inputs3 = [(o, o), (o, o), (o, o)]
    out3 = [{"val": m3(a, b), "calls": m3.calls} for (a, b) in inputs3]
    assert out3 == [{"val": {}, "calls": 1}, {"val": {}, "calls": 1}, {"val": {}, "calls": 1}]

_test_final()
\end{minted}
\VALIDATION{Exactly 3 asserts covering the three examples from the statement.}
\RESULT{A correct memoizer under JS \texttt{===}-style semantics: primitives by value with type tag; objects by identity. Ties do not apply.}
\NotePages{3}

% ============ 7. Testing & Final Reference Implementation (own page) ============
\section{Testing \& Final Reference Implementation}
\LINE{TEST PLAN}{Unit tests exercise: repeated primitives for cache hits; distinct vs identical objects; boolean vs integer typing; keyword arguments stability; and absence of NaN.}
\LINE{CROSS-CHECKS}{Compare outputs across Approaches A, B, and C on primitives (all agree). On object-identity cases, A may disagree; B and C agree.}
\LINE{EDGE-CASE GENERATOR}{Produce tuples of size $k \in \{0,1,2,5\}$ over a small domain: integers $\{-1,0,1\}$, floats $\{-0.0,0.0,1.5\}$, strings, booleans, and fresh object instances to probe identity vs value.}
\begin{minted}{python}
import random

def gen_args(seed=0, k=3, n=20):
    random.seed(seed)
    atoms = [None, -1, 0, 1, -0.0, 0.0, 1.5, "x", "y", True, False]
    res = []
    for _ in range(n):
        args = []
        for __ in range(k):
            choice = random.choice(["prim", "obj"])
            if choice == "prim":
                args.append(random.choice(atoms))
            else:
                args.append({})  # fresh identity
        res.append(tuple(args))
    return res

def cross_check():
    # A vs C on primitives: must match
    from copy import deepcopy

    # Approach A (baseline)
    class SA:
        def _safe_repr(self, x):
            try: return repr(x)
            except Exception: return f"<unrepr:{type(x).__name__}>"
        def memoize(self, fn):
            cache = {}
            def mk(args, kwargs):
                try: return ("H", args, tuple(sorted(kwargs.items())))
                except TypeError:
                    return ("R", tuple(self._safe_repr(a) for a in args),
                            tuple(sorted((k, self._safe_repr(v)) for k,v in kwargs.items())))
            def w(*a, **kw):
                key = mk(a, kw)
                if key in cache: return cache[key]
                w.calls += 1
                cache[key] = fn(*a, **kw); return cache[key]
            w.calls = 0
            return w

    # Approach C (final)
    class SC:
        def memoize(self, fn):
            root, END = {}, ("__END__",)
            def elem(x):
                t = type(x)
                if t in (bool, int, float, str, bytes, type(None)):
                    if isinstance(x, float):
                        if x != x: raise ValueError
                        if x == 0.0: x = 0.0
                    return ("P", t.__name__, x)
                return ("O", id(x))
            def w(*args, **kwargs):
                node = root
                path = [("_argc_", len(args))]
                path += [elem(a) for a in args]
                if kwargs:
                    path.append(("_kw_", tuple(sorted((k, elem(v)) for k, v in kwargs.items()))))
                for k in path:
                    if k not in node: node[k] = {}
                    node = node[k]
                if END in node: return node[END]
                w.calls += 1
                node[END] = fn(*args, **kwargs); return node[END]
            w.calls = 0
            return w

    def add(*xs): return sum(0 if x is None else (1 if x is True else (0 if x is False else x)) for x in xs if not isinstance(x, dict))
    sa, sc = SA(), SC()
    ma, mc = sa.memoize(add), sc.memoize(add)
    # Only primitive args to ensure A and C align
    prim_sets = [(1, 2, 3), ("x", "x"), (True, False), (0.0, -0.0)]
    for args in prim_sets * 3:
        va, vc = ma(*args), mc(*args)
        assert va == vc
    # Object identity cases: only check C's internal consistency
    mobj = sc.memoize(lambda a, b: {**a, **b})
    o = {}
    assert mobj(o, o) == {}
    assert mobj.calls == 1
    assert mobj(o, o) == {}
    assert mobj.calls == 1
    assert mobj({}, {}) == {}
    assert mobj.calls == 2

cross_check()
\end{minted}
\textbf{Reference Code (Ready to Submit)}
\begin{minted}{python}
class Solution:
    def memoize(self, fn):
        root = {}
        END = ("__END__",)

        def key_elem(x):
            t = type(x)
            if t in (bool, int, float, str, bytes, type(None)):
                if isinstance(x, float):
                    if x != x:
                        raise ValueError("NaN not allowed by constraints")
                    if x == 0.0:
                        x = 0.0
                return ("P", t.__name__, x)
            return ("O", id(x))

        def wrapper(*args, **kwargs):
            node = root
            path = [("_argc_", len(args))]
            for a in args:
                path.append(key_elem(a))
            if kwargs:
                path.append(("_kw_", tuple(sorted((k, key_elem(v)) for k, v in kwargs.items()))))
            for k in path:
                if k not in node:
                    node[k] = {}
                node = node[k]
            if END in node:
                return node[END]
            wrapper.calls += 1
            res = fn(*args, **kwargs)
            node[END] = res
            return res

        wrapper.calls = 0
        return wrapper


# Sanity asserts mirroring the statement
if __name__ == "__main__":
    sol = Solution()

    def add(a, b): return a + b
    m1 = sol.memoize(add)
    seq1 = [(2, 2), (2, 2), (1, 2)]
    got1 = [{"val": m1(a, b), "calls": m1.calls} for (a, b) in seq1]
    assert got1 == [{"val": 4, "calls": 1}, {"val": 4, "calls": 1}, {"val": 3, "calls": 2}]

    def merge(a, b): return {**a, **b}
    m2 = sol.memoize(merge)
    seq2 = [({}, {}), ({}, {}), ({}, {})]
    got2 = [{"val": m2(a, b), "calls": m2.calls} for (a, b) in seq2]
    assert got2 == [{"val": {}, "calls": 1}, {"val": {}, "calls": 2}, {"val": {}, "calls": 3}]

    o = {}
    m3 = sol.memoize(merge)
    seq3 = [(o, o), (o, o), (o, o)]
    got3 = [{"val": m3(a, b), "calls": m3.calls} for (a, b) in seq3]
    assert got3 == [{"val": {}, "calls": 1}, {"val": {}, "calls": 1}, {"val": {}, "calls": 1}]
\end{minted}
\NotePages{3}

% ============ 8. Review & Pitfalls (own page) ============
\section{Review \& Pitfalls}
\WHAT{Memoize a function under JS \texttt{===}-style equality: primitives by value (type-sensitive), objects by identity.}
\WHY{Common in interviews to test understanding of equality vs identity, caching design, and building robust hashable keys.}
\CHECKLIST{
\begin{bullets}
\item Classify each argument as primitive vs object.
\item Build a collision-free key: include type tags and arity.
\item Normalize float $-0.0$ and $0.0$; reject NaN per constraints.
\item Include kwargs deterministically (sorted) if supported.
\item Increment call counter only on cache miss.
\end{bullets}
}
\EDGECASES{
\begin{bullets}
\item Distinct empty dicts/lists should not collide.
\item Same object reference should hit the cache.
\item \texttt{1} vs \texttt{True} must not collide.
\item Float $-0.0$ vs $0.0$ should be treated equal.
\item Large arity: prevent prefix collisions by including arity.
\item No NaN in inputs: guard anyway.
\item Zero-argument functions: arity still disambiguates.
\item Mixed primitives and objects in the same position.
\item Keyword arguments order should not matter.
\item Re-entrancy: side effects only on cache miss.
\end{bullets}
}
\PITFALLS{
\begin{bullets}
\item Using \texttt{repr} or deep serialization: breaks identity semantics.
\item Omitting type tags: \texttt{1} and \texttt{True} collide in Python.
\item Not normalizing $-0.0$: diverges from JS \texttt{===}.
\item Forgetting to include arity: prefix-tuple collisions.
\item Unsorted kwargs: non-deterministic keys.
\item Counting calls on cache hits by mistake.
\item Mutating arguments after caching (safe here since key uses identities/values at call time, but beware of relying on mutable content).
\item Memory leaks from retaining references forever; consider weak refs if needed.
\end{bullets}
}
\FAILMODES{Baseline approaches that hash by \texttt{repr} will treat distinct objects as equal. Approaches B/C survive by using identity-aware keys.}
\ELI{Remember: numbers/strings are cached by their value, but objects are cached by their exact identity. If the same object shows up again, you skip work; if it is a different object that just looks the same, you recompute.}
\NotePages{3}

\end{document}