% !TeX program = xelatex
\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{microtype}
\usepackage{setspace}\setstretch{1.05}
\usepackage{fontspec}
\setmainfont{Latin Modern Roman}
\setmonofont{Latin Modern Mono}[BoldFont={Latin Modern Mono},ItalicFont={Latin Modern Mono}]
\usepackage{amsmath,mathtools,amsthm}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\usepackage{unicode-math}\setmathfont{Latin Modern Math}\allowdisplaybreaks[4]
% --- overflow and alignment slack ---
\setlength{\jot}{7pt}
\sloppy\emergencystretch=8em\hfuzz=1pt\vfuzz=2pt\raggedbottom
% --- breakable math helpers ---
\newenvironment{BreakableEquation}{\begin{equation}\begin{aligned}}{\end{aligned}\end{equation}}
\newenvironment{BreakableEquation*}{\begin{equation*}\begin{aligned}}{\end{aligned}\end{equation*}}
\newenvironment{tightalign}{\begingroup\small\allowdisplaybreaks\begin{align}}{\end{align}\endgroup}

\usepackage{xcolor}
\usepackage{xurl} % better URL wrapping
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue]{hyperref}
\usepackage{fancyhdr}
\pagestyle{fancy}\fancyhf{}\lhead{\nouppercase{\leftmark}}\rhead{\thepage}\setlength{\headheight}{26pt}
\usepackage{enumitem,booktabs,tabularx}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\renewcommand{\arraystretch}{1.1}
\setlength{\parindent}{0pt}\setlength{\parskip}{8pt plus 2pt minus 1pt}

% Listings + upquote (no shell-escape needed)
\usepackage{listings}
\usepackage{upquote}
\lstdefinestyle{crisp}{
  basicstyle=\ttfamily\footnotesize,
  frame=single,
  breaklines=true,
  breakatwhitespace=false, % allow breaks inside long tokens
  tabsize=4,
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny,
  numbersep=8pt,
  keepspaces=true,
  columns=fullflexible,
  backgroundcolor=\color{black!02},
  aboveskip=8pt,
  belowskip=8pt
}
% Guarantee that 'python' exists as a language for listings
\lstdefinelanguage{python}{
  morekeywords={def,return,class,if,elif,else,for,while,try,except,raise,assert,pass,break,continue,lambda,nonlocal,global,yield,import,from,as,with,True,False,None},
  sensitive=true,
  morecomment=[l]\#,
  morestring=[b]",
  morestring=[b]'
}
% minted shim (robust; no shell-escape; uses listings' own environment)
\lstnewenvironment{minted}[2][]{\lstset{style=crisp,language=#2,#1}}{}

\usepackage[most]{tcolorbox}
\tcbset{colback=white,colframe=black!15,boxrule=0.4pt,arc=2pt,left=6pt,right=6pt,top=6pt,bottom=6pt,before skip=10pt,after skip=10pt,breakable}
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection}{0.6em}{}
\titlespacing*{\section}{0pt}{*2.0}{*1.0}

% ===== CONSISTENCY TOOLKIT (macros) =====
\newlist{ledger}{enumerate}{1}
\setlist[ledger]{label=\textbullet,leftmargin=2em,itemsep=2pt,topsep=6pt}
\newcommand{\LEDGER}[1]{\textbf{ARITHMETIC LEDGER:}\par\begin{ledger}#1\end{ledger}}

\newlist{algosteps}{enumerate}{1}
\setlist[algosteps]{label=\arabic*.,leftmargin=2em,itemsep=2pt,topsep=6pt}

\newlist{bullets}{itemize}{1}
\setlist[bullets]{label=--,leftmargin=1.6em,itemsep=2pt,topsep=4pt}

\newcommand{\varmapStart}{\textbf{VARIABLE MAPPING:}\par\begin{bullets}}
\newcommand{\var}[2]{\item $#1$ — #2}
\newcommand{\varmapEnd}{\end{bullets}}

\newcommand{\LINE}[2]{\par\noindent\textbf{#1:}~#2\par}
\newcommand{\WHAT}[1]{\LINE{WHAT}{#1}}
\newcommand{\WHY}[1]{\LINE{WHY}{#1}}
\newcommand{\HOW}[1]{\LINE{HOW}{#1}}
\newcommand{\ELI}[1]{\LINE{ELI5}{#1}}
\newcommand{\STATEMENT}[1]{\LINE{STATEMENT}{#1}}
\newcommand{\BREAKDOWN}[1]{\LINE{PROBLEM BREAKDOWN}{#1}}
\newcommand{\MODEL}[1]{\LINE{CANONICAL MATHEMATICAL MODEL}{#1}}
\newcommand{\ASSUMPTIONS}[1]{\LINE{ASSUMPTIONS}{#1}}
\newcommand{\INVARIANTS}[1]{\LINE{INVARIANTS}{#1}}
\newcommand{\WHICHFORMULA}[1]{\LINE{WHICH FORMULA \& WHY}{#1}}
\newcommand{\GOVERN}[1]{\LINE{GOVERNING EQUATION(S)}{#1}}
\newcommand{\INPUTS}[1]{\LINE{INPUTS}{#1}}
\newcommand{\OUTPUTS}[1]{\LINE{OUTPUTS}{#1}}
\newcommand{\SAMPLES}[1]{\LINE{SAMPLES}{#1}}
\newcommand{\RESULT}[1]{\LINE{RESULT}{#1}}
\newcommand{\COMPLEXITY}[1]{\LINE{TIME/SPACE COMPLEXITY}{#1}}
\newcommand{\MEMORY}[1]{\LINE{MEMORY FOOTPRINT}{#1}}
\newcommand{\CORRECTNESS}[1]{\LINE{CORRECTNESS SKETCH}{#1}}
\newcommand{\OPTIMALITY}[1]{\LINE{OPTIMALITY}{#1}}
\newcommand{\FAILMODES}[1]{\LINE{FAILURE MODES}{#1}}
\newcommand{\VALIDATION}[1]{\LINE{VALIDATION}{#1}}
\newcommand{\UNITCHECK}[1]{\LINE{UNIT CHECK}{#1}}
\newcommand{\EDGECASES}[1]{\LINE{EDGE CASES}{#1}}
\newcommand{\CHECKLIST}[1]{\LINE{CHECKLIST}{#1}}
\newcommand{\DERIV}[1]{\LINE{DERIVATION}{#1}}
\newcommand{\LEMMAHEAD}[1]{\LINE{SUPPORTING LEMMA}{#1}}
\newcommand{\PITFALLS}[1]{\LINE{PITFALLS}{#1}}

\usepackage{etoolbox}\pretocmd{\section}{\clearpage}{}{}

\newcommand{\FormulaPage}[2]{%
  \clearpage
  \section*{Formula #1 — #2}%
  \addcontentsline{toc}{section}{Formula #1 — #2}%
}
\newcommand{\ApproachPage}[2]{%
  \clearpage
  \subsection*{Approach #1 — #2}%
  \addcontentsline{toc}{subsection}{Approach #1 — #2}%
}

\begin{document}
\title{Interview Problem Sheet — Ralph And His Tour in Binary Country}
\date{\today}
\author{}
\maketitle
\tableofcontents
\clearpage

% === Notes macro (BODY-ONLY; do not alter the preamble) ===
% Prints exactly N blank pages with empty headers/footers, then leaves you on the last blank page.
\newcommand{\NotePages}[1]{%
  \clearpage
  \begingroup
  \newcount\NPi \newcount\NPn
  \NPi=0 \NPn=#1
  \loop\ifnum\NPi<\NPn
    \advance\NPi by 1
    \mbox{}\thispagestyle{empty}%
    \ifnum\NPi<\NPn\clearpage\fi
  \repeat
  \endgroup
}

% ============ 1. Problem & Metadata (own page) ============
\section{Problem \& Metadata}
\LINE{PLATFORM}{CF}
\LINE{URL}{\url{https://codeforces.com/problemset/problem/894/D}}
\LINE{DIFFICULTY / RATING}{2200}
\STATEMENT{Ralph is in the Binary Country. The Binary Country consists of $n$ cities and $(n - 1)$ bidirectional roads connecting the cities. The roads are numbered from $1$ to $(n - 1)$, the $i$-th road connects the city labeled $\left\lfloor \dfrac{i+1}{2} \right\rfloor$ (here $\lfloor x \rfloor$ denotes $x$ rounded down to the nearest integer) and the city labeled $(i + 1)$, and the length of the $i$-th road is $L_i$.

Now Ralph gives you $m$ queries. In each query he tells you some city $A_i$ and an integer $H_i$. He wants to make some tours starting from this city. He can choose any city in the Binary Country (including $A_i$) as the terminal city for a tour. He gains happiness $(H_i - L)$ during a tour, where $L$ is the distance between the city $A_i$ and the terminal city.

Ralph is interested in tours from $A_i$ in which he can gain positive happiness. For each query, compute the sum of happiness gains for all such tours.

Ralph will never take the same tour twice or more (in one query), he will never pass the same city twice or more in one tour.

Input:
The first line contains two integers $n$ and $m$ ($1 \le n \le 10^6$, $1 \le m \le 10^5$).

$(n - 1)$ lines follow, each line contains one integer $L_i$ ($1 \le L_i \le 10^5$), which denotes the length of the $i$-th road.

$m$ lines follow, each line contains two integers $A_i$ and $H_i$ ($1 \le A_i \le n$, $0 \le H_i \le 10^7$).

Output:
Print $m$ lines, on the $i$-th line print one integer — the answer for the $i$-th query.

Note:
Here is the explanation for the second sample.

Ralph's first query is to start tours from city $2$ and $H_i$ equals to $4$. Here are the options:
\begin{bullets}
\item He can choose city $5$ as his terminal city. Since the distance between city $5$ and city $2$ is $3$, he can gain happiness $4 - 3 = 1$.
\item He can choose city $4$ as his terminal city and gain happiness $3$.
\item He can choose city $1$ as his terminal city and gain happiness $2$.
\item He can choose city $3$ as his terminal city and gain happiness $1$.
\item Note that Ralph can choose city $2$ as his terminal city and gain happiness $4$.
\item Ralph will not choose city $6$ as his terminal city because the distance between city $6$ and city $2$ is $5$, which leads to negative happiness for Ralph.
\end{bullets}
So the answer for the first query is $1 + 3 + 2 + 1 + 4 = 11$.}
\BREAKDOWN{We need to compute for each query $(A, H)$ the sum $\sum_{v \in V} \max(0, H - \operatorname{dist}(A, v))$ on a fixed binary heap-shaped tree with weighted edges. Direct per-query breadth-first or Dijkstra is too slow; we exploit the specific parent structure to precompute sorted distance lists for subtrees and aggregate along the path from $A$ to the root.}
\ELI{Sum the positive leftovers of $H$ after paying the travel distance from $A$ to every city; compute subtree sums fast, then walk up to add ancestor and sibling-subtree contributions.}
\NotePages{3}

% ============ 2. IO Contract (own page) ============
\section{IO Contract}
\INPUTS{Two integers $n, m$. Then $n-1$ integers $L_1,\ldots,L_{n-1}$ for road lengths where road $i$ connects $\left\lfloor \tfrac{i+1}{2} \right\rfloor$ and $(i+1)$. Then $m$ lines with $A_i, H_i$. Ranges: $1 \le n \le 10^6$, $1 \le m \le 10^5$, $1 \le L_i \le 10^5$, $1 \le A_i \le n$, $0 \le H_i \le 10^7$.}
\OUTPUTS{For each query $i$ output a single integer: $\sum_{v=1}^n \max(0, H_i - \operatorname{dist}(A_i, v))$. One answer per line.}
\SAMPLES{Example 1 (tiny):
\begin{bullets}
\item $n=3, m=1$; $L_1=1, L_2=2$; query $A=2, H=2$. Distances from $2$: to $2$ is $0$, to $1$ is $1$, to $3$ is $1+2=3$. Sum: $(2-0)+(2-1)+\max(0,2-3)=2+1+0=3$.
\item $n=6, m=1$; $L=[2,1,1,3,2]$; query $A=2, H=4$. From the note, the answer is $11$.
\end{bullets}}
\NotePages{3}

% ============ 3. Canonical Mathematical Model (own page) ============
\section{Canonical Mathematical Model}
\MODEL{Let $T=(V,E)$ be a rooted binary tree on $V=\{1,\ldots,n\}$ with root $1$ and edges $((\lfloor \tfrac{i+1}{2} \rfloor, i+1), L_i)$ for $i=1,\ldots,n-1$, with positive lengths $L_i$. For a query $(A,H)$ define
\begin{BreakableEquation*}
F(A,H) \coloneqq \sum_{v\in V} \max\bigl(0,\, H - \operatorname{dist}(A,v)\bigr).
\end{BreakableEquation*}
We must compute $F(A,H)$ for all queries.}
\varmapStart
\var{n}{number of cities}
\var{m}{number of queries}
\var{L_i}{length of edge between $\lfloor \tfrac{i+1}{2} \rfloor$ and $(i+1)$}
\var{A,H}{query start city and happiness budget}
\var{\operatorname{dist}(u,v)}{shortest-path distance in $T$}
\var{D_u}{sorted multiset of distances from $u$ to nodes in its subtree (including $0$)}
\var{P_u}{prefix sums over $D_u$ aligned with $D_u$}
\varmapEnd
\GOVERN{
\begin{BreakableEquation*}
F(A,H)=\underbrace{\sum_{x\in \text{subtree}(A)} \max(0,H-\operatorname{dist}(A,x))}_{\text{subtree term}}+\sum_{p\in \text{ancestors}(A)}\left[\max(0,H-\operatorname{dist}(A,p))+\!\!\!\sum_{x\in \text{sibling-subtree at }p}\!\!\!\max(0,H-\operatorname{dist}(A,x))\right].
\end{BreakableEquation*}
The subtree term reduces to $kH - \sum_{i=1}^k D_A[i]$ where $k=\max\{j: D_A[j]\le H\}$ using $D_A$ and $P_A$. Sibling-subtree terms similarly use the shifted $H$ budget $H' = H - \operatorname{dist}(A,p) - w(p,\text{sibling})$ against $D_{\text{sibling}}$.
}
\ASSUMPTIONS{Tree is connected and acyclic by construction. Indices follow $1$-based heap: children of $u$ are $2u$ and $2u+1$ if they do not exceed $n$. Distances are unique sums of positive edge lengths.}
\INVARIANTS{
\begin{bullets}
\item For each $u$, $D_u = \{0\} \cup \{d+w(u,2u): d\in D_{2u}\} \cup \{d+w(u,2u+1): d\in D_{2u+1}\}$ sorted.
\item Prefix sums $P_u$ match $D_u$, enabling $O(\log |D_u|)$ evaluation of $\sum_{d\le H} (H-d)$.
\item Decomposition along ancestors of $A$ counts each node exactly once: either in $A$'s subtree, some sibling-subtree, or an ancestor node itself.
\end{bullets}
}
\NotePages{3}

% ============ 4. Approach A — Baseline (own page) ============
\section{Approach A — Baseline}
\ApproachPage{A}{Brute Force / Direct}
\WHICHFORMULA{For each query $(A,H)$, compute all-pairs distances from $A$ using Dijkstra on the tree (nonnegative weights), then sum $\max(0,H-d)$ over all nodes.}
\ASSUMPTIONS{Prebuild adjacency lists once. Stop relaxing paths exceeding $H$ is a mild pruning but worst-case still $O(n)$.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Build adjacency lists for the $n$-node tree from $L_i$.
\item For a query $(A,H)$, run Dijkstra from $A$, computing distances $d[v]$; optionally ignore pushing states exceeding $H$.
\item Accumulate $\sum_v \max(0,H-d[v])$.
\end{algosteps}
\COMPLEXITY{Each query runs in $O(n \log n)$ in worst case; total $O(mn \log n)$ time and $O(n)$ extra space.}
\[
\begin{aligned}
T_{\text{per-query}}(n) &= O\bigl((n-1)\log n\bigr) \\
T_{\text{total}}(n,m) &= O\bigl(mn\log n\bigr),\quad S(n)=O(n).
\end{aligned}
\]
\CORRECTNESS{Dijkstra yields exact shortest-path distances on a graph with nonnegative edge weights. Summation applies definition of $F(A,H)$.}
\EDGECASES{Single node tree; $H=0$; very large $H$ covering all nodes; skewed heavy edge making many nodes unreachable within $H$.}
\textbf{Code (Baseline)}
\begin{minted}{python}
import sys
import heapq
from typing import List, Tuple

def read_input(data: List[str] = None):
    if data is None:
        data = sys.stdin.read().strip().split()
        if not data:
            return None
    it = iter(data)
    n = int(next(it)); m = int(next(it))
    L = [0]*(n+1)  # 1..n-1 used
    for i in range(1, n):
        L[i] = int(next(it))
    queries = []
    for _ in range(m):
        a = int(next(it)); h = int(next(it))
        queries.append((a, h))
    return n, m, L, queries

def build_adj(n: int, L: List[int]) -> List[List[Tuple[int,int]]]:
    adj = [[] for _ in range(n+1)]
    for i in range(1, n):
        u = (i+1)//2
        v = i+1
        w = L[i]
        adj[u].append((v, w))
        adj[v].append((u, w))
    return adj

def solve_all_baseline(n: int, m: int, L: List[int], queries: List[Tuple[int,int]]) -> List[int]:
    adj = build_adj(n, L)
    ans = []
    for (A, H) in queries:
        # Dijkstra from A, prune by H
        INF = 10**30
        dist = [INF]*(n+1)
        dist[A] = 0
        pq = [(0, A)]
        while pq:
            d, u = heapq.heappop(pq)
            if d != dist[u]:
                continue
            if d > H:
                continue
            for v, w in adj[u]:
                nd = d + w
                if nd < dist[v] and nd <= H:  # prune pushing beyond H
                    dist[v] = nd
                    heapq.heappush(pq, (nd, v))
        total = 0
        # Count nodes with dist <= H (others contribute 0)
        for v in range(1, n+1):
            d = dist[v]
            if d <= H:
                total += H - d
        ans.append(total)
    return ans

def _self_test_baseline():
    # Tiny test 1
    n, m = 3, 1
    L = [0, 1, 2]
    queries = [(2, 2)]
    out = solve_all_baseline(n, m, L, queries)
    assert out == [3]
    # Tiny linear tree n=2
    n, m = 2, 2
    L = [0, 5]
    queries = [(1, 0), (2, 10)]
    out = solve_all_baseline(n, m, L, queries)
    # From 1 with H=0: only node 1 contributes 0
    # From 2 with H=10: node 2 contributes 10, node 1 contributes 5
    assert out == [0, 15]

def main():
    data = sys.stdin.read().strip().split()
    if not data:
        # Optional quick self-checks when no input is provided
        _self_test_baseline()
        return
    n, m, L, queries = read_input(data)
    out = solve_all_baseline(n, m, L, queries)
    print("\n".join(str(x) for x in out))

if __name__ == "__main__":
    # Do not run main if imported; execute when script is entry point.
    # Baseline sanity checks
    _self_test_baseline()
    # Only run main if there is input
    if not sys.stdin.isatty():
        # Peek without consuming: we already consumed in main
        sys.stdin.seek(0)
    main()
\end{minted}
\VALIDATION{Two asserts included. Additionally, manual check on a path of length one validates pruning by $H$ and sum formula.}
\NotePages{3}

% ============ 5. Approach B — Improved (own page) ============
\section{Approach B — Improved}
\ApproachPage{B}{Optimized Data Structure / Pruning / DP}
\WHICHFORMULA{Precompute for every node $u$ the sorted list $D_u$ of distances to nodes in its subtree and corresponding prefix sums $P_u$. This enables $O(\log |D_u|)$ evaluation of $\sum_{x\in \text{subtree}(u)} \max(0, H - \operatorname{dist}(u,x))$. For full-tree answer, sum the subtree of $A$ and walk up ancestors, adding the ancestor itself and the sibling subtree with appropriately reduced budget.}
\ASSUMPTIONS{Binary-heap indexing: children of $u$ are $2u$ and $2u+1$ if within $[1,n]$. Small-to-large merge to keep total time near $O\!\left(\sum |D_u|\right)$ with sorting linear in merges.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Build parent and child arrays in $O(n)$ from the given $L_i$.
\item Bottom-up for $u=n,n-1,\ldots,1$:
  \begin{bullets}
  \item Start with $D_u=[0]$.
  \item For each existing child $c$ of $u$, form shifted list $D_c + w(u,c)$ and merge into $D_u$ (small-to-large).
  \item Build prefix sums $P_u$ aligned with $D_u$.
  \end{bullets}
\item For a query $(A,H)$:
  \begin{bullets}
  \item Subtree term: let $k=\max\{j: D_A[j]\le H\}$; add $kH - P_A[k]$.
  \item Ascend $A \to$ root. At ancestor $p$ with child on path $c$, set $r=H-\operatorname{dist}(A,p)$. If $r<0$, stop. Add $r$ for node $p$. Let $s$ be sibling of $c$, if exists add subtree term on $s$ with budget $r - w(p,s)$.
  \end{bullets}
\end{algosteps}
\COMPLEXITY{Precomputation is $O\!\left(\sum_u |D_u|\right)$ time and space; in a heap-shaped binary tree this is $O(n \log n)$ on average levels. Each query ascends $O(\log n)$ ancestors and does $O(\log |D_x|)$ binary searches per visited subtree.}
\[
\begin{aligned}
T_{\text{build}}(n) &= O(n \log n), \\
T_{\text{query}}(n) &= O\bigl(\log n \cdot \log n\bigr) \text{ in practice}, \\
S(n) &= O(n \log n).
\end{aligned}
\]
\CORRECTNESS{By construction, $D_u$ enumerates all subtree distances from $u$. The ancestor walk partitions the node set into disjoint parts: subtree of $A$, ancestors of $A$, and sibling-subtrees at each ancestor. Each node appears exactly once and contributes $\max(0, H - \operatorname{dist}(A,\cdot))$.}
\textbf{Code (Improved)}
\begin{minted}{python}
import sys
import bisect
from typing import List, Tuple

def read_input(data: List[str] = None):
    if data is None:
        data = sys.stdin.read().strip().split()
        if not data:
            return None
    it = iter(data)
    n = int(next(it)); m = int(next(it))
    L = [0]*(n+1)
    for i in range(1, n):
        L[i] = int(next(it))
    queries = []
    for _ in range(m):
        a = int(next(it)); h = int(next(it))
        queries.append((a, h))
    return n, m, L, queries

def build_tree_heaped(n: int, L: List[int]):
    parent = [0]*(n+1)
    w_to_parent = [0]*(n+1)
    childL = [0]*(n+1)
    childR = [0]*(n+1)
    wL = [0]*(n+1)
    wR = [0]*(n+1)
    for i in range(1, n):
        p = (i+1)//2
        v = i+1
        w = L[i]
        parent[v] = p
        w_to_parent[v] = w
        if childL[p] == 0:
            childL[p] = v
            wL[p] = w
        else:
            childR[p] = v
            wR[p] = w
    return parent, w_to_parent, childL, childR, wL, wR

def merge_small_to_large(a: List[int], b: List[int]) -> List[int]:
    # Both sorted nondecreasing
    if len(a) < len(b):
        a, b = b, a
    # Merge b into a
    i = j = 0
    out = []
    out_extend = out.extend
    # Standard merge without allocations per element (still linear)
    while i < len(a) and j < len(b):
        if a[i] <= b[j]:
            out.append(a[i]); i += 1
        else:
            out.append(b[j]); j += 1
    if i < len(a): out_extend(a[i:])
    if j < len(b): out_extend(b[j:])
    return out

def build_D_and_P(n: int, childL: List[int], childR: List[int], wL: List[int], wR: List[int]):
    D = [None]*(n+1)
    P = [None]*(n+1)
    for u in range(n, 0, -1):
        # start with [0]
        base = [0]
        # left child
        if childL[u]:
            cl = childL[u]
            shifted = [x + wL[u] for x in D[cl]]
            base = merge_small_to_large(base, shifted)
        # right child
        if childR[u]:
            cr = childR[u]
            shifted = [x + wR[u] for x in D[cr]]
            base = merge_small_to_large(base, shifted)
        D[u] = base
        # prefix sums
        ps = [0]*len(base)
        s = 0
        for i, val in enumerate(base):
            s += val
            ps[i] = s
        P[u] = ps
    return D, P

def sum_subtree_positive(D: List[List[int]], P: List[List[int]], u: int, H: int) -> int:
    if H < 0:
        return 0
    vec = D[u]
    k = bisect.bisect_right(vec, H)
    if k <= 0:
        return 0
    return k*H - P[u][k-1]

def solve_all_improved(n: int, m: int, L: List[int], queries: List[Tuple[int,int]]) -> List[int]:
    parent, w_to_parent, childL, childR, wL, wR = build_tree_heaped(n, L)
    D, P = build_D_and_P(n, childL, childR, wL, wR)
    ans = []
    for (A, H) in queries:
        total = 0
        # Subtree of A
        total += sum_subtree_positive(D, P, A, H)
        # Walk up ancestors
        curr = A
        dist_up = 0
        while parent[curr] != 0:
            p = parent[curr]
            w_up = w_to_parent[curr]
            dist_up += w_up
            r = H - dist_up
            if r < 0:
                break
            # add ancestor node p itself
            total += r
            # add sibling subtree, if exists
            if childL[p] == curr:
                sib = childR[p]
                w_sib = wR[p]
            else:
                sib = childL[p]
                w_sib = wL[p]
            if sib != 0:
                total += sum_subtree_positive(D, P, sib, r - w_sib)
            curr = p
        ans.append(total)
    return ans

def _self_test_improved():
    # Use the sample explanation's consistent weights
    # n=6, edges: L=[2,1,1,3,2]
    n = 6
    L = [0, 2, 1, 1, 3, 2]
    queries = [(2, 4)]
    out = solve_all_improved(n, 1, L, queries)
    assert out == [11]
    # Simple 3-node tree
    n = 3
    L = [0, 1, 2]
    queries = [(2, 2)]
    out = solve_all_improved(n, 1, L, queries)
    assert out == [3]

def main():
    data = sys.stdin.read().strip().split()
    if not data:
        _self_test_improved()
        return
    n, m, L, queries = read_input(data)
    out = solve_all_improved(n, m, L, queries)
    print("\n".join(str(x) for x in out))

if __name__ == "__main__":
    _self_test_improved()
    if not sys.stdin.isatty():
        sys.stdin.seek(0)
    main()
\end{minted}
\VALIDATION{Asserts cover the sample explained case ($n=6$, $L=[2,1,1,3,2]$, $(A,H)=(2,4)$) yielding $11$, and a tiny $n=3$ case yielding $3$.}
\NotePages{3}

% ============ 6. Approach C — Optimal (own page) ============
\section{Approach C — Optimal}
\ApproachPage{C}{Provably Optimal Method}
\WHICHFORMULA{Maintain for each node $u$ the sorted list of subtree distances $D_u$ and prefix sums $P_u$ constructed bottom-up with small-to-large merging; answer queries by partitioning the tree along the ancestor chain of $A$. This matches known optimal solutions for this problem.}
\ASSUMPTIONS{All edge weights are positive. Tree indexed as a binary heap, ensuring $O(\log n)$ height. The sum of sizes $\sum_u |D_u|$ is $O(n \log n)$ on this structure, making preprocessing and memory feasible in optimized implementations.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Build parent/children arrays and edge weights.
\item Compute $D_u$ and $P_u$ bottom-up for all $u$ by merging shifted child lists into the parent and adding $0$.
\item For a query $(A,H)$, add subtree contribution at $A$, then for each ancestor $p$ of $A$ add node $p$ itself and the sibling subtree with reduced budget.
\end{algosteps}
\OPTIMALITY{The lower bound per query is at least $\Omega(\log n)$ to account for the ancestor chain in a balanced tree. Our query time is logarithmic in practice. Preprocessing at $O(n \log n)$ is tight given the output-sensitive need to prepare cumulative subtree distance distributions.}
\COMPLEXITY{Preprocessing $O(n \log n)$ time and space; per query $O(\log^2 n)$ with binary searches inside $O(\log n)$ ancestor steps.}
\[
\begin{aligned}
T_{\text{build}}(n) &\approx O(n \log n), \\
T_{\text{query}}(n) &\approx O(\log^2 n), \\
S(n) &\approx O(n \log n).
\end{aligned}
\]
\textbf{Code (Final Submission)}
\begin{minted}{python}
import sys
import bisect
from typing import List, Tuple

def read_input(data: List[str] = None):
    if data is None:
        data = sys.stdin.read().strip().split()
        if not data:
            return None
    it = iter(data)
    n = int(next(it)); m = int(next(it))
    L = [0]*(n+1)
    for i in range(1, n):
        L[i] = int(next(it))
    queries = []
    for _ in range(m):
        a = int(next(it)); h = int(next(it))
        queries.append((a, h))
    return n, m, L, queries

def build_tree_heaped(n: int, L: List[int]):
    parent = [0]*(n+1)
    w_to_parent = [0]*(n+1)
    childL = [0]*(n+1)
    childR = [0]*(n+1)
    wL = [0]*(n+1)
    wR = [0]*(n+1)
    for i in range(1, n):
        p = (i+1)//2
        v = i+1
        w = L[i]
        parent[v] = p
        w_to_parent[v] = w
        if childL[p] == 0:
            childL[p] = v
            wL[p] = w
        else:
            childR[p] = v
            wR[p] = w
    return parent, w_to_parent, childL, childR, wL, wR

def merge_sorted(a: List[int], b: List[int]) -> List[int]:
    if len(a) < len(b):
        a, b = b, a
    i = j = 0
    out = []
    out_extend = out.extend
    while i < len(a) and j < len(b):
        if a[i] <= b[j]:
            out.append(a[i]); i += 1
        else:
            out.append(b[j]); j += 1
    if i < len(a): out_extend(a[i:])
    if j < len(b): out_extend(b[j:])
    return out

def build_D_P(n: int, childL: List[int], childR: List[int], wL: List[int], wR: List[int]):
    D = [None]*(n+1)
    P = [None]*(n+1)
    for u in range(n, 1-1, -1):
        base = [0]
        if childL[u]:
            cl = childL[u]
            shifted = [x + wL[u] for x in D[cl]]
            base = merge_sorted(base, shifted)
        if childR[u]:
            cr = childR[u]
            shifted = [x + wR[u] for x in D[cr]]
            base = merge_sorted(base, shifted)
        D[u] = base
        ps = [0]*len(base)
        s = 0
        for i, val in enumerate(base):
            s += val
            ps[i] = s
        P[u] = ps
    return D, P

def sum_subtree(D: List[List[int]], P: List[List[int]], u: int, H: int) -> int:
    if H < 0:
        return 0
    vec = D[u]
    k = bisect.bisect_right(vec, H)
    if k <= 0:
        return 0
    return k*H - P[u][k-1]

def solve_all(n: int, m: int, L: List[int], queries: List[Tuple[int,int]]) -> List[int]:
    parent, w_to_parent, childL, childR, wL, wR = build_tree_heaped(n, L)
    D, P = build_D_P(n, childL, childR, wL, wR)
    out = []
    for (A, H) in queries:
        total = sum_subtree(D, P, A, H)
        curr = A
        dist_up = 0
        while parent[curr] != 0:
            p = parent[curr]
            dist_up += w_to_parent[curr]
            r = H - dist_up
            if r < 0:
                break
            total += r  # ancestor node p
            # sibling subtree
            if childL[p] == curr:
                sib = childR[p]; ws = wR[p]
            else:
                sib = childL[p]; ws = wL[p]
            if sib != 0:
                total += sum_subtree(D, P, sib, r - ws)
            curr = p
        out.append(total)
    return out

def _self_tests():
    # Sample-like case
    n = 6
    L = [0, 2, 1, 1, 3, 2]
    queries = [(2, 4)]
    assert solve_all(n, 1, L, queries) == [11]
    # Tiny balanced
    n = 3
    L = [0, 1, 2]
    queries = [(2, 2), (1, 0)]
    assert solve_all(n, 2, L, queries) == [3, 0]
    # Single node
    n = 1
    L = [0]
    queries = [(1, 5)]
    assert solve_all(n, 1, L, queries) == [5]

def main():
    data = sys.stdin.read().strip().split()
    if not data:
        _self_tests()
        return
    n, m, L, queries = read_input(data)
    out = solve_all(n, m, L, queries)
    print("\n".join(str(x) for x in out))

if __name__ == "__main__":
    _self_tests()
    if not sys.stdin.isatty():
        sys.stdin.seek(0)
    main()
\end{minted}
\VALIDATION{Exactly three asserts verifying: the sample-style $(2,4)\mapsto 11$ on $n=6$; a tiny $n=3$ case; and a single-node case where the answer equals $H$.}
\RESULT{For each query $(A,H)$, the program prints $\sum_{v=1}^n \max(0, H - \operatorname{dist}(A,v))$ as a 64-bit integer per line.}
\NotePages{3}

% ============ 7. Testing & Final Reference Implementation (own page) ============
\section{Testing \& Final Reference Implementation}
\LINE{TEST PLAN}{Unit tests cover base cases (single node), small trees with hand-computable sums, and the sample-style configuration. Property checks: for $H=0$, answer is $0$; for very large $H$, answer equals $nH - \sum_v \operatorname{dist}(A,v)$.}
\LINE{CROSS-CHECKS}{Compare outputs of baseline Dijkstra solution and improved solution on small random instances ($n\le 20$) for multiple random $H$.}
\LINE{EDGE-CASE GENERATOR}{Create random $n\le 20$ with random edge weights, then query random $(A,H)$ with $H$ in a range that sometimes prunes and sometimes includes all nodes.}
\begin{minted}{python}
import random

def gen_small_case(n=12, seed=0):
    random.seed(seed)
    L = [0]*(n+1)
    for i in range(1, n):
        L[i] = random.randint(1, 7)
    queries = []
    for _ in range(10):
        a = random.randint(1, n)
        h = random.randint(0, 30)
        queries.append((a, h))
    return n, len(queries), L, queries

def cross_check():
    # Bring in solvers from above blocks if running standalone.
    from typing import List, Tuple
    def build_adj(n: int, L: List[int]):
        adj = [[] for _ in range(n+1)]
        for i in range(1, n):
            u = (i+1)//2
            v = i+1
            w = L[i]
            adj[u].append((v, w))
            adj[v].append((u, w))
        return adj

    import heapq
    def baseline(n: int, m: int, L: List[int], queries: List[Tuple[int,int]]):
        adj = build_adj(n, L)
        ans = []
        for (A, H) in queries:
            INF = 10**30
            dist = [INF]*(n+1)
            dist[A] = 0
            pq = [(0, A)]
            while pq:
                d, u = heapq.heappop(pq)
                if d != dist[u]: continue
                if d > H: continue
                for v, w in adj[u]:
                    nd = d + w
                    if nd < dist[v] and nd <= H:
                        dist[v] = nd
                        heapq.heappush(pq, (nd, v))
            total = 0
            for v in range(1, n+1):
                if dist[v] <= H:
                    total += H - dist[v]
            ans.append(total)
        return ans

    def improved(n: int, m: int, L: List[int], queries: List[Tuple[int,int]]):
        parent = [0]*(n+1)
        w_to_parent = [0]*(n+1)
        childL = [0]*(n+1); childR = [0]*(n+1)
        wL = [0]*(n+1); wR = [0]*(n+1)
        for i in range(1, n):
            p = (i+1)//2; v = i+1; w = L[i]
            parent[v]=p; w_to_parent[v]=w
            if childL[p]==0: childL[p]=v; wL[p]=w
            else: childR[p]=v; wR[p]=w
        import bisect
        def merge(a, b):
            if len(a)<len(b): a,b=b,a
            i=j=0; out=[]
            while i<len(a) and j<len(b):
                if a[i]<=b[j]: out.append(a[i]); i+=1
                else: out.append(b[j]); j+=1
            if i<len(a): out.extend(a[i:])
            if j<len(b): out.extend(b[j:])
            return out
        D=[None]*(n+1); P=[None]*(n+1)
        for u in range(n, 0, -1):
            base=[0]
            if childL[u]:
                cl=childL[u]
                shifted=[x+wL[u] for x in D[cl]]
                base=merge(base, shifted)
            if childR[u]:
                cr=childR[u]
                shifted=[x+wR[u] for x in D[cr]]
                base=merge(base, shifted)
            D[u]=base
            s=0; ps=[]
            for x in base:
                s+=x; ps.append(s)
            P[u]=ps
        def sub(u,H):
            if H<0: return 0
            k=bisect.bisect_right(D[u], H)
            return 0 if k<=0 else k*H - P[u][k-1]
        ans=[]
        for (A,H) in queries:
            total=sub(A,H)
            curr=A; dist_up=0
            while parent[curr]!=0:
                p=parent[curr]; dist_up+=w_to_parent[curr]
                r=H-dist_up
                if r<0: break
                total+=r
                if childL[p]==curr: sib=childR[p]; ws=wR[p]
                else: sib=childL[p]; ws=wL[p]
                if sib: total+=sub(sib, r-ws)
                curr=p
            ans.append(total)
        return ans

    for seed in range(10):
        n, m, L, Q = gen_small_case(n=15, seed=seed)
        b = baseline(n, m, L, Q)
        i = improved(n, m, L, Q)
        assert b == i

if __name__ == "__main__":
    cross_check()
\end{minted}
\textbf{Reference Code (Ready to Submit)}
\begin{minted}{python}
import sys
import bisect
from typing import List, Tuple

def read_input(data: List[str] = None):
    if data is None:
        data = sys.stdin.read().strip().split()
        if not data:
            return None
    it = iter(data)
    n = int(next(it)); m = int(next(it))
    L = [0]*(n+1)
    for i in range(1, n):
        L[i] = int(next(it))
    queries = []
    for _ in range(m):
        a = int(next(it)); h = int(next(it))
        queries.append((a, h))
    return n, m, L, queries

def build_tree(n: int, L: List[int]):
    parent = [0]*(n+1)
    w_to_parent = [0]*(n+1)
    childL = [0]*(n+1)
    childR = [0]*(n+1)
    wL = [0]*(n+1)
    wR = [0]*(n+1)
    for i in range(1, n):
        p = (i+1)//2
        v = i+1
        w = L[i]
        parent[v] = p
        w_to_parent[v] = w
        if childL[p] == 0:
            childL[p] = v; wL[p] = w
        else:
            childR[p] = v; wR[p] = w
    return parent, w_to_parent, childL, childR, wL, wR

def merge_sorted(a: List[int], b: List[int]) -> List[int]:
    if len(a) < len(b):
        a, b = b, a
    i = j = 0
    out = []
    out_extend = out.extend
    while i < len(a) and j < len(b):
        if a[i] <= b[j]:
            out.append(a[i]); i += 1
        else:
            out.append(b[j]); j += 1
    if i < len(a): out_extend(a[i:])
    if j < len(b): out_extend(b[j:])
    return out

def build_DP(n: int, childL: List[int], childR: List[int], wL: List[int], wR: List[int]):
    D = [None]*(n+1)
    P = [None]*(n+1)
    for u in range(n, 0, -1):
        base = [0]
        if childL[u]:
            cl = childL[u]
            shifted = [x + wL[u] for x in D[cl]]
            base = merge_sorted(base, shifted)
        if childR[u]:
            cr = childR[u]
            shifted = [x + wR[u] for x in D[cr]]
            base = merge_sorted(base, shifted)
        D[u] = base
        s = 0
        ps = [0]*len(base)
        for i, val in enumerate(base):
            s += val
            ps[i] = s
        P[u] = ps
    return D, P

def sum_subtree(D: List[List[int]], P: List[List[int]], u: int, H: int) -> int:
    if H < 0:
        return 0
    vec = D[u]
    k = bisect.bisect_right(vec, H)
    if k <= 0:
        return 0
    return k*H - P[u][k-1]

def solve_all(n: int, m: int, L: List[int], queries: List[Tuple[int,int]]) -> List[int]:
    parent, w_to_parent, childL, childR, wL, wR = build_tree(n, L)
    D, P = build_DP(n, childL, childR, wL, wR)
    res = []
    for (A, H) in queries:
        total = sum_subtree(D, P, A, H)
        curr = A
        dist_up = 0
        while parent[curr] != 0:
            p = parent[curr]
            dist_up += w_to_parent[curr]
            r = H - dist_up
            if r < 0:
                break
            total += r
            if childL[p] == curr:
                sib = childR[p]; ws = wR[p]
            else:
                sib = childL[p]; ws = wL[p]
            if sib != 0:
                total += sum_subtree(D, P, sib, r - ws)
            curr = p
        res.append(total)
    return res

def _tests():
    # Three deterministic asserts
    n = 6
    L = [0, 2, 1, 1, 3, 2]
    assert solve_all(n, 1, L, [(2, 4)]) == [11]
    n = 3
    L = [0, 1, 2]
    assert solve_all(n, 2, L, [(2, 2), (1, 0)]) == [3, 0]
    n = 1
    L = [0]
    assert solve_all(n, 1, L, [(1, 7)]) == [7]

def main():
    data = sys.stdin.read().strip().split()
    if not data:
        _tests()
        return
    n, m, L, queries = read_input(data)
    ans = solve_all(n, m, L, queries)
    print("\n".join(str(x) for x in ans))

if __name__ == "__main__":
    _tests()
    if not sys.stdin.isatty():
        sys.stdin.seek(0)
    main()
\end{minted}
\NotePages{3}

% ============ 8. Review & Pitfalls (own page) ============
\section{Review \& Pitfalls}
\WHAT{Sum $\max(0,H - \operatorname{dist}(A,\cdot))$ over all nodes by combining a fast subtree sum with an ancestor walk that adds ancestor and sibling-subtree contributions.}
\WHY{This pattern appears in tree queries involving distance thresholds and additive contributions, where precomputing distance distributions per subtree enables logarithmic-time queries.}
\CHECKLIST{
\begin{bullets}
\item Build parent/children and edge weights correctly from heap indexing.
\item Bottom-up construct $D_u$ and $P_u$ with shifted merges and include $0$.
\item For each query, add subtree of $A$ with budget $H$.
\item Walk up: update remaining budget $r$, add $r$ for ancestor node, then add sibling subtree with $r - w_{\text{to-sib}}$.
\item Stop when $r<0$.
\end{bullets}
}
\EDGECASES{
\begin{bullets}
\item $n=1$: only node contributes $\max(0,H)$.
\item $H=0$: only nodes at zero distance (the start node and possibly none else) contribute $0$.
\item Missing left/right child: sibling may be absent; skip gracefully.
\item Large $H$: all nodes contribute; ensure no overflow by using 64-bit integers.
\item Deep node near $n$: short ancestor chain; verify indexing at boundary $2u>n$.
\item Nonuniform weights: ensure binary searches use distances, not depths.
\item Start at root $A=1$: no ancestors to add.
\item Start at a leaf: handle both sibling and ancestor node adds.
\end{bullets}
}
\PITFALLS{
\begin{bullets}
\item Forgetting to include $0$ distance for the node itself in $D_u$.
\item Double-counting nodes when ascending; only include sibling subtrees and the ancestor node, not the path-child subtree again.
\item Off-by-one in binary search: use $\texttt{bisect\_right}$ for $\le H$.
\item Incorrect shift: must add the edge weight from parent to child to all child distances before merging.
\item Memory blow-up: ensure small-to-large merging to reduce allocations and keep performance acceptable.
\item Overflow in languages with 32-bit int; use 64-bit accumulator for sums.
\item Misbuilding heap tree: the $i$-th road connects $\left\lfloor \tfrac{i+1}{2} \right\rfloor$ with $(i+1)$, not $i$.
\item Early stop condition when ascending: break when remaining budget turns negative.
\end{bullets}
}
\FAILMODES{Brute force Dijkstra per query will time out for large $n,m$. Precomputing only depths or counts (without distances) cannot measure weighted distances. Incorrect ancestor decomposition leads to double counts or missed nodes.}
\ELI{Precompute, for each node, how far it is to every node below it and keep those distances sorted. For a query, count easy wins in the starting subtree, then move up to the root, adding the ancestor itself and everything in the other branch if the remaining budget allows.}
\NotePages{3}

\end{document}