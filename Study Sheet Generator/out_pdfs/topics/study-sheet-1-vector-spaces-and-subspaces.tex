% !TeX program = xelatex
\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{microtype,setspace,amsmath,amssymb,mathtools,amsthm,unicode-math}
\setstretch{1.05}
\setmainfont{Latin Modern Roman}
\setmonofont{Latin Modern Mono}
\setmathfont{Latin Modern Math}

\allowdisplaybreaks[4]
\setlength{\jot}{7pt}
\setlength{\emergencystretch}{8em}
\sloppy

\usepackage{xcolor,fancyhdr,enumitem,inconsolata,listings}
\pagestyle{fancy}\fancyhf{}\lhead{\nouppercase{\leftmark}}\rhead{\thepage}
\setlength{\headheight}{26pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt plus 2pt minus 1pt}
\raggedbottom

\newenvironment{BreakableEquation}{\begin{equation}\begin{aligned}}{\end{aligned}\end{equation}}
\newenvironment{BreakableEquation*}{\begin{equation*}\begin{aligned}}{\end{aligned}\end{equation*}}
\newenvironment{tightalign}{\begingroup\small\allowdisplaybreaks\begin{align}}{\end{align}\endgroup}

\providecommand{\enumlistm}{enumitem}
\newenvironment{minted}[2][]{%
  \lstset{style=code,language=#2,#1}\begin{lstlisting}%
}{\end{lstlisting}}

\newcommand{\inputminted}[3][]{\begin{lstlisting}\end{lstlisting}}

\newlist{bullets}{itemize}{1}
\setlist[bullets]{label=--,leftmargin=1.6em,itemsep=2pt,topsep=4pt}

\newcommand{\varmapStart}{\textbf{VARIABLE MAPPING:}\par\begin{bullets}}
\newcommand{\var}[2]{\item $#1$ — #2}
\newcommand{\varmapEnd}{\end{bullets}}

\newcommand{\glossx}[6]{%
  \textbf{#1}\par
  \begin{bullets}
    \item \textbf{What:} #2
    \item \textbf{Why:} #3
    \item \textbf{How:} #4
    \item \textbf{ELI5:} #5
    \item \textbf{Pitfall/Example:} #6
  \end{bullets}
}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}

\lstdefinestyle{code}{
  basicstyle=\ttfamily\footnotesize,
  backgroundcolor=\color{black!02},
  frame=single,
  numbers=left, numberstyle=\tiny, numbersep=8pt,
  breaklines=true, breakatwhitespace=true,
  tabsize=4, showstringspaces=false,
  upquote=true, keepspaces=true, columns=fullflexible,
  literate=
    {–}{{-}}1
    {—}{{-}}1
    {…}{{...}}1
    {≤}{{\ensuremath{\le}}}1
    {≥}{{\ensuremath{\ge}}}1
    {≠}{{\ensuremath{\ne}}}1
    {≈}{{\ensuremath{\approx}}}1
    {±}{{\ensuremath{\pm}}}1
    {→}{{\ensuremath{\to}}}1
    {←}{{\ensuremath{\leftarrow}}}1
    {∞}{{\ensuremath{\infty}}}1
    {√}{{\ensuremath{\sqrt{\ }}}}1
    {×}{{\ensuremath{\times}}}1
    {÷}{{\ensuremath{\div}}}1
}

\lstnewenvironment{codepy}[1][]%
  {\lstset{style=code,language=Python,#1}}%
  {}

\newcommand{\inlinecode}[1]{\lstinline[style=code]!#1!}

\newcommand{\LF}[2]{\par\noindent\textbf{#1:}~#2\par}
\newcommand{\WHAT}[1]{\LF{WHAT}{#1}}
\newcommand{\WHY}[1]{\LF{WHY}{#1}}
\newcommand{\HOW}[1]{\LF{HOW}{#1}}
\newcommand{\ELI}[1]{\LF{ELI5}{#1}}
\newcommand{\SCOPE}[1]{\LF{SCOPE}{#1}}
\newcommand{\CONFUSIONS}[1]{\LF{COMMON CONFUSIONS}{#1}}
\newcommand{\APPLICATIONS}[1]{\LF{APPLICATIONS}{#1}}
\newcommand{\FORMULA}[1]{\LF{FORMULA}{#1}}
\newcommand{\CANONICAL}[1]{\LF{CANONICAL FORM}{#1}}
\newcommand{\PRECONDS}[1]{\LF{PRECONDITIONS}{#1}}
\newcommand{\DERIVATION}[1]{\LF{DERIVATION}{#1}}
\newcommand{\EQUIV}[1]{\LF{EQUIVALENT FORMS}{#1}}
\newcommand{\LIMITS}[1]{\LF{LIMIT CASES}{#1}}
\newcommand{\INPUTS}[1]{\LF{INPUTS}{#1}}
\newcommand{\OUTPUTS}[1]{\LF{OUTPUTS}{#1}}
\newcommand{\RESULT}[1]{\LF{RESULT}{#1}}
\newcommand{\INTUITION}[1]{\LF{INTUITION}{#1}}
\newcommand{\PITFALLS}[1]{\LF{PITFALLS}{#1}}
\newcommand{\MODEL}[1]{\LF{CANONICAL MATH MODEL}{#1}}
\newcommand{\ASSUMPTIONS}[1]{\LF{ASSUMPTIONS}{#1}}
\newcommand{\WHICHFORMULA}[1]{\LF{WHICH FORMULA \& WHY}{#1}}
\newcommand{\GOVERN}[1]{\LF{GOVERNING EQUATION(S)}{#1}}
\newcommand{\UNITCHECK}[1]{\LF{UNIT CHECK}{#1}}
\newcommand{\EDGECASES}[1]{\LF{EDGE CASES}{#1}}
\newcommand{\ALTERNATE}[1]{\LF{ALTERNATE APPROACH (sketch)}{#1}}
\newcommand{\PROBLEM}[1]{\LF{PROBLEM}{#1}}
\newcommand{\API}[1]{\LF{API}{#1}}
\newcommand{\COMPLEXITY}[1]{\LF{COMPLEXITY}{#1}}
\newcommand{\FAILMODES}[1]{\LF{FAILURE MODES}{#1}}
\newcommand{\STABILITY}[1]{\LF{NUMERICAL STABILITY}{#1}}
\newcommand{\VALIDATION}[1]{\LF{VALIDATION}{#1}}
\newcommand{\EXPLANATION}[1]{\LF{EXPLANATION}{#1}}
\newcommand{\SCENARIO}[1]{\LF{SCENARIO}{#1}}
\newcommand{\PIPELINE}[1]{\LF{PIPELINE STEPS}{#1}}
\newcommand{\METRICS}[1]{\LF{METRICS}{#1}}
\newcommand{\INTERPRET}[1]{\LF{INTERPRETATION}{#1}}
\newcommand{\NEXTSTEPS}[1]{\LF{LIMITATIONS \& NEXT STEPS}{#1}}

\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries}{\thesection}{0.6em}{}
\titlespacing*{\section}{0pt}{*2}{*1}
\usepackage{etoolbox}
\pretocmd{\section}{\clearpage}{}{}

\newcommand{\FormulaPage}[2]{%
  \clearpage
  \section*{Formula #1 — #2}%
  \addcontentsline{toc}{section}{Formula #1 — #2}%
}
\newcommand{\ProblemPage}[2]{%
  \clearpage
  \subsection*{Problem #1: #2}%
  \addcontentsline{toc}{subsection}{Problem #1: #2}%
}
\newcommand{\CodeDemoPage}[1]{%
  \clearpage
  \subsection*{Coding Demo: #1}%
  \addcontentsline{toc}{subsection}{Coding Demo: #1}%
}
\newcommand{\DomainPage}[1]{%
  \clearpage
  \subsection*{#1 (End-to-End)}%
  \addcontentsline{toc}{subsection}{#1 (End-to-End)}%
}

\begin{document}
\title{Comprehensive Study Sheet — Vector Spaces and Subspaces}
\date{\today}
\maketitle
\tableofcontents
\clearpage

\section{Concept Overview}

\WHAT{
A vector space $(V,+,\cdot)$ over a field $\mathbb{F}$ is a set $V$ with
addition $+ : V \times V \to V$ and scalar multiplication
$\cdot : \mathbb{F} \times V \to V$ satisfying the $8$ axioms:
associativity, commutativity of $+$, additive identity $0$, additive
inverse, distributivity of scalar over vector addition and field
addition, compatibility $(ab)v=a(bv)$, and $1v=v$.
A subspace $W\subseteq V$ is a nonempty subset closed under $+$ and
scalar multiplication, hence itself a vector space under the inherited
operations. The span $\mathrm{span}(S)$ of $S\subseteq V$ is the set of
all finite linear combinations of elements of $S$.
A set is linearly independent if the only linear combination equaling
$0$ has all coefficients $0$. A basis is a linearly independent spanning
set. The dimension is the cardinality of a basis (finite case).
}

\WHY{
Vector spaces are the ambient structures for linear phenomena: solutions
of homogeneous linear systems, polynomial spaces, function spaces, and
state spaces. Subspaces model constraints and invariants.
Basis and dimension turn infinite possibilities into finite coordinates,
enabling computation and classification. The span and subspace tests give
constructive ways to detect linear structure.
}

\HOW{
1. Specify the field $\mathbb{F}$, operations on $V$, and verify axioms.
2. To certify a subset $W$ is a subspace, use the subspace criterion
that it is closed under linear combinations.
3. Construct spans via linear combinations and compress them to a basis
by eliminating dependencies.
4. Use bases to define coordinates and compute dimensions, and apply the
dimension identity for sums and intersections of subspaces.
}

\ELI{
Think of vectors as arrows or lists you can add and stretch. A vector
space is any collection where adding arrows and stretching by numbers
stays inside. A subspace is a flat slice through the origin. The span of
some arrows is all places you can reach by adding and stretching them.
A basis is the smallest set of arrows that can reach everything uniquely.
}

\SCOPE{
Fields $\mathbb{R}$ and $\mathbb{C}$ are most common, but any field is
allowed. Many results here assume finite dimension; infinite-dimensional
spaces need care (e.g., bases may be infinite and require choice).
Nonlinear sets or affine sets not through the origin are not subspaces.
}

\CONFUSIONS{
Do not confuse a subset with a subspace; closure and origin are required.
Linear independence is about the zero combination, not geometry alone.
A basis is not unique, but its size (dimension) is. Affine hull is not
the same as span unless it contains the origin. Sum $U+V$ is not a
direct sum unless $U\cap V=\{0\}$.
}

\APPLICATIONS{
\begin{bullets}
\item Mathematical foundations: linear systems, polynomials, function spaces.
\item Computational modeling: state spaces and constraint subspaces.
\item Engineering: modes, signals, and control subspaces.
\item Statistics and algorithms: feature spaces and column spaces.
\end{bullets}
}

\textbf{ANALYTIC STRUCTURE.}
Vector spaces are linear and homogeneous. Subspaces are convex cones
that are closed under additive inverses. The sum $U+V$ is linear; the
intersection $U\cap V$ is linear. Finite-dimensional spaces are
isomorphic to $\mathbb{F}^n$.

\textbf{CANONICAL LINKS.}
Span minimality, subspace criterion, basis equivalences, and the
dimension formula $\dim(U+V)=\dim U+\dim V-\dim(U\cap V)$ interlock.
Coordinates relative to a basis provide an isomorphism to $\mathbb{F}^n$.

\textbf{PROBLEM-TYPE RECOGNITION HEURISTICS.}
\begin{bullets}
\item Phrases like ``set of solutions of homogeneous equations'' signal a subspace.
\item Words ``span,'' ``linear combination'' indicate generator reduction to basis.
\item ``Unique coordinates'' implies a basis; check linear independence and spanning.
\item ``Dimensions of sum and intersection'' trigger the dimension formula.
\end{bullets}

\textbf{SOLUTION STRATEGY BLUEPRINT.}
\begin{bullets}
\item Translate constraints into linear equations or generators.
\item Apply the subspace test or build the span.
\item Row-reduce to find bases and dimensions.
\item Use coordinate maps to express vectors and check uniqueness.
\end{bullets}

\textbf{CONCEPTUAL INVARIANTS.}
Dimension, linear dependence relations, and isomorphism class to
$\mathbb{F}^n$ for finite-dimensional spaces.

\textbf{EDGE INTUITION.}
In the trivial cases $V=\{0\}$ or $S=\varnothing$, spans collapse to
$\{0\}$. If $U$ and $V$ overlap heavily, $U+V$ grows slowly; if they
intersect trivially, $U\oplus V$ has dimension additivity.

\section{Glossary}

\glossx{Vector Space}
{A set with vector addition and scalar multiplication over a field
satisfying the linear axioms.}
{Unifies linear systems, polynomials, and functions under one structure.}
{Verify closure and axioms; then use bases to coordinate vectors.}
{Like a perfectly flat, stretchable sheet passing through the origin.}
{Not every subset is a subspace; lines not through the origin fail.}

\glossx{Subspace}
{A nonempty subset closed under addition and scalar multiplication.}
{Encodes constraints and invariants as linear sets preserved by linear
operations.}
{Use the subspace test: closure under $a u+b v$ for all $u,v$ and scalars
$a,b$.}
{A flat slice through the origin within a bigger flat space.}
{Forgetting the origin: affine lines offset from $0$ are not subspaces.}

\glossx{Span}
{All finite linear combinations of a subset $S\subseteq V$.}
{Constructs the smallest subspace containing a set of generators.}
{Form linear combinations; row-reduce to compress to a basis.}
{All places you can get to by adding and stretching the given arrows.}
{Infinite coefficients are not allowed; only finite sums define span.}

\glossx{Basis and Dimension}
{A basis is a linearly independent spanning set; dimension is its size.}
{Gives unique coordinates and classifies finite-dimensional spaces.}
{Prove LI and spanning; then coordinate via expansion in the basis.}
{A minimal set of arrows to build every arrow exactly one way.}
{A spanning set may be redundant; a basis must be both spanning and LI.}

\section{Symbol Ledger}
\varmapStart
\var{V}{Vector space over field $\mathbb{F}$.}
\var{\mathbb{F}}{Base field (e.g., $\mathbb{R}$ or $\mathbb{C}$).}
\var{U,W}{Subspaces of $V$.}
\var{S}{Subset of $V$ used as generators.}
\var{\mathrm{span}(S)}{Span of $S$, the subspace of all finite linear combinations.}
\var{\dim V}{Dimension of $V$ (finite case).}
\var{v_1,\dots,v_n}{Vectors in $V$.}
\var{a_1,\dots,a_n}{Scalars in $\mathbb{F}$.}
\var{B}{An ordered basis $(b_1,\dots,b_n)$ of $V$.}
\var{[v]_B}{Coordinate column vector of $v$ in basis $B$.}
\var{U+V}{Sum $\{u+v: u\in U, v\in V\}$.}
\var{U\cap V}{Intersection subspace.}
\varmapEnd

\section{Formula Canon — One Formula Per Page}

\FormulaPage{1}{Subspace Criterion (Linear Combination Test)}
\WHAT{
Characterizes subspaces by closure under arbitrary linear combinations.}
\WHY{
Provides a minimal, easy-to-check condition to certify a subset is a
subspace without rechecking all axioms.}
\FORMULA{
\[
W\subseteq V \text{ is a subspace } \iff
\left(\exists w_0\in W\ \text{and}\ \forall u,v\in W,\ \forall a,b\in\mathbb{F},
\ a u + b v \in W\right).
\]
}
\CANONICAL{
$V$ is a vector space over $\mathbb{F}$. The subset $W\subseteq V$ is
tested for nonemptiness and closure under $a u + b v$.}
\PRECONDS{
\begin{bullets}
\item $V$ is a vector space over $\mathbb{F}$.
\item $W\subseteq V$ is a subset.
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
If $W\subseteq V$ is nonempty and closed under $a u+b v$ for all
$u,v\in W$ and $a,b\in\mathbb{F}$, then $0\in W$ and $W$ is closed under
addition and scalar multiplication.
\end{lemma}
\begin{proof}
Pick $w_0\in W$. Taking $a=0$, $b=0$, $u=v=w_0$ gives $0u+0v=0\in W$.
For addition, set $a=b=1$ to get $u+v\in W$. For scalar multiplication,
use $b=0$ to get $a u + 0 v = a u\in W$. Thus $W$ inherits the vector
space operations, hence is a subspace. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{Forward ($\Rightarrow$):}\quad
&\text{If $W$ is a subspace, it is closed under $+$ and scalar mult.} \\
&\text{Hence $a u + b v \in W$ for all $u,v\in W$, $a,b\in\mathbb{F}$.}\\
\text{Backward ($\Leftarrow$):}\quad
&\text{Assume $W$ nonempty and closed under $a u+b v$. By the lemma,}\\
&\text{$W$ contains $0$, is closed under $+$ and scalar multiplication.}\\
&\text{Thus $W$ satisfies the subspace axioms (inherited), so is a subspace.}
\end{align*}
}
\EQUIV{
\begin{bullets}
\item Equivalent $2$-condition test: $W\ne\varnothing$, closed under $+$,
and closed under scalar multiplication.
\item Equivalent $1$-condition variant: $0\in W$ and closed under
$u+v$ and $a u$ for $a\in\mathbb{F}$.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item If $W=\varnothing$, it is not a subspace.
\item If closure fails even for one pair of elements or one scalar, $W$
is not a subspace.
\end{bullets}
}
\INPUTS{$V$ vector space over $\mathbb{F}$, subset $W\subseteq V$.}
\RESULT{
$W$ is a subspace exactly when it is nonempty and closed under arbitrary
linear combinations of two elements.}
\PITFALLS{
\begin{bullets}
\item Forgetting to check nonemptiness and the presence of $0$.
\item Verifying only for special scalars (like $a=b=1$) is insufficient.
\end{bullets}
}
\ELI{
If you can add any two of its vectors and stretch them by any numbers
and still never leave the set, and the set is not empty, then it is a
flat space inside the big space.}

\FormulaPage{2}{Span as Smallest Containing Subspace}
\WHAT{
Identifies $\mathrm{span}(S)$ both as all finite linear combinations of
$S$ and as the smallest subspace containing $S$.}
\WHY{
Connects constructive generation (linear combinations) with universal
minimality (intersection) for reasoning and computation.}
\FORMULA{
\[
\mathrm{span}(S)=
\left\{\sum_{i=1}^k a_i s_i:\ k\in\mathbb{N},\ s_i\in S,\ a_i\in\mathbb{F}\right\}
=\bigcap\{W\subseteq V:\ W\text{ subspace and }S\subseteq W\}.
\]
}
\CANONICAL{
$V$ is a vector space over $\mathbb{F}$, $S\subseteq V$ is arbitrary.}
\PRECONDS{
\begin{bullets}
\item Finite linear combinations are taken (no infinite sums).
\item Intersection is over all subspaces containing $S$.
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
The intersection of any nonempty family of subspaces of $V$ is a
subspace of $V$.
\end{lemma}
\begin{proof}
Let $\{W_\alpha\}_{\alpha\in A}$ be subspaces. If the family is nonempty,
$0\in W_\alpha$ for all $\alpha$, so $0$ lies in the intersection.
Closure: for $u,v$ in the intersection and $a,b\in\mathbb{F}$, we have
$u,v\in W_\alpha$ for each $\alpha$, hence $a u + b v\in W_\alpha$ for
each $\alpha$. Thus $a u + b v$ lies in the intersection. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{Define } T
&=\left\{\sum_{i=1}^k a_i s_i:\ k\in\mathbb{N},\ s_i\in S,\ a_i\in\mathbb{F}\right\}.\\
\text{(1) $T$ is a subspace: }&
0\in T\ (\text{take }k=1,a_1=0),\ \text{and $T$ is closed under $a u+b v$.}\\
\text{(2) Minimality: }&S\subseteq T\ \text{by taking $k=1$, so any subspace
$W$ containing $S$}\\
&\text{contains all linear combinations of $S$, hence $T\subseteq W$.}\\
\text{(3) Intersection form: }&
\bigcap\{W:\ S\subseteq W\}\ \text{is a subspace by the lemma and is the}\\
&\text{largest lower bound of such $W$; minimality gives equality with $T$.}
\end{align*}
}
\EQUIV{
\begin{bullets}
\item If $S=\{v_1,\dots,v_m\}$, then $\mathrm{span}(S)=\{A c:\ c\in\mathbb{F}^m\}$
where $A=[v_1\ \cdots\ v_m]$.
\item If $S=\varnothing$, then $\mathrm{span}(S)=\{0\}$.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Infinite combinations are outside the span unless topology adds limits.
\item If $S$ already spans $V$, the intersection equals $V$.
\end{bullets}
}
\INPUTS{$V$ vector space over $\mathbb{F}$, $S\subseteq V$.}
\RESULT{
$\mathrm{span}(S)$ is the subspace of all finite linear combinations and
is the smallest subspace containing $S$.}
\PITFALLS{
\begin{bullets}
\item Mistaking infinite sums as allowed; span uses finite sums only.
\item Forgetting that the empty set spans $\{0\}$.
\end{bullets}
}
\ELI{
Start with a handful of building blocks; span is everything you can
assemble using add and stretch, and nothing more. The intersection view
says it is the tightest flat that contains your blocks.}

\FormulaPage{3}{Basis Characterizations}
\WHAT{
Equivalences between spanning, linear independence, minimal spanning,
maximal independence, and uniqueness of coordinates.}
\WHY{
These characterizations allow flexible proofs and practical tests for
bases and coordinate uniqueness in finite dimension.}
\FORMULA{
\[
\text{For finite-dimensional }V,\ \ B\subseteq V\ \text{is a basis}\iff
\begin{cases}
\text{$B$ spans $V$ and is linearly independent},\\
\text{$B$ is a minimal spanning set},\\
\text{$B$ is a maximal linearly independent set}.
\end{cases}
\]
}
\CANONICAL{
$V$ is finite-dimensional over $\mathbb{F}$.}
\PRECONDS{
\begin{bullets}
\item Finite-dimensionality ensures that maximal LI and minimal spanning
sets exist and coincide with bases.
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
If $B$ is a linearly independent spanning set, then every $v\in V$ has a
unique representation as a linear combination of elements of $B$.
\end{lemma}
\begin{proof}
Existence holds since $B$ spans. For uniqueness, suppose
$\sum a_i b_i=\sum c_i b_i$. Then $\sum (a_i-c_i)b_i=0$, and linear
independence implies $a_i=c_i$ for all $i$. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{(1) Basis $\Rightarrow$ LI + Span: }&\text{Definition.}\\
\text{(2) LI + Span $\Rightarrow$ minimal spanning: }&
\text{If a vector is removed, spanning fails; else it was dependent.}\\
\text{(3) LI + Span $\Rightarrow$ maximal LI: }&
\text{Adding any new vector yields dependence since $B$ already spans.}\\
\text{(4) Minimal spanning $\Rightarrow$ LI: }&
\text{A dependence would allow removal without losing span.}\\
\text{(5) Maximal LI $\Rightarrow$ spanning: }&
\text{If not spanning, add a missing vector to contradict maximality.}
\end{align*}
}
\EQUIV{
\begin{bullets}
\item Uniqueness of coordinates: the coordinate map $[\,\cdot\,]_B$ is well-defined.
\item Any two bases of $V$ have the same finite cardinality (dimension).
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item In infinite-dimensional spaces, Zorn's lemma may be needed for
existence of a basis; minimal spanning and maximal LI require care.
\end{bullets}
}
\INPUTS{$V$ finite-dimensional, candidate set $B=\{b_1,\dots,b_n\}\subseteq V$.}
\RESULT{
$B$ is a basis iff it is LI and spanning; equivalently minimal spanning
or maximal LI; coordinates are unique.}
\PITFALLS{
\begin{bullets}
\item Proving spanning but not checking independence (or vice versa).
\item Assuming coordinates are unique without establishing independence.
\end{bullets}
}
\ELI{
A basis is a perfectly nonredundant toolkit that can build everything,
and no tool can be removed or added without breaking that perfection.}

\FormulaPage{4}{Dimension of a Sum of Subspaces}
\WHAT{
Gives the dimension of the sum $U+V$ in terms of dimensions of $U$, $V$,
and their intersection.}
\WHY{
Avoids double-counting shared directions and is essential for computing
dimensions of combined constraints or generators.}
\FORMULA{
\[
\dim(U+V)=\dim U+\dim V-\dim(U\cap V).
\]
}
\CANONICAL{
$U,V$ are subspaces of a finite-dimensional vector space $V_0$.}
\PRECONDS{
\begin{bullets}
\item $\dim U,\dim V<\infty$ (then $\dim(U+V)<\infty$).
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
If $\{w_1,\dots,w_k\}$ is a basis of $U\cap V$, it extends to bases
$\{w_1,\dots,w_k,u_{k+1},\dots,u_m\}$ of $U$ and
$\{w_1,\dots,w_k,v_{k+1},\dots,v_n\}$ of $V$.
\end{lemma}
\begin{proof}
Extend a basis of $U\cap V$ to $U$ and $V$ by adding independent vectors
from each space; this is possible in finite dimension. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
&\text{Let }W=\{w_1,\dots,w_k\}\text{ basis of }U\cap V.\\
&\text{Extend to bases }U:\ W\cup U' \text{ and } V:\ W\cup V'.\\
&\text{Claim: }W\cup U'\cup V'\text{ spans }U+V.\\
&\text{Any }x\in U+V\text{ can be written }x=u+v, u\in U, v\in V.\\
&u = \sum \alpha_i w_i + \sum \beta_j u'_j,\quad
v = \sum \gamma_i w_i + \sum \delta_\ell v'_\ell.\\
&x = \sum (\alpha_i+\gamma_i) w_i + \sum \beta_j u'_j + \sum \delta_\ell v'_\ell.\\
&\text{Independence: } W,U',V' \text{ are collectively independent.}\\
&\text{Suppose } \sum a_i w_i + \sum b_j u'_j + \sum c_\ell v'_\ell = 0.\\
&\text{Group } (\sum a_i w_i + \sum b_j u'_j) = - \sum c_\ell v'_\ell
\in U\cap V.\\
&\text{Express both sides in basis }W\text{ to get }b_j=0,\ c_\ell=0,\
a_i=0.\\
&\text{Thus }W\cup U'\cup V'\text{ is a basis of }U+V.\\
&\Rightarrow \dim(U+V)=k+|U'|+|V'|=(k+(m-k))+(k+(n-k))-k=m+n-k.\\
&\text{Since }m=\dim U,\ n=\dim V,\ k=\dim(U\cap V),\ \text{formula follows.}
\end{align*}
}
\EQUIV{
\begin{bullets}
\item If $U\cap V=\{0\}$, then $\dim(U\oplus V)=\dim U+\dim V$.
\item For generators $A,B$, $\dim\mathrm{span}([A\ B])=\dim U+\dim V-\dim(U\cap V)$.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Requires finite dimensions; in infinite dimension, cardinal arithmetic
is subtler.
\end{bullets}
}
\INPUTS{$U,V\le V_0$ finite-dimensional subspaces.}
\RESULT{
The dimension of the sum is the sum of dimensions minus the overlap
dimension.}
\PITFALLS{
\begin{bullets}
\item Double-counting the intersection directions.
\item Assuming additivity without checking directness.
\end{bullets}
}
\ELI{
Add the counts of directions from each subspace and subtract the ones
you counted twice because they are shared.}

\FormulaPage{5}{Coordinate Isomorphism w.r.t. a Basis}
\WHAT{
Associates each $v\in V$ with a unique coordinate vector $[v]_B\in
\mathbb{F}^n$ via a basis $B$, yielding an isomorphism.}
\WHY{
Reduces abstract linear problems to concrete computations in
$\mathbb{F}^n$ with matrix algebra.}
\FORMULA{
\[
\phi_B:\mathbb{F}^n\to V,\quad \phi_B(c)=\sum_{i=1}^n c_i b_i
\quad\text{is a linear bijection, and}\quad [v]_B=\phi_B^{-1}(v).
\]
}
\CANONICAL{
$V$ finite-dimensional with ordered basis $B=(b_1,\dots,b_n)$.}
\PRECONDS{
\begin{bullets}
\item $B$ is a basis (LI and spanning).
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
If $B$ is a basis of $V$, then every $v\in V$ has a unique coordinate
vector in $\mathbb{F}^n$ relative to $B$.
\end{lemma}
\begin{proof}
Spanning gives existence; independence gives uniqueness, as in the
coordinate uniqueness lemma above. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
&\text{Linearity: }\phi_B(\alpha c+\beta d)=\sum (\alpha c_i+\beta d_i)b_i\\
&=\alpha \sum c_i b_i+\beta \sum d_i b_i=\alpha \phi_B(c)+\beta \phi_B(d).\\
&\text{Injective: }\phi_B(c)=0\Rightarrow \sum c_i b_i=0\Rightarrow
c_i=0\ \forall i.\\
&\text{Surjective: }\text{For any }v,\ \exists c \text{ with }v=\sum c_i b_i.\\
&\text{Hence }\phi_B \text{ is a linear bijection; }[v]_B=\phi_B^{-1}(v).
\end{align*}
}
\EQUIV{
\begin{bullets}
\item Matrix form: If $B=[b_1\ \cdots\ b_n]$, then $v=B c$ and $[v]_B=c$.
\item Change of basis: $[v]_{B'}=P_{B\to B'}[v]_B$ for an invertible matrix
$P_{B\to B'}$.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Requires a chosen ordered basis; coordinates depend on this choice.
\end{bullets}
}
\INPUTS{$B$ an ordered basis of $V$, $v\in V$, $c\in\mathbb{F}^n$.}
\RESULT{
$\phi_B$ is an isomorphism $\,\mathbb{F}^n\simeq V$; $[v]_B$ are the
unique coordinates of $v$ in basis $B$.}
\PITFALLS{
\begin{bullets}
\item Mixing bases when writing coordinates.
\item Assuming coordinates are intrinsic without fixing a basis.
\end{bullets}
}
\ELI{
Pick $n$ reference arrows; any arrow is a recipe of $n$ ingredients
(coefficients). The coordinate map reads or writes the recipe uniquely.}

\section{10 Exhaustive Problems and Solutions}

\ProblemPage{1}{Solution Space of a Homogeneous System is a Subspace}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
The solution set to $A x=0$ in $\mathbb{F}^n$ is a subspace; find a
basis and dimension for a concrete $A$.
\PROBLEM{
Given $A=\begin{bmatrix}1&2&-1\\2&4&0\end{bmatrix}$ over $\mathbb{R}$,
show $N(A)=\{x\in\mathbb{R}^3:Ax=0\}$ is a subspace and compute a basis
and its dimension.}
\MODEL{
\[
N(A)=\{x\in\mathbb{R}^3:Ax=0\},\quad A\in\mathbb{R}^{2\times 3}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard vector space structure on $\mathbb{R}^3$.
\item Real field $\mathbb{R}$.
\end{bullets}
}
\varmapStart
\var{A}{$2\times 3$ matrix of coefficients.}
\var{x}{Unknown vector in $\mathbb{R}^3$.}
\var{N(A)}{Null space (solution space) of $Ax=0$.}
\varmapEnd
\WHICHFORMULA{
Use the subspace criterion and span concept from the Formula Canon.}
\GOVERN{
\[
Ax=0\ \Rightarrow\ N(A)\text{ is closed under }a u+b v,\ \text{hence a subspace.}
\]
}
\INPUTS{$A=\begin{bmatrix}1&2&-1\\2&4&0\end{bmatrix}$.}
\DERIVATION{
\begin{align*}
&\text{Row-reduce }A:\\
\begin{bmatrix}1&2&-1\\2&4&0\end{bmatrix}
&\xrightarrow{R_2\gets R_2-2R_1}
\begin{bmatrix}1&2&-1\\0&0&2\end{bmatrix}.\\
&\text{Solve }x_1+2x_2-x_3=0,\ 2x_3=0\Rightarrow x_3=0,\ x_1=-2x_2.\\
&\text{Parametrize }x=(-2t, t, 0)=t(-2,1,0).\\
&\Rightarrow N(A)=\mathrm{span}\{(-2,1,0)\},\ \dim N(A)=1.\\
&\text{Subspace: }u,v\in N(A)\Rightarrow Au=Av=0,\ A(a u+b v)=a Au+b Av=0.
\end{align*}
}
\RESULT{
$N(A)$ is a subspace with basis $\{(-2,1,0)\}$ and dimension $1$.}
\UNITCHECK{
Linear closure verified; dimension consistent with rank $2$ of $A$.}
\EDGECASES{
\begin{bullets}
\item If $A=0$, then $N(A)=\mathbb{R}^3$.
\item If $A$ has full row rank $2$, nullity is $1$ as computed.
\end{bullets}
}
\ALTERNATE{
Compute RREF and free variables explicitly; the same basis emerges.}
\VALIDATION{
\begin{bullets}
\item Check $A(-2,1,0)^\top=0$.
\item Any $x$ orthogonal to rows of $A$ lies in $N(A)$.
\end{bullets}
}
\INTUITION{
Solutions live in a line through the origin orthogonal to the row space.}
\CANONICAL{
\begin{bullets}
\item $N(A)$ is a subspace by linearity of $A$.
\item Basis from free-variable parametrization.
\end{bullets}
}

\ProblemPage{2}{Spanning and Coordinates in $\mathbb{R}^3$}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Determine whether given vectors span $\mathbb{R}^3$, extract a basis,
and express a vector in coordinates.
\PROBLEM{
Let $v_1=(1,0,1)$, $v_2=(0,1,1)$, $v_3=(1,1,2)$ in $\mathbb{R}^3$.
Do $\{v_1,v_2,v_3\}$ span $\mathbb{R}^3$? If so, express
$w=(2,3,5)$ in the basis $B=(v_1,v_2,v_3)$.}
\MODEL{
\[
B=\{v_1,v_2,v_3\},\quad A=[v_1\ v_2\ v_3]\in\mathbb{R}^{3\times 3}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard vector space structure on $\mathbb{R}^3$.
\end{bullets}
}
\varmapStart
\var{v_i}{Generators in $\mathbb{R}^3$.}
\var{A}{Matrix with columns $v_i$.}
\var{w}{Target vector to coordinate.}
\var{c}{Coordinate vector with $A c=w$.}
\varmapEnd
\WHICHFORMULA{
Use basis characterization and coordinate isomorphism.}
\GOVERN{
\[
\det A\ne 0\ \Leftrightarrow\ B\ \text{is a basis of }\mathbb{R}^3.
\]
}
\INPUTS{$v_1=(1,0,1)$, $v_2=(0,1,1)$, $v_3=(1,1,2)$, $w=(2,3,5)$.}
\DERIVATION{
\begin{align*}
&A=\begin{bmatrix}1&0&1\\0&1&1\\1&1&2\end{bmatrix},\quad
\det A=1(1\cdot 2-1\cdot 1)-0+\ 1(0\cdot 1-1\cdot 1)= (1)-1=0.\\
&\text{So }v_3=v_1+v_2,\ \text{set }B'=(v_1,v_2)\ \text{does not span }\mathbb{R}^3.\\
&\text{But }\{v_1,v_2,v_3\}\text{ span the plane }z=x+y.\\
&\text{Check if }w \in \mathrm{span}\{v_1,v_2\}:\\
&\text{We need }x+y=z\ \text{for }w=(2,3,5):\ 2+3=5\ (\text{true}).\\
&\text{Solve }A c=w\text{ with dependence }v_3=v_1+v_2:\\
&c=(c_1,c_2,c_3),\ \ w=c_1 v_1+c_2 v_2+c_3(v_1+v_2).\\
&\Rightarrow w=(c_1+c_3)v_1+(c_2+c_3)v_2.\\
&\text{Choose }c_3=0\ \text{for uniqueness in }B'=(v_1,v_2).\\
&\text{Solve }[v_1\ v_2]\begin{bmatrix}\alpha\\\beta\end{bmatrix}=w:\\
&\begin{bmatrix}1&0\\0&1\\1&1\end{bmatrix}
\begin{bmatrix}\alpha\\\beta\end{bmatrix}
=\begin{bmatrix}2\\3\\5\end{bmatrix}\Rightarrow \alpha=2,\ \beta=3,\ 2+3=5.\\
&\Rightarrow [w]_{(v_1,v_2)}=(2,3),\ \text{and one coordinate choice in $B$ is }\\
&[w]_B=(2,3,0)\ (\text{nonunique since $B$ is dependent}).
\end{align*}
}
\RESULT{
$\{v_1,v_2,v_3\}$ is dependent and spans the plane $z=x+y$. The vector
$w$ lies in this plane with coordinates $(2,3)$ in the independent pair
$(v_1,v_2)$.}
\UNITCHECK{
Dependence detected via $\det A=0$ and $v_3=v_1+v_2$.}
\EDGECASES{
\begin{bullets}
\item If $w$ did not satisfy $z=x+y$, it would not be representable.
\item Any representation in the dependent triple is nonunique.
\end{bullets}
}
\ALTERNATE{
Row-reduce $A$ to find the dependence and a basis for the span.}
\VALIDATION{
\begin{bullets}
\item Verify $2 v_1+3 v_2=(2,3,5)$.
\end{bullets}
}
\INTUITION{
The three vectors lie on one plane; two suffice to describe $w$.}
\CANONICAL{
\begin{bullets}
\item Spanning set reduction to a basis by removing dependencies.
\item Coordinate uniqueness holds only for a basis.
\end{bullets}
}

\ProblemPage{3}{Dimension of Sum and Intersection in $\mathbb{R}^4$}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Compute $\dim(U+V)$ and a basis for $U\cap V$ for given generators and
verify $\dim(U+V)=\dim U+\dim V-\dim(U\cap V)$.
\PROBLEM{
In $\mathbb{R}^4$, let
$U=\mathrm{span}\{u_1=(1,0,1,0),u_2=(0,1,0,1)\}$ and
$V=\mathrm{span}\{v_1=(1,1,1,1),v_2=(1,-1,1,-1)\}$.
Find bases and dimensions of $U$, $V$, $U+V$, and $U\cap V$.}
\MODEL{
\[
U=\mathrm{span}\{u_1,u_2\},\quad V=\mathrm{span}\{v_1,v_2\}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard vector space structure on $\mathbb{R}^4$.
\end{bullets}
}
\varmapStart
\var{u_i,v_j}{Generators in $\mathbb{R}^4$.}
\var{U,V}{Subspaces of $\mathbb{R}^4$.}
\varmapEnd
\WHICHFORMULA{
Use the dimension formula for sums of subspaces.}
\GOVERN{
\[
\dim(U+V)=\dim U+\dim V-\dim(U\cap V).
\]
}
\INPUTS{$u_1,u_2,v_1,v_2$ as given.}
\DERIVATION{
\begin{align*}
&\dim U=2\ \text{(independent)},\ \dim V=2\ \text{(independent)}.\\
&\text{Compute }U\cap V:\ \text{solve }a u_1+b u_2=c v_1+d v_2.\\
&\text{Left: }(a,b,a,b),\ \text{Right: }(c+d,c-d,c+d,c-d).\\
&\text{Equate: }a=c+d,\ b=c-d,\ a=c+d,\ b=c-d\ (\text{redundant}).\\
&\text{Thus }(a,b)=(c+d,c-d).\\
&\text{Parametrize }c,s\ \text{with }d=s,\ c=t:\\
&(a,b)=(t+s,t-s).\\
&\text{Pick }t=1,s=0\Rightarrow (a,b)=(1,1)\Rightarrow u_1+u_2=(1,1,1,1)=v_1.\\
&\text{Pick }t=0,s=1\Rightarrow (a,b)=(1,-1)\Rightarrow u_1-u_2=(1,-1,1,-1)=v_2.\\
&\Rightarrow U\cap V=\mathrm{span}\{u_1+u_2,\ u_1-u_2\}=\mathrm{span}\{v_1,v_2\}.\\
&\text{But }v_1,v_2\in V\ \text{and also in }U\ \Rightarrow U\cap V=V.\\
&\text{Hence }V\subseteq U,\ \dim(U\cap V)=2,\ U+V=U,\ \dim(U+V)=2.\\
&\text{Check formula: }2=2+2-2.
\end{align*}
}
\RESULT{
$U=\mathrm{span}\{u_1,u_2\}$, $V\subseteq U$, $U\cap V=V$ with basis
$\{v_1,v_2\}$, and $\dim(U+V)=2$.}
\UNITCHECK{
Dimensions consistent and identity verified exactly.}
\EDGECASES{
\begin{bullets}
\item If $V$ were disjoint except $\{0\}$, sum would have dimension $4$.
\end{bullets}
}
\ALTERNATE{
Stack columns $[u_1\ u_2\ v_1\ v_2]$ and compute ranks to infer dims.}
\VALIDATION{
\begin{bullets}
\item Directly check $v_1=u_1+u_2$ and $v_2=u_1-u_2$ numerically.
\end{bullets}
}
\INTUITION{
$V$ is the diagonal and anti-diagonal plane sitting inside $U$.}
\CANONICAL{
\begin{bullets}
\item Compute intersections by equating linear combinations.
\item Verify dimension identity.
\end{bullets}
}

\ProblemPage{4}{Narrative: Alice and Bob Build Polynomial Subspaces}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Decompose $\mathbb{R}_2[x]$ into a direct sum of two subspaces chosen by
Alice and Bob; find coordinates.
\PROBLEM{
Let $V=\mathbb{R}_2[x]=\{a+bx+cx^2\}$. Alice picks
$U=\{p(x):p(1)=p(-1)\}$ and Bob picks
$W=\{p(x):p(1)=-p(-1)\}$. Show $V=U\oplus W$, find bases, and express
$q(x)=3+2x+x^2$ as $u+w$ with $u\in U$, $w\in W$.}
\MODEL{
\[
V=\mathbb{R}_2[x],\quad U=\{p:\ p(1)=p(-1)\},\quad W=\{p:\ p(1)=-p(-1)\}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard vector space over $\mathbb{R}$.
\end{bullets}
}
\varmapStart
\var{U,W}{Even and odd under $x\mapsto -x$ at $\{\pm 1\}$.}
\var{q}{Target polynomial $3+2x+x^2$.}
\varmapEnd
\WHICHFORMULA{
Use direct sum criterion $V=U\oplus W$ iff $V=U+W$ and $U\cap W=\{0\}$.}
\GOVERN{
\[
\dim V=3,\quad \dim U+\dim W=\dim V,\quad U\cap W=\{0\}.
\]
}
\INPUTS{$V=\mathbb{R}_2[x]$, $q(x)=3+2x+x^2$.}
\DERIVATION{
\begin{align*}
&\text{Characterize }U,W:\\
&p(x)=a+bx+cx^2,\ p(1)=a+b+c,\ p(-1)=a-b+c.\\
&U:\ a+b+c=a-b+c\Rightarrow b=0\Rightarrow U=\mathrm{span}\{1,x^2\}.\\
&W:\ a+b+c=-(a-b+c)\Rightarrow a+c=0\Rightarrow a=-c.\\
&\text{Write }p(x)=-c+bx+c x^2=c(x^2-1)+b x.\\
&\Rightarrow W=\mathrm{span}\{x,x^2-1\}.\\
&U\cap W=\{0\}\ \text{since }U \text{ has only even terms, }W \text{ has only odd plus }(x^2-1).\\
&\text{Solve }u+w=q,\ u=\alpha\cdot 1+\beta x^2,\ w=\gamma x+\delta(x^2-1).\\
&u+w=(\alpha-\delta)+\gamma x+(\beta+\delta)x^2=q=3+2x+x^2.\\
&\text{Match coefficients: }\gamma=2,\ \beta+\delta=1,\ \alpha-\delta=3.\\
&\text{Choose }\delta=0\Rightarrow \beta=1,\ \alpha=3.\\
&u=3+1\cdot x^2,\ w=2 x+0\cdot (x^2-1)=2x.
\end{align*}
}
\RESULT{
$U=\mathrm{span}\{1,x^2\}$, $W=\mathrm{span}\{x,x^2-1\}$, $V=U\oplus W$,
and $q(x)=(3+x^2)+2x$.}
\UNITCHECK{
Dimensions $\dim U=2$, $\dim W=2$, intersection trivial, sum dimension $3$.}
\EDGECASES{
\begin{bullets}
\item Polynomials of higher degree split similarly into even and odd parts.
\end{bullets}
}
\ALTERNATE{
Use parity: $u(x)=\tfrac{q(x)+q(-x)}{2}$, $w(x)=\tfrac{q(x)-q(-x)}{2}$.}
\VALIDATION{
\begin{bullets}
\item Check $u(1)=u(-1)$ and $w(1)=-w(-1)$.
\end{bullets}
}
\INTUITION{
Even and odd components give an orthogonal-like decomposition of $V$.}
\CANONICAL{
\begin{bullets}
\item Direct sum via complementary structures.
\item Coordinate extraction by coefficient matching.
\end{bullets}
}

\ProblemPage{5}{Narrative: Unique Decomposition in a Direct Sum}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Given $V=U\oplus W$, prove uniqueness of decomposition and compute
coordinates in a concrete instance.
\PROBLEM{
Let $U=\mathrm{span}\{e_1,e_2\}$ and $W=\mathrm{span}\{e_3,e_4\}$ in
$\mathbb{R}^4$. For $v=(1,2,3,4)$, find $u\in U$ and $w\in W$ with
$v=u+w$ and prove uniqueness.}
\MODEL{
\[
\mathbb{R}^4=U\oplus W,\quad U\cap W=\{0\}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard basis $e_i$ of $\mathbb{R}^4$.
\end{bullets}
}
\varmapStart
\var{U,W}{Coordinate planes.}
\var{v}{Vector $(1,2,3,4)$.}
\var{u,w}{Components in $U$ and $W$.}
\varmapEnd
\WHICHFORMULA{
Use direct sum uniqueness: if $U\cap W=\{0\}$, then decomposition is unique.}
\GOVERN{
\[
v=u+w=u'+w'\ \Rightarrow\ (u-u')=(w'-w)\in U\cap W=\{0\}\Rightarrow u=u',w=w'.
\]
}
\INPUTS{$v=(1,2,3,4)$.}
\DERIVATION{
\begin{align*}
&U=\{(a,b,0,0)\},\ W=\{(0,0,c,d)\}.\\
&\text{Pick }u=(1,2,0,0),\ w=(0,0,3,4)\Rightarrow u+w=v.\\
&\text{Uniqueness: Suppose }v=u+w=u'+w'.\\
&\Rightarrow (u-u')=(w'-w)\in U\cap W=\{0\}\Rightarrow u=u',\ w=w'.
\end{align*}
}
\RESULT{
$u=(1,2,0,0)$, $w=(0,0,3,4)$, decomposition unique.}
\UNITCHECK{
Coordinates match componentwise; intersection trivial.}
\EDGECASES{
\begin{bullets}
\item If $U$ and $W$ overlapped nontrivially, decomposition would not be unique.
\end{bullets}
}
\ALTERNATE{
Use projection maps $\pi_U(v)=(v_1,v_2,0,0)$ and $\pi_W(v)=(0,0,v_3,v_4)$.}
\VALIDATION{
\begin{bullets}
\item Verify $u\in U$, $w\in W$, and $u+w=v$.
\end{bullets}
}
\INTUITION{
Coordinates split into independent blocks.}
\CANONICAL{
\begin{bullets}
\item Direct sum implies uniqueness of component representation.
\end{bullets}
}

\ProblemPage{6}{Expectation Puzzle: Random Span Dimension}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Compute the expected dimension of the span formed by randomly selecting
vectors from a fixed set in $\mathbb{R}^2$.
\PROBLEM{
Let $S=\{(1,0),(2,0),(0,1)\}$ in $\mathbb{R}^2$. Each vector is included
independently with probability $\tfrac{1}{2}$ to form $T\subseteq S$.
Let $D=\dim\mathrm{span}(T)$. Compute $\mathbb{E}[D]$.}
\MODEL{
\[
D(\omega)=\dim\mathrm{span}(T(\omega)),\quad T\subseteq S.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Independence of inclusion events; standard dimension over $\mathbb{R}$.
\end{bullets}
}
\varmapStart
\var{S}{Fixed set of three vectors in $\mathbb{R}^2$.}
\var{T}{Random subset of $S$.}
\var{D}{Random dimension of the span.}
\varmapEnd
\WHICHFORMULA{
Use span minimality and dependence $(2,0)=2(1,0)$.}
\GOVERN{
\[
\dim\mathrm{span}(T)=
\begin{cases}
0 & T=\varnothing,\\
1 & T\subseteq \{(1,0),(2,0)\},\ T\ne\varnothing,\\
2 & \text{otherwise}.
\end{cases}
\]
}
\INPUTS{$p=\tfrac{1}{2}$ inclusion for each of three vectors.}
\DERIVATION{
\begin{align*}
&\text{List cases by whether $(0,1)$ is included:}\\
&\text{Case A: }(0,1)\notin T\ (\text{prob }1/2).\\
&\quad T\subseteq \{(1,0),(2,0)\}.\\
&\quad \Pr(T=\varnothing)=(1/2)^2=1/4,\ \dim=0.\\
&\quad \Pr(T\ne\varnothing)=1-1/4=3/4,\ \dim=1.\\
&\quad \mathbb{E}[D\mid A]=0\cdot(1/4)+1\cdot(3/4)=3/4.\\
&\text{Case B: }(0,1)\in T\ (\text{prob }1/2).\\
&\quad \dim=1\ \text{if only }(0,1)\ \text{is present, prob }(1/2)^2=1/4.\\
&\quad \dim=2\ \text{otherwise, prob }1-1/4=3/4.\\
&\quad \mathbb{E}[D\mid B]=1\cdot(1/4)+2\cdot(3/4)=7/4.\\
&\text{Total: }\mathbb{E}[D]=(1/2)\cdot(3/4)+(1/2)\cdot(7/4)=
\frac{3+7}{8}=\frac{10}{8}=\frac{5}{4}.
\end{align*}
}
\RESULT{
$\mathbb{E}[D]=5/4=1.25$.}
\UNITCHECK{
Dimension bounded by $0\le D\le 2$; expectation lies within range.}
\EDGECASES{
\begin{bullets}
\item If $(2,0)$ were removed, expected dimension increases.
\end{bullets}
}
\ALTERNATE{
Compute by full enumeration of $2^3=8$ subsets and average the
dimensions.}
\VALIDATION{
\begin{bullets}
\item Check each subset dimension quickly: only $\varnothing$ gives $0$,
only singleton or both $(1,0),(2,0)$ without $(0,1)$ give $1$,
others give $2$.
\end{bullets}
}
\INTUITION{
Independence plus one redundant vector reduces average dimension.}
\CANONICAL{
\begin{bullets}
\item Dependence relations limit span growth under random selection.
\end{bullets}
}

\ProblemPage{7}{Proof: Intersection of Subspaces is a Subspace}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Prove that the intersection of any family of subspaces of $V$ is a
subspace of $V$.}
\PROBLEM{
Let $\{W_\alpha\}_{\alpha\in A}$ be subspaces of $V$. Show that
$\bigcap_{\alpha\in A} W_\alpha$ is a subspace of $V$.}
\MODEL{
\[
\bigcap_{\alpha\in A} W_\alpha \le V.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item $V$ is a vector space over $\mathbb{F}$; the family is nonempty.
\end{bullets}
}
\varmapStart
\var{W_\alpha}{Subspaces indexed by $A$.}
\varmapEnd
\WHICHFORMULA{
Use the subspace criterion with $a u+b v$.}
\GOVERN{
\[
u,v\in \bigcap W_\alpha,\ a,b\in\mathbb{F}\Rightarrow a u+b v\in \bigcap W_\alpha.
\]
}
\INPUTS{Family $\{W_\alpha\}_{\alpha\in A}$.}
\DERIVATION{
\begin{align*}
&\text{Nonempty: }0\in W_\alpha\ \forall\alpha\Rightarrow 0\in \bigcap W_\alpha.\\
&\text{Closure: }u,v\in \bigcap W_\alpha\Rightarrow u,v\in W_\alpha\ \forall\alpha.\\
&\text{Then }a u+b v\in W_\alpha\ \forall\alpha\Rightarrow a u+b v\in \bigcap W_\alpha.\\
&\text{Hence by the subspace criterion, the intersection is a subspace.}
\end{align*}
}
\RESULT{
$\bigcap_{\alpha\in A} W_\alpha$ is a subspace of $V$.}
\UNITCHECK{
Contains $0$ and closed under $+$ and scalar multiplication.}
\EDGECASES{
\begin{bullets}
\item Intersection of an empty family is $V$ by convention.
\end{bullets}
}
\ALTERNATE{
Equivalently, verify subgroup under addition and closure under scalars.}
\VALIDATION{
\begin{bullets}
\item Test with two planes in $\mathbb{R}^3$; intersection is a line or plane.
\end{bullets}
}
\INTUITION{
Common directions preserved by all subspaces remain linear.}
\CANONICAL{
\begin{bullets}
\item The intersection is the largest subspace contained in all $W_\alpha$.
\end{bullets}
}

\ProblemPage{8}{Proof: Extend LI Set to a Basis in Finite Dimension}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Prove that any linearly independent set in finite-dimensional $V$ can be
extended to a basis.}
\PROBLEM{
Let $V$ be finite-dimensional and $S$ a linearly independent subset.
Show there exists a basis $B$ of $V$ with $S\subseteq B$.}
\MODEL{
\[
S\subseteq V\ \text{LI},\quad \exists B\ \text{basis of }V,\ S\subseteq B.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item $\dim V=n<\infty$.
\end{bullets}
}
\varmapStart
\var{S}{Linearly independent set.}
\var{B}{Basis extending $S$.}
\varmapEnd
\WHICHFORMULA{
Use basis characterizations and spanning completion.}
\GOVERN{
\[
\text{Any LI set can be augmented until it spans; finite steps suffice.}
\]
}
\INPUTS{$V$ finite-dimensional, $S$ LI.}
\DERIVATION{
\begin{align*}
&\text{If }S\text{ already spans, done. Otherwise pick }v_1\notin \mathrm{span}(S)\\
&\text{and set }S_1=S\cup\{v_1\}\ \text{(still LI).}\\
&\text{Repeat: if }S_k\text{ does not span, pick }v_{k+1}\notin \mathrm{span}(S_k).\\
&\text{Each step increases the size; cannot exceed }n=\dim V.\\
&\text{Thus after }\le n-|S|\text{ steps, obtain a spanning LI set }B.\\
&\text{By characterization, }B\text{ is a basis containing }S.
\end{align*}
}
\RESULT{
There exists a basis $B$ with $S\subseteq B$.}
\UNITCHECK{
Cardinality bound by $n$ ensures termination.}
\EDGECASES{
\begin{bullets}
\item If $S=\varnothing$, any basis works.
\item If $S$ already spans, no augmentation needed.
\end{bullets}
}
\ALTERNATE{
Row-reduce a matrix whose columns include $S$ and additional candidates.}
\VALIDATION{
\begin{bullets}
\item In $\mathbb{R}^3$, extend $\{(1,0,0)\}$ by adding $(0,1,0)$ and $(0,0,1)$.
\end{bullets}
}
\INTUITION{
Keep adding genuinely new directions until you can reach everywhere.}
\CANONICAL{
\begin{bullets}
\item Maximal LI sets are bases in finite dimension.
\end{bullets}
}

\ProblemPage{9}{Combo: Function Subspaces with Integral Constraint}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Show that the set of vectors with zero sum is a subspace and decompose a
vector accordingly (discrete analog of mean-zero function space).}
\PROBLEM{
Let $V=\mathbb{R}^5$ and $W=\{x\in\mathbb{R}^5:\ \mathbf{1}^\top x=0\}$
where $\mathbf{1}=(1,1,1,1,1)^\top$. Prove $W$ is a subspace, find its
dimension and a basis, and decompose $y=(1,2,3,4,5)$ into $y=u+w$ with
$u\in \mathrm{span}\{\mathbf{1}\}$ and $w\in W$.}
\MODEL{
\[
W=\{x:\ \sum_{i=1}^5 x_i=0\},\quad U=\mathrm{span}\{\mathbf{1}\}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard vector space structure over $\mathbb{R}$.
\end{bullets}
}
\varmapStart
\var{W}{Mean-zero subspace.}
\var{U}{Span of the all-ones vector.}
\var{y}{Vector to decompose.}
\varmapEnd
\WHICHFORMULA{
Use the subspace criterion and direct sum with $U$ via orthogonal
complement-like splitting (algebraic).}
\GOVERN{
\[
\dim W=4,\quad \mathbb{R}^5=U\oplus W.
\]
}
\INPUTS{$y=(1,2,3,4,5)$, $\mathbf{1}=(1,1,1,1,1)$.}
\DERIVATION{
\begin{align*}
&\text{Subspace: }x,y\in W\Rightarrow \mathbf{1}^\top (a x+b y)=
a\,\mathbf{1}^\top x+b\,\mathbf{1}^\top y=0.\\
&\dim W=5-1=4\ \text{(one linear constraint).}\\
&\text{One basis: }e_1-e_5,\ e_2-e_5,\ e_3-e_5,\ e_4-e_5.\\
&\text{Decomposition: }u=\alpha \mathbf{1},\ w=y-u.\\
&\text{Choose }\alpha=\tfrac{1}{5}\mathbf{1}^\top y=\tfrac{1+2+3+4+5}{5}=3.\\
&u=3(1,1,1,1,1)=(3,3,3,3,3),\ w=y-u=(-2,-1,0,1,2).\\
&\mathbf{1}^\top w=(-2-1+0+1+2)=0\Rightarrow w\in W.
\end{align*}
}
\RESULT{
$W$ is a subspace with basis $\{e_i-e_5\}_{i=1}^4$, $\dim W=4$, and
$y=(3,3,3,3,3)+(-2,-1,0,1,2)$.}
\UNITCHECK{
Dimensions add: $1+4=5$; $w$ sums to zero as required.}
\EDGECASES{
\begin{bullets}
\item For $n$ entries, $\dim W=n-1$ with basis $\{e_i-e_n\}_{i=1}^{n-1}$.
\end{bullets}
}
\ALTERNATE{
Solve $\min_{\alpha}\|y-\alpha \mathbf{1}\|^2$; same $\alpha$ arises
(algebraic projection along $W$).}
\VALIDATION{
\begin{bullets}
\item Check $\mathbf{1}^\top w=0$ and $y=u+w$ numerically.
\end{bullets}
}
\INTUITION{
Split into average part and fluctuations summing to zero.}
\CANONICAL{
\begin{bullets}
\item Hyperplane subspaces via one linear constraint.
\end{bullets}
}

\ProblemPage{10}{Combo: Solutions of a Linear ODE Form a Subspace}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
The solution set of a homogeneous linear ODE with constant coefficients
is a vector subspace; compute a basis in a simple case.}
\PROBLEM{
Consider $V=\{y:\mathbb{R}\to\mathbb{R}\ \text{twice differentiable}\}$
and the homogeneous ODE $y''-y=0$. Show the solution set $W$ is a
subspace of $V$ and find a basis. Express $f(x)=e^x+e^{-x}$ in that
basis and verify uniqueness.}
\MODEL{
\[
W=\{y\in V:\ y''-y=0\}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard vector space of functions with pointwise operations.
\end{bullets}
}
\varmapStart
\var{W}{Solution subspace of the ODE.}
\var{e^x,e^{-x}}{Candidate basis functions.}
\varmapEnd
\WHICHFORMULA{
Use linearity of the differential operator and basis characterization.}
\GOVERN{
\[
L[y]=y''-y\ \text{linear}\Rightarrow L[a u+b v]=a L[u]+b L[v].
\]
}
\INPUTS{Differential operator $L[y]=y''-y$.}
\DERIVATION{
\begin{align*}
&\text{Subspace: }u,v\in W\Rightarrow L[u]=L[v]=0\Rightarrow L[a u+b v]=0.\\
&\text{Basis: Solve }r^2-1=0\Rightarrow r=\pm 1.\\
&\Rightarrow W=\mathrm{span}\{e^x,e^{-x}\}.\\
&\text{Coordinates for }f(x)=e^x+e^{-x}: [f]_{(e^x,e^{-x})}=(1,1).\\
&\text{Uniqueness by independence of }e^x,e^{-x}.
\end{align*}
}
\RESULT{
$W$ is a subspace with basis $\{e^x,e^{-x}\}$; $f=e^x+e^{-x}$ has
coordinates $(1,1)$.}
\UNITCHECK{
Linearity of $L$ and independence of exponentials verified by Wronskian
$W(e^x,e^{-x})=-2\ne 0$.}
\EDGECASES{
\begin{bullets}
\item Repeated roots yield polynomial factors multiplying exponentials.
\end{bullets}
}
\ALTERNATE{
Solve via initial values; the map $(y(0),y'(0))\mapsto y$ is an
isomorphism $\mathbb{R}^2\simeq W$.}
\VALIDATION{
\begin{bullets}
\item Check $f''-f=0$ directly.
\end{bullets}
}
\INTUITION{
Solutions form a two-direction space spanned by growth and decay modes.}
\CANONICAL{
\begin{bullets}
\item Homogeneous solutions form subspaces due to operator linearity.
\end{bullets}
}

\section{Coding Demonstrations}

\CodeDemoPage{RREF Basis of a Span and Linear Independence}
\PROBLEM{
Compute a basis for the span of given vectors in $\mathbb{R}^n$ via
row-reduction, determine rank, and verify against a library method.}
\API{
\begin{bullets}
\item \inlinecode{def read_input(s) -> list[list[float]]}
\item \inlinecode{def solve_case(mat) -> (list[list[float]], int)}
\item \inlinecode{def validate() -> None}
\item \inlinecode{def main() -> None}
\end{bullets}
}
\INPUTS{
Matrix with vectors as rows; basis rows and rank are returned.}
\OUTPUTS{
Basis rows spanning the same row space and the rank (dimension).}
\FORMULA{
\[
\mathrm{rank}(A)=\dim\mathrm{span}\{\text{rows of }A\}.
\]
}
\textbf{SOLUTION A — From Scratch (Mathematically Explicit Implementation)}
\begin{codepy}
# Deterministic RREF-based basis extraction and rank computation.
def read_input(s):
    rows = []
    for line in s.strip().split(";"):
        if line.strip():
            rows.append([float(x) for x in line.split()])
    return rows

def rref(mat, tol=1e-12):
    A = [row[:] for row in mat]
    m, n = len(A), len(A[0]) if A else 0
    r, c = 0, 0
    pivots = []
    while r < m and c < n:
        p = max(range(r, m), key=lambda i: abs(A[i][c]))
        if abs(A[p][c]) <= tol:
            c += 1
            continue
        A[r], A[p] = A[p], A[r]
        piv = A[r][c]
        A[r] = [v / piv for v in A[r]]
        for i in range(m):
            if i != r and abs(A[i][c]) > tol:
                fac = A[i][c]
                A[i] = [A[i][j] - fac * A[r][j] for j in range(n)]
        pivots.append(c)
        r += 1
        c += 1
    return A, pivots

def basis_rows(mat):
    rref_mat, pivs = rref(mat)
    basis = []
    for i in range(len(pivs)):
        basis.append(rref_mat[i])
    return basis, len(pivs)

def solve_case(mat):
    return basis_rows(mat)

def validate():
    M = read_input("1 0 1; 0 1 1; 1 1 2")
    basis, r = solve_case(M)
    assert r == 2
    # Check that basis rows span plane z=x+y
    x, y = 2.0, 3.0
    z = basis[0][2]*x + basis[1][2]*y
    assert abs(z - (x + y)) < 1e-9

def main():
    validate()
    M = read_input("1 2 -1; 2 4 0")
    basis, r = solve_case(M)
    print("rank", r, "basis_rows", [list(map(round, b)) for b in basis])

if __name__ == "__main__":
    main()
\end{codepy}
\textbf{SOLUTION B — Library-Based (Validated Computational Shortcut)}
\begin{codepy}
# Library method using NumPy's QR to find rank and a row-space basis.
import numpy as np

def read_input(s):
    rows = []
    for line in s.strip().split(";"):
        if line.strip():
            rows.append([float(x) for x in line.split()])
    return np.array(rows, dtype=float)

def rowspace_basis(A, tol=1e-12):
    Q, R = np.linalg.qr(A.T)
    diag = np.abs(np.diag(R))
    rank = int(np.sum(diag > tol))
    idx = list(range(rank))
    B = R[:rank, :]  # row-space basis in RREF-like upper form
    return B, rank

def solve_case(mat):
    A = np.array(mat, dtype=float)
    B, r = rowspace_basis(A)
    return B.tolist(), int(r)

def validate():
    A = read_input("1 0 1; 0 1 1; 1 1 2")
    B, r = solve_case(A)
    assert r == 2

def main():
    validate()
    A = read_input("1 2 -1; 2 4 0")
    B, r = solve_case(A)
    print("rank", r, "basis_shape", np.array(B).shape)

if __name__ == "__main__":
    main()
\end{codepy}
\COMPLEXITY{
Both variants run in time $\mathcal{O}(mn\min\{m,n\})$ for $m\times n$
matrices and space $\mathcal{O}(mn)$.}
\FAILMODES{
\begin{bullets}
\item Nearly dependent rows need tolerance; use robust pivoting or SVD.
\item Empty matrices handled by checks; return rank $0$.
\end{bullets}
}
\STABILITY{
\begin{bullets}
\item Pivoting mitigates loss of significance in elimination.
\item QR is numerically stable for rank determination.
\end{bullets}
}
\VALIDATION{
\begin{bullets}
\item Cross-check ranks on the same input.
\item Evaluate a known plane relation $z=x+y$ from basis rows.
\end{bullets}
}
\RESULT{
Both implementations agree on rank and produce compatible bases.}
\EXPLANATION{
Row space dimension equals span dimension of generators; RREF selects a
basis by eliminating dependencies.}

\CodeDemoPage{Verify Dimension Formula for Sum of Subspaces}
\PROBLEM{
Given generators of $U$ and $V$ in $\mathbb{R}^n$, compute
$\dim U,\ \dim V,\ \dim(U+V)$, and infer $\dim(U\cap V)$; verify the
dimension identity.}
\API{
\begin{bullets}
\item \inlinecode{def read_input(s) -> (list,list)}
\item \inlinecode{def solve_case(U,V) -> dict}
\item \inlinecode{def validate() -> None}
\item \inlinecode{def main() -> None}
\end{bullets}
}
\INPUTS{
Row lists for generators of $U$ and $V$.}
\OUTPUTS{
Dictionary with dims and a boolean flag that the identity holds.}
\FORMULA{
\[
\dim(U+V)=\mathrm{rank}\begin{bmatrix}U\\ V\end{bmatrix},\quad
\dim(U\cap V)=\dim U+\dim V-\dim(U+V).
\]
}
\textbf{SOLUTION A — From Scratch (Mathematically Explicit Implementation)}
\begin{codepy}
# Use RREF to compute ranks and verify the dimension formula.
def read_input(s):
    parts = s.split("|")
    U = [[float(x) for x in row.split()] for row in parts[0].split(";")]
    V = [[float(x) for x in row.split()] for row in parts[1].split(";")]
    return U, V

def rref(mat, tol=1e-12):
    A = [row[:] for row in mat]
    m, n = len(A), len(A[0]) if A else 0
    r, c = 0, 0
    pivots = 0
    while r < m and c < n:
        p = max(range(r, m), key=lambda i: abs(A[i][c]))
        if abs(A[p][c]) <= tol:
            c += 1
            continue
        A[r], A[p] = A[p], A[r]
        piv = A[r][c]
        A[r] = [v / piv for v in A[r]]
        for i in range(m):
            if i != r and abs(A[i][c]) > tol:
                fac = A[i][c]
                A[i] = [A[i][j] - fac * A[r][j] for j in range(n)]
        pivots += 1
        r += 1
        c += 1
    return A, pivots

def rank(mat):
    return rref(mat)[1]

def solve_case(U, V):
    dimU = rank(U)
    dimV = rank(V)
    UV = U + V
    dimUV = rank(UV)
    dimInt = dimU + dimV - dimUV
    ok = (dimUV == dimU + dimV - dimInt)
    return {"dimU": dimU, "dimV": dimV, "dimUV": dimUV,
            "dimInt": dimInt, "ok": ok}

def validate():
    U = [[1,0,1,0],[0,1,0,1]]
    V = [[1,1,1,1],[1,-1,1,-1]]
    res = solve_case(U, V)
    assert res["dimU"] == 2 and res["dimV"] == 2
    assert res["dimUV"] == 2 and res["dimInt"] == 2 and res["ok"]

def main():
    validate()
    U, V = read_input("1 0 0; 0 1 0|1 1 0; 0 0 1")
    res = solve_case(U, V)
    print(res)

if __name__ == "__main__":
    main()
\end{codepy}
\textbf{SOLUTION B — Library-Based (Validated Computational Shortcut)}
\begin{codepy}
# NumPy ranks via SVD to compute dimensions sturdily.
import numpy as np

def read_input(s):
    parts = s.split("|")
    U = np.array([[float(x) for x in r.split()] for r in parts[0].split(";")])
    V = np.array([[float(x) for x in r.split()] for r in parts[1].split(";")])
    return U, V

def rank(A, tol=1e-10):
    s = np.linalg.svd(A, compute_uv=False)
    return int(np.sum(s > tol))

def solve_case(U, V):
    dimU = rank(U)
    dimV = rank(V)
    UV = np.vstack([U, V])
    dimUV = rank(UV)
    dimInt = dimU + dimV - dimUV
    ok = (dimUV == dimU + dimV - dimInt)
    return {"dimU": dimU, "dimV": dimV, "dimUV": dimUV,
            "dimInt": dimInt, "ok": ok}

def validate():
    U = np.array([[1,0,1,0],[0,1,0,1]], float)
    V = np.array([[1,1,1,1],[1,-1,1,-1]], float)
    res = solve_case(U, V)
    assert res["ok"] and res["dimInt"] == 2

def main():
    validate()
    U, V = read_input("1 0 0; 0 1 0|1 1 0; 0 0 1")
    res = solve_case(U, V)
    print(res)

if __name__ == "__main__":
    main()
\end{codepy}
\COMPLEXITY{
Both: time $\mathcal{O}(mn\min\{m,n\})$ and space $\mathcal{O}(mn)$ for
$m\times n$ matrices.}
\FAILMODES{
\begin{bullets}
\item Near dependence needs tolerance tuning.
\item Empty inputs should return zero dimensions.
\end{bullets}
}
\STABILITY{
\begin{bullets}
\item SVD rank is more stable than naive elimination for ill-conditioned data.
\end{bullets}
}
\VALIDATION{
\begin{bullets}
\item Compare outputs of both methods on the same inputs.
\end{bullets}
}
\RESULT{
Identity verified on test cases; ranks match across methods.}
\EXPLANATION{
Stacking generators realizes $U+V$; SVD or RREF computes its dimension.}

\section{Applied Domains — Detailed End-to-End Scenarios}

\DomainPage{Machine Learning}
\SCENARIO{
Verify that the column space of a feature matrix is a subspace; compute
its dimension (feature rank) and express targets in that subspace.}
\ASSUMPTIONS{
\begin{bullets}
\item Linear regression hypothesis space is the column space of $X$.
\item Data deterministic with fixed seed.
\end{bullets}
}
\WHICHFORMULA{
Column space is a subspace; coordinate isomorphism yields coefficients.}
\varmapStart
\var{X}{Design matrix in $\mathbb{R}^{n\times d}$.}
\var{y}{Target vector in $\mathbb{R}^n$.}
\var{\mathrm{Col}(X)}{Subspace spanned by columns of $X$.}
\varmapEnd
\PIPELINE{
\begin{bullets}
\item Generate $X$ with a dependent column to illustrate rank.
\item Compute rank and a basis for $\mathrm{Col}(X)$.
\item Solve $X\beta=y$ when $y\in \mathrm{Col}(X)$.
\end{bullets}
}
\textbf{Implementation (From Scratch)}
\begin{codepy}
import numpy as np

def generate(seed=0):
    np.random.seed(seed)
    n = 6
    x1 = np.linspace(0, 5, n)
    x2 = 2 * x1
    x3 = np.ones(n)
    X = np.column_stack([x1, x2, x3])
    beta = np.array([1.0, 0.5, 2.0])
    y = X @ beta
    return X, y

def rref(A, tol=1e-12):
    A = A.copy().astype(float)
    m, n = A.shape
    r, c = 0, 0
    pivs = []
    while r < m and c < n:
        p = r + np.argmax(np.abs(A[r:, c]))
        if abs(A[p, c]) <= tol:
            c += 1
            continue
        A[[r, p]] = A[[p, r]]
        A[r] = A[r] / A[r, c]
        for i in range(m):
            if i != r and abs(A[i, c]) > tol:
                A[i] -= A[i, c] * A[r]
        pivs.append(c)
        r += 1
        c += 1
    return A, pivs

def basis_cols(X):
    R, pivs = rref(X)
    return pivs

def main():
    X, y = generate()
    pivs = basis_cols(X)
    print("rank", len(pivs), "pivot_cols", pivs)
    # Solve least squares; y is in the column space by construction.
    beta_hat = np.linalg.lstsq(X, y, rcond=None)[0]
    yhat = X @ beta_hat
    assert np.allclose(y, yhat)
    print("beta_hat", np.round(beta_hat, 3))

if __name__ == "__main__":
    main()
\end{codepy}
\textbf{Implementation (Library Version)}
\begin{codepy}
import numpy as np

def main():
    np.random.seed(0)
    n = 6
    x1 = np.linspace(0, 5, n)
    x2 = 2 * x1
    x3 = np.ones(n)
    X = np.column_stack([x1, x2, x3])
    rank = np.linalg.matrix_rank(X)
    print("rank", rank)
    beta = np.array([1.0, 0.5, 2.0])
    y = X @ beta
    beta_hat, *_ = np.linalg.lstsq(X, y, rcond=None)
    assert np.allclose(y, X @ beta_hat)
    print("ok", True)

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{Rank of $X$ and fitting residual $\|y-X\beta\|$.}
\INTERPRET{Dependent features reduce the hypothesis subspace dimension.}
\NEXTSTEPS{Use SVD to analyze near dependencies and regularization.}

\DomainPage{Quantitative Finance}
\SCENARIO{
Portfolio weight space $\mathbb{R}^d$ and zero-sum subspace
$W=\{w:\mathbf{1}^\top w=0\}$; decompose a portfolio into average and
zero-sum parts.}
\ASSUMPTIONS{
\begin{bullets}
\item Deterministic weights; no stochastic inputs required.
\end{bullets}
}
\WHICHFORMULA{
$W$ is a subspace of dimension $d-1$; $\mathbb{R}^d=\mathrm{span}
\{\mathbf{1}\}\oplus W$.}
\varmapStart
\var{w}{Portfolio weights in $\mathbb{R}^d$.}
\var{\mathbf{1}}{All-ones vector.}
\var{W}{Zero-sum subspace.}
\varmapEnd
\PIPELINE{
\begin{bullets}
\item Construct $w$.
\item Compute $\alpha=\frac{\mathbf{1}^\top w}{d}$ and $w_0=w-\alpha\mathbf{1}$.
\item Verify $\mathbf{1}^\top w_0=0$.
\end{bullets}
}
\textbf{Implementation (Full Pipeline)}
\begin{codepy}
import numpy as np

def decompose(w):
    d = len(w)
    one = np.ones(d)
    alpha = float(one @ w) / d
    u = alpha * one
    w0 = w - u
    return u, w0

def main():
    w = np.array([0.5, 0.3, 0.2])
    u, w0 = decompose(w)
    assert abs(np.sum(w0)) < 1e-12
    print("u", np.round(u, 3), "w0", np.round(w0, 3))

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{Check $\mathbf{1}^\top w_0=0$ and that $w=u+w_0$.}
\INTERPRET{Separate market exposure (average) from relative bets (zero-sum).}
\NEXTSTEPS{Add constraints subspaces like sector-neutral or beta-neutral.}

\DomainPage{Deep Learning}
\SCENARIO{
In a linear network, the hypothesis space equals the column space of the
design matrix; compute its dimension and confirm output reachability.}
\ASSUMPTIONS{
\begin{bullets}
\item Single linear layer $\hat{y}=X\beta$ with fixed $X$.
\end{bullets}
}
\WHICHFORMULA{
Coordinate isomorphism within the column space; rank gives dimension.}
\PIPELINE{
\begin{bullets}
\item Build $X$ with a redundant feature.
\item Compute $\mathrm{rank}(X)$ and verify that any $\hat{y}$ in the
column space is exactly reachable.
\end{bullets}
}
\textbf{Implementation (End-to-End)}
\begin{codepy}
import numpy as np

def main():
    np.random.seed(0)
    X = np.column_stack([np.arange(5), 2*np.arange(5), np.ones(5)])
    rank = np.linalg.matrix_rank(X)
    beta = np.array([1.0, 0.5, 3.0])
    y = X @ beta
    beta_hat, *_ = np.linalg.lstsq(X, y, rcond=None)
    assert np.allclose(y, X @ beta_hat)
    print("rank", rank, "ok", True)

if __name__ == "__main__":
    main()
\end{codepy}
\textbf{Analytical OLS Comparison}
\begin{codepy}
def ols_closed(X, y):
    XtX = X.T @ X
    Xty = X.T @ y
    return np.linalg.solve(XtX, Xty)
\end{codepy}
\METRICS{Matrix rank and exact fit residuals.}
\INTERPRET{Redundant features do not expand the hypothesis subspace.}
\NEXTSTEPS{Study subspace of gradients during training trajectories.}

\DomainPage{Kaggle / Data Analytics}
\SCENARIO{
Centering columns maps data to the mean-zero subspace; verify subspace
properties and compute a basis for the centered data span.}
\ASSUMPTIONS{
\begin{bullets}
\item Numeric features; deterministic generation.
\end{bullets}
}
\WHICHFORMULA{
Mean-zero vectors form a subspace; basis via row-reduction.}
\PIPELINE{
\begin{bullets}
\item Generate a small dataset with correlated features.
\item Center columns to land in the mean-zero subspace.
\item Compute the span dimension (rank) of centered data.
\end{bullets}
}
\textbf{Implementation (Complete EDA Pipeline)}
\begin{codepy}
import numpy as np

def create(n=6, seed=0):
    np.random.seed(seed)
    a = np.linspace(0, 5, n)
    b = a + np.ones(n)
    c = 2 * a
    X = np.column_stack([a, b, c])
    return X

def center(X):
    return X - X.mean(axis=0, keepdims=True)

def main():
    X = create()
    Xc = center(X)
    one = np.ones(Xc.shape[0])
    assert np.allclose(one @ Xc, np.zeros(3))
    rank = np.linalg.matrix_rank(Xc)
    print("rank_centered", rank)

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{Verify column means are zero and report rank.}
\INTERPRET{Centering removes average direction; span reveals variability.}
\NEXTSTEPS{Proceed to PCA to find principal subspaces.}

\end{document}