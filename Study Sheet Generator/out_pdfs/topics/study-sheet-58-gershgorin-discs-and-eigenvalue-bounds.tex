% !TeX program = xelatex
\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{microtype,setspace,amsmath,amssymb,mathtools,amsthm,unicode-math}
\setstretch{1.05}
\setmainfont{Latin Modern Roman}
\setmonofont{Latin Modern Mono}
\setmathfont{Latin Modern Math}

% --- Overflow / line-break safety ---
\allowdisplaybreaks[4]
\setlength{\jot}{7pt}
\setlength{\emergencystretch}{8em}
\sloppy

\usepackage{xcolor,fancyhdr,enumitem,inconsolata,listings}
\pagestyle{fancy}\fancyhf{}\lhead{\nouppercase{\leftmark}}\rhead{\thepage}
\setlength{\headheight}{26pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt plus 2pt minus 1pt}
\raggedbottom

% --- Breakable math helpers (use these in the body) ---
\newenvironment{BreakableEquation}{\begin{equation}\begin{aligned}}{\end{aligned}\end{equation}}
\newenvironment{BreakableEquation*}{\begin{equation*}\begin{aligned}}{\end{aligned}\end{equation*}}
\newenvironment{tightalign}{\begingroup\small\allowdisplaybreaks\begin{align}}{\end{align}\endgroup}

% ---------- Safety shims ----------
% Robust minted → listings shim (no shell-escape; supports [opts]{language})
\providecommand{\enumlistm}{enumitem}
\newenvironment{minted}[2][]{%
  \lstset{style=code,language=#2,#1}\begin{lstlisting}%
}{\end{lstlisting}}

% Fallback for \inputminted (ignore file; keep build unbroken)
\newcommand{\inputminted}[3][]{\begin{lstlisting}\end{lstlisting}}

% ---------- Bulleted lines (no tables) ----------
\newlist{bullets}{itemize}{1}
\setlist[bullets]{label=--,leftmargin=1.6em,itemsep=2pt,topsep=4pt}

% ---------- Variable mapping (lines, no tables) ----------
\newcommand{\varmapStart}{\textbf{VARIABLE MAPPING:}\par\begin{bullets}}
\newcommand{\var}[2]{\item $#1$ — #2}
\newcommand{\varmapEnd}{\end{bullets}}

% ---------- Glossary item with ELI5 and Pitfall/Example ----------
\newcommand{\glossx}[6]{%
  \textbf{#1}\par
  \begin{bullets}
    \item \textbf{What:} #2
    \item \textbf{Why:} #3
    \item \textbf{How:} #4
    \item \textbf{ELI5:} #5
    \item \textbf{Pitfall/Example:} #6
  \end{bullets}
}

% ---------- Theorem structures ----------
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
% ---------- Code blocks ----------
\lstdefinestyle{code}{
  basicstyle=\ttfamily\footnotesize,
  backgroundcolor=\color{black!02},
  frame=single,
  numbers=left, numberstyle=\tiny, numbersep=8pt,
  breaklines=true, breakatwhitespace=true,
  tabsize=4, showstringspaces=false,
  upquote=true, keepspaces=true, columns=fullflexible,
  % Unicode safety: map common symbols so listings never chokes
  literate=
    {–}{{-}}1
    {—}{{-}}1
    {…}{{...}}1
    {≤}{{\ensuremath{\le}}}1
    {≥}{{\ensuremath{\ge}}}1
    {≠}{{\ensuremath{\ne}}}1
    {≈}{{\ensuremath{\approx}}}1
    {±}{{\ensuremath{\pm}}}1
    {→}{{\ensuremath{\to}}}1
    {←}{{\ensuremath{\leftarrow}}}1
    {∞}{{\ensuremath{\infty}}}1
    {√}{{\ensuremath{\sqrt{\ }}}}1
    {×}{{\ensuremath{\times}}}1
    {÷}{{\ensuremath{\div}}}1
}

% Main code environment for all Python blocks
\lstnewenvironment{codepy}[1][]%
  {\lstset{style=code,language=Python,#1}}%
  {}

% Inline code; change delimiters if your snippet contains '!'
\newcommand{\inlinecode}[1]{\lstinline[style=code]!#1!}

% ---------- Line-label macros ----------
\newcommand{\LF}[2]{\par\noindent\textbf{#1:}~#2\par}
\newcommand{\WHAT}[1]{\LF{WHAT}{#1}}
\newcommand{\WHY}[1]{\LF{WHY}{#1}}
\newcommand{\HOW}[1]{\LF{HOW}{#1}}
\newcommand{\ELI}[1]{\LF{ELI5}{#1}}
\newcommand{\SCOPE}[1]{\LF{SCOPE}{#1}}
\newcommand{\CONFUSIONS}[1]{\LF{COMMON CONFUSIONS}{#1}}
\newcommand{\APPLICATIONS}[1]{\LF{APPLICATIONS}{#1}}
\newcommand{\FORMULA}[1]{\LF{FORMULA}{#1}}
\newcommand{\CANONICAL}[1]{\LF{CANONICAL FORM}{#1}}
\newcommand{\PRECONDS}[1]{\LF{PRECONDITIONS}{#1}}
\newcommand{\DERIVATION}[1]{\LF{DERIVATION}{#1}}
\newcommand{\EQUIV}[1]{\LF{EQUIVALENT FORMS}{#1}}
\newcommand{\LIMITS}[1]{\LF{LIMIT CASES}{#1}}
\newcommand{\INPUTS}[1]{\LF{INPUTS}{#1}}
\newcommand{\OUTPUTS}[1]{\LF{OUTPUTS}{#1}}
\newcommand{\RESULT}[1]{\LF{RESULT}{#1}}
\newcommand{\INTUITION}[1]{\LF{INTUITION}{#1}}
\newcommand{\PITFALLS}[1]{\LF{PITFALLS}{#1}}
\newcommand{\MODEL}[1]{\LF{CANONICAL MATH MODEL}{#1}}
\newcommand{\ASSUMPTIONS}[1]{\LF{ASSUMPTIONS}{#1}}
\newcommand{\WHICHFORMULA}[1]{\LF{WHICH FORMULA \& WHY}{#1}}
\newcommand{\GOVERN}[1]{\LF{GOVERNING EQUATION(S)}{#1}}
\newcommand{\UNITCHECK}[1]{\LF{UNIT CHECK}{#1}}
\newcommand{\EDGECASES}[1]{\LF{EDGE CASES}{#1}}
\newcommand{\ALTERNATE}[1]{\LF{ALTERNATE APPROACH (sketch)}{#1}}
\newcommand{\PROBLEM}[1]{\LF{PROBLEM}{#1}}
\newcommand{\API}[1]{\LF{API}{#1}}
\newcommand{\COMPLEXITY}[1]{\LF{COMPLEXITY}{#1}}
\newcommand{\FAILMODES}[1]{\LF{FAILURE MODES}{#1}}
\newcommand{\STABILITY}[1]{\LF{NUMERICAL STABILITY}{#1}}
\newcommand{\VALIDATION}[1]{\LF{VALIDATION}{#1}}
\newcommand{\EXPLANATION}[1]{\LF{EXPLANATION}{#1}}
\newcommand{\SCENARIO}[1]{\LF{SCENARIO}{#1}}
\newcommand{\PIPELINE}[1]{\LF{PIPELINE STEPS}{#1}}
\newcommand{\METRICS}[1]{\LF{METRICS}{#1}}
\newcommand{\INTERPRET}[1]{\LF{INTERPRETATION}{#1}}
\newcommand{\NEXTSTEPS}[1]{\LF{LIMITATIONS \& NEXT STEPS}{#1}}

% ---------- Section formatting ----------
\usepackage{titlesec}
\titleformat{\section}{\Large\bfseries}{\thesection}{0.6em}{}
\titlespacing*{\section}{0pt}{*2}{*1}
\usepackage{etoolbox}
\pretocmd{\section}{\clearpage}{}{}

% ---------- Page helpers ----------
\newcommand{\FormulaPage}[2]{%
  \clearpage
  \section*{Formula #1 — #2}%
  \addcontentsline{toc}{section}{Formula #1 — #2}%
}
\newcommand{\ProblemPage}[2]{%
  \clearpage
  \subsection*{Problem #1: #2}%
  \addcontentsline{toc}{subsection}{Problem #1: #2}%
}
\newcommand{\CodeDemoPage}[1]{%
  \clearpage
  \subsection*{Coding Demo: #1}%
  \addcontentsline{toc}{subsection}{Coding Demo: #1}%
}
\newcommand{\DomainPage}[1]{%
  \clearpage
  \subsection*{#1 (End-to-End)}%
  \addcontentsline{toc}{subsection}{#1 (End-to-End)}%
}

\begin{document}
\title{Comprehensive Study Sheet — Gershgorin Discs and Eigenvalue Bounds}
\date{\today}
\maketitle
\tableofcontents
\clearpage

\section{Concept Overview}
\WHAT{
Given a complex square matrix $A=(a_{ij})\in\mathbb{C}^{n\times n}$,
the Gershgorin discs are the set of $n$ closed discs in $\mathbb{C}$,
$D_i=\{z\in\mathbb{C}:|z-a_{ii}|\le R_i\}$ with row radii
$R_i=\sum_{j\ne i}|a_{ij}|$. The Gershgorin Circle Theorem states that
the spectrum $\sigma(A)$ is contained in $\bigcup_{i=1}^n D_i$.
A column version uses $C_j=\{z:|z-a_{jj}|\le S_j\}$ with
$S_j=\sum_{i\ne j}|a_{ij}|$. Consequences include eigenvalue location
bounds, spectral radius bounds, and nonsingularity tests under diagonal
dominance.
}
\WHY{
Locating eigenvalues is central to stability analysis, numerical linear
algebra, and perturbation theory. Gershgorin provides cheap, rigorous,
easily computed bounds using only matrix entries, enabling certification
of nonsingularity, step size limits, and clustering of eigenvalues.
}
\HOW{
1. Fix an eigenpair $(\lambda,x)$ with $x\ne 0$ and choose an index $k$
where $|x_k|$ is maximal. 2. Expand $(A-\lambda I)x=0$ in row $k$ and
isolate $a_{kk}-\lambda$. 3. Apply triangle inequality to bound
$|a_{kk}-\lambda|$ by the row sum of off-diagonal magnitudes.
4. Conclude $\lambda\in D_k$. Repeat for columns via $A^\top$.
}
\ELI{
Each row paints a safety circle on the complex plane centered at its
diagonal entry; if you throw all eigenvalues as darts, every dart lands
inside at least one painted circle.
}
\SCOPE{
Valid for all complex matrices, any size. Tightness varies with entry
structure. For Hermitian matrices, discs intersect the real axis and all
eigenvalues are real, so bounds reduce to real intervals. Degenerate
case: if some $R_i=0$, the $i$th disc shrinks to the point $a_{ii}$,
forcing an eigenvalue equal to $a_{ii}$ if the union is separated and
counts match in refined versions.
}
\CONFUSIONS{
Gershgorin discs bound eigenvalues, not singular values. Diagonal
dominance implies nonsingularity but is not necessary. Norm bounds
$\rho(A)\le \|A\|$ are different from Gershgorin and can be combined.
}
\APPLICATIONS{
\begin{bullets}
\item Mathematical foundations: location of roots of characteristic
polynomials via entrywise information.
\item Computational modeling: preconditioner design and pivot safety via
diagonal dominance.
\item Physical or engineering: stability margins of linearized systems
from Jacobians.
\item Algorithmic: safe step sizes in gradient methods via spectral
radius bounds on Hessians.
\end{bullets}
}

\textbf{ANALYTIC STRUCTURE.}
Gershgorin sets are unions of closed discs determined by $\ell_1$
off-diagonal row or column norms. The mapping $A\mapsto\{D_i\}$ is
continuous under entrywise perturbations; eigenvalues vary continuously,
making inclusion robust. The structure is subadditive in radii and
centered at diagonal elements.

\textbf{CANONICAL LINKS.}
Linked to: triangle inequality, eigenvalue invariance under transpose,
Hermitian real-spectrum property, diagonal dominance (Levy--Desplanques
criterion), spectral radius bounds. Column version follows from row
version applied to $A^\top$.

\textbf{PROBLEM-TYPE RECOGNITION HEURISTICS.}
\begin{bullets}
\item Phrases: diagonal dominance, eigenvalue location, spectral radius,
stability margin, safe step size.
\item Signatures: sums of off-diagonal magnitudes, discs centered at
$a_{ii}$, comparison to zero location for nonsingularity.
\item Patterns: certify invertibility without computing eigenvalues;
bound $\max|\lambda|$ via entrywise quantities.
\end{bullets}

\textbf{SOLUTION STRATEGY BLUEPRINT.}
\begin{bullets}
\item Translate matrix entries into centers $a_{ii}$ and radii $R_i$ or
$S_j$.
\item Invoke row or column Gershgorin inclusion.
\item Substitute numeric sums to draw or compare discs.
\item For Hermitian, restrict to real intervals.
\item Validate by optional eigen-computation or limit checks.
\end{bullets}

\textbf{CONCEPTUAL INVARIANTS.}
Centers equal diagonal entries. Radii equal off-diagonal $\ell_1$ row or
column norms. Inclusion invariant under row/column permutations matching
definitions. Spectral inclusion robust under small perturbations.

\textbf{EDGE INTUITION.}
As off-diagonals vanish, discs collapse to points at $a_{ii}$ and
eigenvalues converge to those diagonals. With large off-diagonals, discs
inflate and may overlap, giving looser but still valid bounds. If all
discs avoid $0$, $A$ is nonsingular with a margin equal to the minimal
distance from $0$ to the union.

\section{Glossary}
\glossx{Gershgorin Disc}{
For row $i$, $D_i=\{z:|z-a_{ii}|\le R_i\}$ with
$R_i=\sum_{j\ne i}|a_{ij}|\,$. Column discs use $S_j=\sum_{i\ne j}|a_{ij}|$.
}{
Provides computable regions containing all eigenvalues of $A$.
}{
Compute $R_i$ (or $S_j$) and draw discs centered at $a_{ii}$.
}{
Each row draws a circle that must catch all eigenvalues.
}{
Confusing $R_i$ with $\sqrt{\sum |a_{ij}|^2}$ leads to wrong radii.
}

\glossx{Diagonal Dominance}{
Row-dominant if $|a_{ii}|>\sum_{j\ne i}|a_{ij}|$ for all $i$.
}{
Certifies nonsingularity via exclusion of $0$ from all discs.
}{
Check strict inequality for each row (or column).
}{
The diagonal is heavier than all other entries in its row.
}{
Non-strict dominance does not guarantee invertibility.
}

\glossx{Spectral Radius}{
$\rho(A)=\max\{|\lambda|:\lambda\in\sigma(A)\}$.
}{
Controls asymptotic powers $A^k$ and stability of iterations.
}{
Bound by discs: $\rho(A)\le \max_i(|a_{ii}|+R_i)$.
}{
Largest distance of an eigenvalue from the origin.
}{
Do not confuse with any induced matrix norm; only inequality holds.
}

\glossx{Hermitian Interval Bound}{
For $A=A^\ast$, eigenvalues are real and lie in
$[a_{ii}-R_i,a_{ii}+R_i]$ for some $i$.
}{
Sharper interpretation of Gershgorin on the real line.
}{
Use Gershgorin inclusion plus reality of eigenvalues.
}{
Project discs onto the real line when spectrum is real.
}{
Intervals may still overlap heavily if off-diagonals are large.
}

\section{Symbol Ledger}
\varmapStart
\var{A=(a_{ij})}{Complex $n\times n$ matrix under analysis.}
\var{\sigma(A)}{Spectrum: multiset of eigenvalues of $A$.}
\var{\lambda}{Generic eigenvalue of $A$.}
\var{x}{Eigenvector associated with $\lambda$.}
\var{R_i}{Row radius $\sum_{j\ne i}|a_{ij}|$.}
\var{S_j}{Column radius $\sum_{i\ne j}|a_{ij}|$.}
\var{D_i}{Row Gershgorin disc $\{z:|z-a_{ii}|\le R_i\}$.}
\var{C_j}{Column disc $\{z:|z-a_{jj}|\le S_j\}$.}
\var{\rho(A)}{Spectral radius $\max_{\lambda\in\sigma(A)}|\lambda|$.}
\var{I}{Identity matrix.}
\var{A^\top}{Transpose of $A$.}
\var{A^\ast}{Conjugate transpose of $A$.}
\var{d_i}{Diagonal entry $a_{ii}$.}
\var{n}{Matrix dimension.}
\var{\|\cdot\|_\infty}{Induced $\ell_\infty$ norm.}
\varmapEnd

\section{Formula Canon — One Formula Per Page}

\FormulaPage{1}{Gershgorin Circle Theorem (Row Version)}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Every eigenvalue of $A\in\mathbb{C}^{n\times n}$ lies in at least one
row Gershgorin disc $D_i=\{z:|z-a_{ii}|\le R_i\}$ with
$R_i=\sum_{j\ne i}|a_{ij}|$.

\WHAT{
Inclusion of the spectrum $\sigma(A)$ in a union of $n$ discs centered at
diagonal entries $a_{ii}$ with radii equal to off-diagonal row sums.
}
\WHY{
It localizes eigenvalues using only entry magnitudes, enabling quick
stability checks and invertibility certification without eigen-solvers.
}
\FORMULA{
\[
\sigma(A)\subseteq \bigcup_{i=1}^n D_i,\qquad
D_i=\left\{z\in\mathbb{C}:\ |z-a_{ii}|\le \sum_{j\ne i}|a_{ij}|\right\}.
\]
}
\CANONICAL{
$A$ arbitrary complex square matrix; no symmetry or definiteness
assumptions. Radii use $\ell_1$ off-diagonal row sums.
}
\PRECONDS{
\begin{bullets}
\item $A\in\mathbb{C}^{n\times n}$.
\item Eigenpair definition: $(A-\lambda I)x=0$ with $x\ne 0$.
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
Let $(\lambda,x)$ be an eigenpair of $A$ with $x\ne 0$. If $k$ maximizes
$|x_k|$, then
$|a_{kk}-\lambda|\le \sum_{j\ne k}|a_{kj}|\frac{|x_j|}{|x_k|}\le R_k$.
\end{lemma}
\begin{proof}
From $(A-\lambda I)x=0$, the $k$th row gives
$(a_{kk}-\lambda)x_k+\sum_{j\ne k}a_{kj}x_j=0$.
Rearrange:
$(a_{kk}-\lambda)x_k=-\sum_{j\ne k}a_{kj}x_j$.
Take absolute values and use triangle inequality:
$|a_{kk}-\lambda||x_k|\le \sum_{j\ne k}|a_{kj}||x_j|$.
Since $|x_j|\le |x_k|$ by maximality,
$|a_{kk}-\lambda|\le \sum_{j\ne k}|a_{kj}|\le R_k$. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{Step 1:}~&(A-\lambda I)x=0,\ x\ne 0,\ k=\arg\max_i |x_i|.\\
\text{Step 2:}~&(a_{kk}-\lambda)x_k=-\sum_{j\ne k}a_{kj}x_j.\\
\text{Step 3:}~&|a_{kk}-\lambda|
\le \sum_{j\ne k}|a_{kj}|\frac{|x_j|}{|x_k|}
\le \sum_{j\ne k}|a_{kj}|=R_k.\\
\text{Step 4:}~&\lambda\in D_k\ \Rightarrow\
\lambda\in \bigcup_{i=1}^n D_i.\\
\text{Step 5:}~&\sigma(A)\subseteq \bigcup_i D_i\ \text{as claimed.}
\end{align*}
}
\textbf{GENERAL PROBLEM-SOLVING TEMPLATE.}
\begin{bullets}
\item Compute $d_i=a_{ii}$ and $R_i=\sum_{j\ne i}|a_{ij}|$.
\item Form discs $D_i=\{z:|z-d_i|\le R_i\}$.
\item Conclude $\sigma(A)\subseteq \bigcup_i D_i$.
\item For Hermitian $A$, intersect with $\mathbb{R}$.
\item Use exclusion of $0$ to certify nonsingularity.
\end{bullets}
\EQUIV{
\begin{bullets}
\item Column version via transpose: use $S_j=\sum_{i\ne j}|a_{ij}|$.
\item Bound on spectral radius: $\rho(A)\le \max_i(|a_{ii}|+R_i)$.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Discs can be large and overlapping; inclusion may be loose.
\item If $R_i=0$, disc collapses to $a_{ii}$ and forces an eigenvalue at
$a_{ii}$ when all other discs are disjoint from it.
\end{bullets}
}
\INPUTS{$A=(a_{ij})$, $d_i=a_{ii}$, $R_i=\sum_{j\ne i}|a_{ij}|$.}
\DERIVATION{
\begin{align*}
\text{Compute:}~&R_i\ \text{for each row}.\\
\text{Assemble:}~&D_i=\{z:|z-d_i|\le R_i\}.\\
\text{Inclusion:}~&\sigma(A)\subseteq \bigcup_i D_i.
\end{align*}
}
\RESULT{
All eigenvalues lie in the union of row Gershgorin discs.
}
\UNITCHECK{
Analytic consistency: both sides are subsets of $\mathbb{C}$;
radii are nonnegative by construction.
}
\PITFALLS{
\begin{bullets}
\item Using $\ell_2$ or $\ell_\infty$ sums for radii invalidates the
theorem.
\item Forgetting absolute values on off-diagonals mis-centers radii.
\end{bullets}
}
\INTUITION{
An eigenvector cannot concentrate all mass off the pivot row of its
largest coordinate without forcing the shift $\lambda$ close to
$a_{kk}$; otherwise the row imbalance cannot cancel to zero.
}
\CANONICAL{
\begin{bullets}
\item Universal inclusion: $\sigma(A)\subseteq \bigcup_i \mathbb{D}(a_{ii},R_i)$.
\item Entrywise bound produces spectral localization without solving
polynomials.
\end{bullets}
}

\FormulaPage{2}{Gershgorin Circle Theorem (Column Version)}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Every eigenvalue lies in at least one column disc
$C_j=\{z:|z-a_{jj}|\le S_j\}$, where $S_j=\sum_{i\ne j}|a_{ij}|$.

\WHAT{
Column-based inclusion of $\sigma(A)$ using off-diagonal column sums.
}
\WHY{
Sometimes column sums are much smaller than row sums, giving tighter
bounds; both can be intersected for improved localization.
}
\FORMULA{
\[
\sigma(A)\subseteq \bigcup_{j=1}^n C_j,\qquad
C_j=\left\{z\in\mathbb{C}:\ |z-a_{jj}|\le \sum_{i\ne j}|a_{ij}|\right\}.
\]
}
\CANONICAL{
Follows from row version applied to $A^\top$ since
$\sigma(A)=\sigma(A^\top)$ and column sums of $A$ are row sums of
$A^\top$.
}
\PRECONDS{
\begin{bullets}
\item $A\in\mathbb{C}^{n\times n}$.
\item Equality of characteristic polynomials under transpose.
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
$A$ and $A^\top$ have identical characteristic polynomials, hence the
same eigenvalues with multiplicity.
\end{lemma}
\begin{proof}
$\det(\lambda I-A^\top)=\det((\lambda I-A)^\top)=\det(\lambda I-A)$,
using $\det(B^\top)=\det(B)$ for any square $B$. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{Step 1:}~&\sigma(A)=\sigma(A^\top).\\
\text{Step 2:}~&\text{Apply row Gershgorin to }A^\top.\\
\text{Step 3:}~&\text{Row discs of }A^\top\text{ are column discs of }A.\\
\text{Conclude:}~&\sigma(A)\subseteq \bigcup_{j} C_j.
\end{align*}
}
\textbf{GENERAL PROBLEM-SOLVING TEMPLATE.}
\begin{bullets}
\item Compute $S_j=\sum_{i\ne j}|a_{ij}|$.
\item Form $C_j=\{z:|z-a_{jj}|\le S_j\}$.
\item Use $\sigma(A)\subseteq \bigcup_j C_j$.
\item Optionally intersect with row discs for sharper bounds.
\end{bullets}
\EQUIV{
\begin{bullets}
\item Row version is identical after transposition.
\item For $A^\ast$, same inclusion holds, preserving spectrum.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Column discs can be looser than row discs depending on scaling.
\item Intersection of row and column unions is still a superset, not
necessarily tight.
\end{bullets}
}
\INPUTS{$A=(a_{ij})$, $S_j=\sum_{i\ne j}|a_{ij}|$.}
\DERIVATION{
\begin{align*}
\text{Compute:}~&S_j\ \text{for each column}.\\
\text{Assemble:}~&C_j=\{z:|z-a_{jj}|\le S_j\}.\\
\text{Inclusion:}~&\sigma(A)\subseteq \bigcup_j C_j.
\end{align*}
}
\RESULT{
All eigenvalues lie in the union of column Gershgorin discs.
}
\UNITCHECK{
Analytic consistency: both sides are subsets of $\mathbb{C}$; radii are
nonnegative.
}
\PITFALLS{
\begin{bullets}
\item Confusing $S_j$ with $\sum_i|a_{ji}|$ (note indices).
\item Assuming column version dominates row version; either can be
tighter.
\end{bullets}
}
\INTUITION{
Apply the same maximal-coordinate argument to $A^\top$ so the role of
rows and columns swaps, producing column-based discs.
}
\CANONICAL{
\begin{bullets}
\item Universal inclusion via column sums.
\item Spectral invariance under transpose underpins equivalence.
\end{bullets}
}

\FormulaPage{3}{Levy--Desplanques: Strict Diagonal Dominance $\Rightarrow$ Invertible}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
If $|a_{ii}|>\sum_{j\ne i}|a_{ij}|$ for every $i$, then $A$ is
nonsingular.

\WHAT{
Criterion ensuring $0\notin\sigma(A)$ via strict diagonal dominance.
}
\WHY{
Gives a fast, verifiable sufficient condition for invertibility and
stable elimination without pivoting in many cases.
}
\FORMULA{
\[
\Big(\forall i:\ |a_{ii}|>\sum_{j\ne i}|a_{ij}|\Big)\ \Longrightarrow\
0\notin \bigcup_{i=1}^n D_i\ \Longrightarrow\ 0\notin \sigma(A).
\]
}
\CANONICAL{
Row version stated; column version also holds. The margin
$m=\min_i\{|a_{ii}|-R_i\}>0$ quantifies the exclusion distance.
}
\PRECONDS{
\begin{bullets}
\item Strict diagonal dominance by rows (or columns).
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
If $0\notin \bigcup_i D_i$, then $0\notin \sigma(A)$.
\end{lemma}
\begin{proof}
By Gershgorin inclusion, $\sigma(A)\subseteq \bigcup_i D_i$. If $0$ were
an eigenvalue, then $0\in \sigma(A)\subseteq \bigcup_i D_i$, a
contradiction. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{Step 1:}~&|a_{ii}|>R_i\ \Rightarrow\ \text{disc }D_i\ \text{excludes }0.\\
\text{Step 2:}~&\text{Hence }0\notin \bigcup_i D_i.\\
\text{Step 3:}~&\text{By lemma, }0\notin \sigma(A).\\
\text{Step 4:}~&A\ \text{is nonsingular}.
\end{align*}
}
\textbf{GENERAL PROBLEM-SOLVING TEMPLATE.}
\begin{bullets}
\item Compute $m=\min_i(|a_{ii}|-R_i)$.
\item If $m>0$, conclude $A$ invertible; margin $m$ quantifies how far
$0$ lies from the union.
\item Optionally use column dominance similarly.
\end{bullets}
\EQUIV{
\begin{bullets}
\item Column strict dominance $\Rightarrow$ invertible.
\item Weak dominance with at least one strict row and irreducibility can
also imply nonsingularity, but requires extra structure.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Non-strict dominance does not guarantee invertibility.
\item Invertible matrices may fail diagonal dominance; this is only
sufficient, not necessary.
\end{bullets}
}
\INPUTS{$A=(a_{ij})$, $R_i=\sum_{j\ne i}|a_{ij}|$, margin
$m=\min_i(|a_{ii}|-R_i)$.}
\DERIVATION{
\begin{align*}
\text{Compute:}~&m=\min_i(|a_{ii}|-R_i).\\
\text{Decision:}~&m>0~\Rightarrow~A\ \text{invertible}.
\end{align*}
}
\RESULT{
If strictly diagonally dominant, $A$ is nonsingular; $0$ is excluded
from every disc by at least margin $m$.
}
\UNITCHECK{
Inequalities compare magnitudes; dimensions are consistent; margin $m$
has same units as $a_{ii}$.
}
\PITFALLS{
\begin{bullets}
\item Checking only a subset of rows can miss a violating row.
\item Confusing row with column dominance in non-normalized matrices.
\end{bullets}
}
\INTUITION{
Each diagonal entry dominates the sum of rivals in its row, so no shift
$\lambda=0$ can balance the row equation to zero with a nonzero vector.
}
\CANONICAL{
\begin{bullets}
\item Invertibility certified by exclusion of $0$ from Gershgorin union.
\item Margin $m$ is a robustness measure to perturbations.
\end{bullets}
}

\FormulaPage{4}{Spectral Radius and Real-Interval Bounds}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Gershgorin yields an a priori upper bound on spectral radius and, for
Hermitian $A$, real-interval localization.

\WHAT{
Upper bound $\rho(A)\le \max_i(|a_{ii}|+R_i)$ for any $A$; for
$A=A^\ast$, every eigenvalue $\lambda$ satisfies
$\lambda\in [a_{ii}-R_i,a_{ii}+R_i]$ for some $i$.
}
\WHY{
Provides quick stability bounds and interpretable intervals for symmetric
or Hermitian problems common in applications.
}
\FORMULA{
\[
\rho(A)\le \max_{1\le i\le n}\left(|a_{ii}|+R_i\right),\quad
A=A^\ast\Rightarrow \sigma(A)\subseteq \bigcup_{i=1}^n
[a_{ii}-R_i,a_{ii}+R_i]\subset \mathbb{R}.
\]
}
\CANONICAL{
$A\in\mathbb{C}^{n\times n}$ arbitrary for the radius bound; $A=A^\ast$
for real intervals. $R_i=\sum_{j\ne i}|a_{ij}|$.
}
\PRECONDS{
\begin{bullets}
\item Gershgorin row inclusion.
\item For intervals, Hermitian property: eigenvalues real.
\end{bullets}
}
\textbf{SUPPORTING LEMMAS.}
\begin{lemma}
If $\lambda\in D_i$, then $|\lambda|\le |a_{ii}|+R_i$.
\end{lemma}
\begin{proof}
Triangle inequality: $|\lambda|\le |a_{ii}|+|\lambda-a_{ii}|
\le |a_{ii}|+R_i$. \qedhere
\end{proof}
\begin{lemma}
If $A=A^\ast$, then $\sigma(A)\subset \mathbb{R}$.
\end{lemma}
\begin{proof}
Standard: for any eigenpair $Ax=\lambda x$ with $x\ne 0$,
$\lambda=\frac{x^\ast A x}{x^\ast x}\in\mathbb{R}$ because
$x^\ast A x$ is real when $A$ is Hermitian. \qedhere
\end{proof}
\DERIVATION{
\begin{align*}
\text{Step 1:}~&\lambda\in \bigcup_i D_i.\\
\text{Step 2:}~&\exists i:\ |\lambda|\le |a_{ii}|+R_i.\\
\text{Step 3:}~&\Rightarrow \rho(A)\le \max_i(|a_{ii}|+R_i).\\
\text{Step 4:}~&A=A^\ast\Rightarrow \lambda\in\mathbb{R}.\\
\text{Step 5:}~&\lambda\in D_i\cap \mathbb{R}=
[a_{ii}-R_i,a_{ii}+R_i].
\end{align*}
}
\textbf{GENERAL PROBLEM-SOLVING TEMPLATE.}
\begin{bullets}
\item Compute $M=\max_i(|a_{ii}|+R_i)$; conclude $\rho(A)\le M$.
\item If Hermitian, collect intervals $[a_{ii}-R_i,a_{ii}+R_i]$; conclude
$\sigma(A)$ is within their union.
\end{bullets}
\EQUIV{
\begin{bullets}
\item Column-based bound: $\rho(A)\le \max_j(|a_{jj}|+S_j)$.
\item If $m=\min_i(|a_{ii}|-R_i)>0$, then $|\lambda|\ge m$ for all
$\lambda\in \sigma(A)$; hence $A$ is well-conditioned away from zero in
a Gershgorin sense.
\end{bullets}
}
\LIMITS{
\begin{bullets}
\item Lower bounds on $\rho(A)$ generally require more structure.
\item Intervals may be wide if off-diagonals are large.
\end{bullets}
}
\INPUTS{$A=(a_{ij})$, $R_i=\sum_{j\ne i}|a_{ij}|$.}
\DERIVATION{
\begin{align*}
M&=\max_i(|a_{ii}|+R_i),\quad \rho(A)\le M.\\
\text{Hermitian:}~&\text{report intervals }[a_{ii}-R_i,a_{ii}+R_i].
\end{align*}
}
\RESULT{
Quick bound $\rho(A)\le M$ and, for Hermitian $A$, real-interval
localization of all eigenvalues.
}
\UNITCHECK{
All bounds compare real magnitudes; units match matrix entry units.
}
\PITFALLS{
\begin{bullets}
\item Assuming equality $\rho(A)=M$; bound may be conservative.
\item Forgetting Hermitian assumption when claiming real intervals.
\end{bullets}
}
\INTUITION{
The furthest any disc point is from the origin is its center magnitude
plus radius. Hermitian squeezes the complex picture onto the real axis.
}
\CANONICAL{
\begin{bullets}
\item $\rho(A)\le \max_i(|a_{ii}|+R_i)$ is an immediate corollary.
\item For $A=A^\ast$, intervals encode localization on $\mathbb{R}$.
\end{bullets}
}

\section{10 Exhaustive Problems and Solutions}

\ProblemPage{1}{Compute and Compare Gershgorin Discs for a Given Matrix}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Given $A=\begin{bmatrix}4&-1&0\\2&3&1\\0&-2&2\end{bmatrix}$, locate
Gershgorin discs and compare with true eigenvalues.

\PROBLEM{
Compute $D_i$ and $C_j$, bound $\rho(A)$, and verify all eigenvalues
are within the union. Provide numeric eigenvalues to compare.
}
\MODEL{
\[
A=\begin{bmatrix}
4&-1&0\\
2&3&1\\
0&-2&2
\end{bmatrix},\quad
R_1=1,\ R_2=3,\ R_3=2,\quad
S_1=2,\ S_2=3,\ S_3=1.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Standard complex arithmetic; eigenvalues of real matrix occur in
conjugate pairs or real values.
\end{bullets}
}
\varmapStart
\var{A}{Given matrix.}
\var{D_i}{Row discs centered at $a_{ii}$ with radii $R_i$.}
\var{C_j}{Column discs centered at $a_{jj}$ with radii $S_j$.}
\var{\lambda}{Eigenvalue of $A$.}
\varmapEnd
\WHICHFORMULA{
Row and column Gershgorin inclusion, spectral radius bound
$\rho(A)\le \max_i(|a_{ii}|+R_i)$.
}
\GOVERN{
\[
\sigma(A)\subseteq \bigcup_i D_i,\quad
\sigma(A)\subseteq \bigcup_j C_j.
\]
}
\INPUTS{$a_{11}=4,a_{22}=3,a_{33}=2$; off-diagonals as specified.}
\DERIVATION{
\begin{align*}
R_1&=|-1|+0=1,& D_1&:\ |z-4|\le 1.\\
R_2&=|2|+|1|=3,& D_2&:\ |z-3|\le 3.\\
R_3&=|-2|+0=2,& D_3&:\ |z-2|\le 2.\\
S_1&=|2|+0=2,& C_1&:\ |z-4|\le 2.\\
S_2&=|-1|+|-2|=3,& C_2&:\ |z-3|\le 3.\\
S_3&=|1|+0=1,& C_3&:\ |z-2|\le 1.\\
\rho(A)&\le \max\{5,6,4\}=6.
\end{align*}
}
\RESULT{
Row discs: centers $(4,3,2)$ with radii $(1,3,2)$. Column discs: centers
$(4,3,2)$ with radii $(2,3,1)$. Spectral radius bound $6$.
Numerically, $\sigma(A)\approx\{4.5616,2.4384,2.0\}$, all inside discs.
}
\UNITCHECK{
All quantities are dimensionless magnitudes. Bound $6$ exceeds
$|\lambda|$ values.
}
\EDGECASES{
\begin{bullets}
\item If $a_{12}$ were $-10$, $R_1$ would inflate and loosen bounds.
\item If $a_{23}=0$, $R_2$ would drop to $2$, tightening $D_2$.
\end{bullets}
}
\ALTERNATE{
Intersect row and column unions to tighten: e.g., $\{|z-4|\le 1\}
\cap \{|z-4|\le 2\}=\{|z-4|\le 1\}$ keeps the tighter one for row $1$.
}
\VALIDATION{
\begin{bullets}
\item Direct computation of eigenvalues confirms inclusion.
\item Check that $\max|\lambda|\approx 4.5616\le 6$.
\end{bullets}
}
\INTUITION{
Large $R_2$ means row 2 is most coupled, giving the widest disc.
}

\ProblemPage{2}{Nonsingularity via Strict Diagonal Dominance}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Show $A=\begin{bmatrix}5&-1&-1\\-1&4&-1\\-1&-1&3\end{bmatrix}$ is
invertible and bound $|\lambda|$ away from $0$.

\PROBLEM{
Compute $m=\min_i(|a_{ii}|-R_i)$ and conclude $|\lambda|\ge m$ for all
$\lambda\in \sigma(A)$, hence $A$ is nonsingular.
}
\MODEL{
\[
R_1=2,\ R_2=2,\ R_3=2,\quad
|a_{11}|-R_1=3,\ |a_{22}|-R_2=2,\ |a_{33}|-R_3=1.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Gershgorin inclusion and exclusion logic.
\end{bullets}
}
\varmapStart
\var{m}{Exclusion margin $\min_i(|a_{ii}|-R_i)$.}
\var{\lambda}{Eigenvalue.}
\varmapEnd
\WHICHFORMULA{
Levy--Desplanques theorem and conditional lower bound on $|\lambda|$.
}
\GOVERN{
\[
|\lambda|\ge \min_i(|a_{ii}|-R_i)=m>0.
\]
}
\INPUTS{$|a_{11}|-R_1=3$, $|a_{22}|-R_2=2$, $|a_{33}|-R_3=1$.}
\DERIVATION{
\begin{align*}
m&=\min\{3,2,1\}=1.\\
0&\notin \bigcup_i D_i\ \Rightarrow\ 0\notin \sigma(A).\\
|\lambda|&\ge m=1\ \text{for all }\lambda\in \sigma(A).
\end{align*}
}
\RESULT{
$A$ invertible; all eigenvalues have modulus at least $1$.
}
\UNITCHECK{
Bounds are on real magnitudes; consistent.
}
\EDGECASES{
\begin{bullets}
\item If $a_{33}$ were $2$, $m$ would drop to $0$ (cannot conclude).
\end{bullets}
}
\ALTERNATE{
Column dominance is identical here due to symmetry.
}
\VALIDATION{
\begin{bullets}
\item Numerically, eigenvalues $\approx\{6.246,3.000,2.754\}$ satisfy
the bound.
\end{bullets}
}
\INTUITION{
Every row diagonal beats its neighbors; zero cannot be an eigenvalue.
}

\ProblemPage{3}{Row vs. Column Discs Tightness}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
For $A=\begin{bmatrix}1&10\\ \epsilon&1\end{bmatrix}$ with small
$\epsilon>0$, compare row and column discs.

\PROBLEM{
Show row discs are loose while column discs are tight when $\epsilon$ is
small, and explain why intersecting improves localization.
}
\MODEL{
\[
R_1=10,\ R_2=\epsilon,\quad S_1=\epsilon,\ S_2=10.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item $\epsilon\in(0,1)$ and small.
\end{bullets}
}
\varmapStart
\var{\epsilon}{Small positive parameter.}
\var{D_i,C_j}{Row and column discs.}
\varmapEnd
\WHICHFORMULA{
Both Gershgorin inclusions hold; intersection yields a valid superset.
}
\GOVERN{
\[
\sigma(A)\subseteq \Big(\bigcup_i D_i\Big)\cap \Big(\bigcup_j C_j\Big).
\]
}
\INPUTS{$\epsilon$ small, $a_{11}=a_{22}=1$, $a_{12}=10$, $a_{21}=\epsilon$.}
\DERIVATION{
\begin{align*}
D_1&:\ |z-1|\le 10,\quad D_2:\ |z-1|\le \epsilon.\\
C_1&:\ |z-1|\le \epsilon,\quad C_2:\ |z-1|\le 10.\\
\text{Intersection}&:\ |z-1|\le \epsilon\ \cup\ |z-1|\le \epsilon\\
&=|z-1|\le \epsilon.
\end{align*}
}
\RESULT{
Intersected bound reduces to $\{|z-1|\le \epsilon\}$, tight when
$\epsilon$ is small; actual eigenvalues are near $1$ and $1+10\epsilon$.
}
\UNITCHECK{
All discs centered at $1$ with different radii; consistent.
}
\EDGECASES{
\begin{bullets}
\item As $\epsilon\to 0$, one eigenvalue sticks at $1$; the other tends
to $1$ as well, but exact matrix becomes defective at $\epsilon=0$.
\end{bullets}
}
\ALTERNATE{
Scale $A$ by diagonal similarity $DAD^{-1}$ to balance row and column
sums before applying Gershgorin (preconditioning idea).
}
\VALIDATION{
\begin{bullets}
\item Compute eigenvalues explicitly:
$\lambda=1\pm \sqrt{10\epsilon}$ approximately for small $\epsilon$.
\end{bullets}
}
\INTUITION{
Pick the smaller radius from rows or columns to sharpen the catch region.
}

\ProblemPage{4}{Hermitian Interval Localization}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
For the symmetric matrix
$A=\begin{bmatrix}2&-1&0\\-1&2&-1\\0&-1&2\end{bmatrix}$, bound all
eigenvalues using real intervals.

\PROBLEM{
Compute $R_i$ and intervals $[a_{ii}-R_i,a_{ii}+R_i]$ and compare with
true eigenvalues.
}
\MODEL{
\[
R_1=1,\ R_2=2,\ R_3=1,\quad
I_1=[1,3],\ I_2=[0,4],\ I_3=[1,3].
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item $A$ is Hermitian $\Rightarrow$ eigenvalues real.
\end{bullets}
}
\varmapStart
\var{I_i}{Real intervals $[a_{ii}-R_i,a_{ii}+R_i]$.}
\varmapEnd
\WHICHFORMULA{
Hermitian interval bound from Formula 4.
}
\GOVERN{
\[
\sigma(A)\subseteq I_1\cup I_2\cup I_3\subset \mathbb{R}.
\]
}
\INPUTS{$a_{ii}=2$, $R_1=1,R_2=2,R_3=1$.}
\DERIVATION{
\begin{align*}
I_1&=[2-1,2+1]=[1,3],\\
I_2&=[2-2,2+2]=[0,4],\\
I_3&=[2-1,2+1]=[1,3].
\end{align*}
}
\RESULT{
Eigenvalues are $\{2-2\cos(k\pi/4):k=1,2,3\}=\{0.5858,2,3.4142\}$, all
inside $[0,4]$ and tighter $[1,3]$ for two of them.
}
\UNITCHECK{
Intervals on real line; consistent with symmetry.
}
\EDGECASES{
\begin{bullets}
\item Adding a small coupling at $(1,3)$ inflates $R_1,R_3$ and widens
intervals.
\end{bullets}
}
\ALTERNATE{
Column intervals identical by symmetry; intersection equals the same set.
}
\VALIDATION{
\begin{bullets}
\item Closed form eigenvalues of tridiagonal Toeplitz confirm bounds.
\end{bullets}
}
\INTUITION{
Nearest neighbors spread values by at most the sum of their strengths.
}

\ProblemPage{5}{Graph Laplacian Eigenvalue Bounds via Gershgorin}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
For an unweighted graph Laplacian $L=D-A_{\text{adj}}$, show
$\sigma(L)\subseteq [0,2d_{\max}]$.

\PROBLEM{
Use Gershgorin on $L$ to bound eigenvalues and explain zero eigenvalue
multiplicity relates to components.
}
\MODEL{
\[
L_{ii}=d_i,\ L_{ij}=-1\ \text{if }(i,j)\in E,\ 0\ \text{otherwise}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Simple undirected graph; $L$ is symmetric positive semidefinite.
\end{bullets}
}
\varmapStart
\var{d_i}{Degree of node $i$.}
\var{d_{\max}}{Maximum degree.}
\var{L}{Graph Laplacian.}
\varmapEnd
\WHICHFORMULA{
Hermitian interval bound with $R_i=\sum_{j\ne i}|L_{ij}|=d_i$.
}
\GOVERN{
\[
\sigma(L)\subseteq \bigcup_i [d_i-d_i,\ d_i+d_i]=\bigcup_i [0,2d_i]
\subseteq [0,2d_{\max}].
\]
}
\INPUTS{$L_{ii}=d_i$, off-diagonals $-1$ on edges, $0$ else.}
\DERIVATION{
\begin{align*}
R_i&=\sum_{j\ne i}|L_{ij}|=\sum_{j\sim i}1=d_i.\\
I_i&=[d_i-R_i,d_i+R_i]=[0,2d_i]\subseteq [0,2d_{\max}].
\end{align*}
}
\RESULT{
All eigenvalues of $L$ lie in $[0,2d_{\max}]$.
}
\UNITCHECK{
Bounds are real and nonnegative; consistent with $L$ being
positive semidefinite.
}
\EDGECASES{
\begin{bullets}
\item For $d_{\max}=1$ (matching), eigenvalues in $[0,2]$.
\item Complete graph on $n$: $d_{\max}=n-1$, bound $[0,2(n-1)]$.
\end{bullets}
}
\ALTERNATE{
Use Rayleigh quotient to show $\lambda_{\max}\le 2d_{\max}$ directly;
Gershgorin gives the same range quickly.
}
\VALIDATION{
\begin{bullets}
\item Compute eigenvalues numerically for a sample graph and confirm
bounds.
\end{bullets}
}
\INTUITION{
Each node spreads value to its neighbors by at most its degree.
}

\ProblemPage{6}{Narrative: Alice and Bob Choose Rows vs. Columns}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Alice uses row discs; Bob uses column discs on
$A=\begin{bmatrix}3&-2&0\\ \tfrac12&2&\tfrac12\\ 0&-1&1\end{bmatrix}$.

\PROBLEM{
Who gets the tighter bound on $\rho(A)$ and why does their intersection
improve the estimate?
}
\MODEL{
\[
R=(2,1,1),\ S=(\tfrac12,3,\tfrac12),\ a_{ii}=(3,2,1).
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Use $\rho(A)\le \max(|a_{ii}|+R_i)$ and the column analogue.
\end{bullets}
}
\varmapStart
\var{R_i,S_j}{Row and column radii.}
\var{\rho(A)}{Spectral radius.}
\varmapEnd
\WHICHFORMULA{
Formula 1 and 2; Formula 4 for spectral radius bound.
}
\GOVERN{
\[
\rho(A)\le \min\Big(\max_i(|a_{ii}|+R_i),\ \max_j(|a_{jj}|+S_j)\Big).
\]
}
\INPUTS{$R=(2,1,1)$, $S=(\tfrac12,3,\tfrac12)$, $|a_{ii}|=(3,2,1)$.}
\DERIVATION{
\begin{align*}
\text{Row: }&\max(|3|+2,|2|+1,|1|+1)=5.\\
\text{Column: }&\max(|3|+\tfrac12,|2|+3,|1|+\tfrac12)=5.\\
\text{Intersect union}&\Rightarrow \text{no worse than either bound}.
\end{align*}
}
\RESULT{
Both obtain $\rho(A)\le 5$; intersection cannot worsen and may tighten
the set of admissible $\lambda$.
}
\UNITCHECK{
All magnitudes are real; consistent.
}
\EDGECASES{
\begin{bullets}
\item If $a_{12}$ were $-20$, row bound inflates to $23$, column may
stay small depending on $S$.
\end{bullets}
}
\ALTERNATE{
Scale columns to balance $S_j$ with $R_i$ before applying bounds.
}
\VALIDATION{
\begin{bullets}
\item Numerical eigenvalues are $\approx\{3.5616,1.4384,1.0\}$,
consistent with bound $5$.
\end{bullets}
}
\INTUITION{
Pick the side with smaller off-diagonal sums; otherwise, combine both.
}

\ProblemPage{7}{Expectation Puzzle: Random Diagonal Dominance}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
Let $A=\begin{bmatrix}2&X\\ Y&2\end{bmatrix}$ where $X,Y$ are
independent taking values $\pm 1$ with equal probability. Compute
$\mathbb{P}(A\ \text{is nonsingular})$ via Gershgorin.

\PROBLEM{
Use strict diagonal dominance by rows to certify nonsingularity and
determine the probability of meeting the criterion.
}
\MODEL{
\[
R_1=|X|=1,\ R_2=|Y|=1,\quad |a_{11}|=|a_{22}|=2.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Use sufficiency of strict diagonal dominance to guarantee
invertibility.
\end{bullets}
}
\varmapStart
\var{X,Y}{Independent Rademacher variables.}
\var{R_1,R_2}{Row radii.}
\varmapEnd
\WHICHFORMULA{
Levy--Desplanques: if $|a_{ii}|>R_i$ for all $i$, then invertible.
}
\GOVERN{
\[
|2|>1\ \wedge\ |2|>1\ \Rightarrow\ A\ \text{invertible}.
\]
}
\INPUTS{$|2|>1$ always; $R_1=R_2=1$ always.}
\DERIVATION{
\begin{align*}
\Pr\big(|2|>1\text{ for both rows}\big)&=1.\\
\Rightarrow\ \Pr(A\ \text{invertible})&=1.
\end{align*}
}
\RESULT{
$A$ is almost surely invertible; probability $1$ via Gershgorin.
}
\UNITCHECK{
Probabilities well-defined; bounds deterministic in this setup.
}
\EDGECASES{
\begin{bullets}
\item If diagonal were $1$, criterion would be non-strict and
inconclusive; actual singularity occurs when $XY=1$.
\end{bullets}
}
\ALTERNATE{
Exact determinant: $\det(A)=4-XY\in\{3,5\}>0$ confirms invertibility.
}
\VALIDATION{
\begin{bullets}
\item Direct enumeration of four outcomes yields positive determinants.
\end{bullets}
}
\INTUITION{
Strong diagonals overwhelm random off-diagonals here.
}

\ProblemPage{8}{Proof-Style: Column Strict Dominance Implies Invertible}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
If $|a_{jj}|>\sum_{i\ne j}|a_{ij}|$ for all $j$, then $A$ is
nonsingular.

\PROBLEM{
Prove nonsingularity using column Gershgorin inclusion.
}
\MODEL{
\[
C_j=\{z:|z-a_{jj}|\le S_j\},\ S_j=\sum_{i\ne j}|a_{ij}|.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item Column version of Gershgorin holds (Formula 2).
\end{bullets}
}
\varmapStart
\var{S_j}{Column radii.}
\var{C_j}{Column discs.}
\varmapEnd
\WHICHFORMULA{
Column Gershgorin inclusion excludes $0$ if $|a_{jj}|>S_j$ for all $j$.
}
\GOVERN{
\[
0\notin \bigcup_j C_j\ \Rightarrow\ 0\notin \sigma(A).
\]
}
\INPUTS{$|a_{jj}|>S_j$ for all $j$.}
\DERIVATION{
\begin{align*}
\text{Each }C_j&\ \text{excludes }0\ \Rightarrow\
0\notin \bigcup_j C_j.\\
\sigma(A)&\subseteq \bigcup_j C_j\ \Rightarrow\ 0\notin \sigma(A).
\end{align*}
}
\RESULT{
$A$ is invertible.
}
\UNITCHECK{
All inequalities compare magnitudes; consistent.
}
\EDGECASES{
\begin{bullets}
\item Non-strict column dominance is inconclusive.
\end{bullets}
}
\ALTERNATE{
Transpose to reduce to row strict dominance case.
}
\VALIDATION{
\begin{bullets}
\item Numerical tests on random strictly column-dominant matrices show
no zero pivots in Gaussian elimination.
\end{bullets}
}
\INTUITION{
Dominant column centers keep $0$ far from every disc.
}

\ProblemPage{9}{Proof-Style: Stability Under Small Perturbations}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
If $A$ is strictly row diagonally dominant with margin
$m=\min_i(|a_{ii}|-R_i)>0$ and $\|E\|_\infty< m$, then $A+E$ is
nonsingular.

\PROBLEM{
Use Gershgorin on $A+E$ to show $0$ remains excluded from the union of
discs.
}
\MODEL{
\[
R_i(A+E)\le R_i(A)+\sum_{j\ne i}|e_{ij}|,\quad
|a_{ii}+e_{ii}|\ge |a_{ii}|-|e_{ii}|.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item $\|E\|_\infty=\max_i\sum_j|e_{ij}|<m$.
\end{bullets}
}
\varmapStart
\var{m}{Dominance margin of $A$.}
\var{E}{Perturbation matrix.}
\varmapEnd
\WHICHFORMULA{
Levy--Desplanques applied to $A+E$ via updated radii and centers.
}
\GOVERN{
\[
|a_{ii}+e_{ii}|-R_i(A+E)\ge (|a_{ii}|-R_i(A))-\|E\|_\infty>0.
\]
}
\INPUTS{$m=\min_i(|a_{ii}|-R_i(A))$, $\|E\|_\infty<m$.}
\DERIVATION{
\begin{align*}
|a_{ii}+e_{ii}|-R_i(A+E)
&\ge |a_{ii}|-|e_{ii}|-R_i(A)-\sum_{j\ne i}|e_{ij}|\\
&\ge (|a_{ii}|-R_i(A))-\sum_j|e_{ij}|\\
&\ge m-\|E\|_\infty>0.
\end{align*}
}
\RESULT{
$A+E$ is strictly diagonally dominant, hence nonsingular.
}
\UNITCHECK{
All terms are real magnitudes; dimensions consistent.
}
\EDGECASES{
\begin{bullets}
\item If $\|E\|_\infty=m$, criterion becomes non-strict and inconclusive.
\end{bullets}
}
\ALTERNATE{
Use Neumann series if additionally $\|A^{-1}\|_\infty\|E\|_\infty<1$;
Gershgorin requires only entrywise bounds.
}
\VALIDATION{
\begin{bullets}
\item Random tests with small $\|E\|_\infty$ confirm invertibility via
numerical solvers.
\end{bullets}
}
\INTUITION{
Small perturbations cannot close a positive dominance gap.
}

\ProblemPage{10}{Combo: Gradient Step Size via Gershgorin}
\textbf{CANONICAL MATHEMATICAL STATEMENT.}
For least-squares Hessian $H=X^\top X$, choose $\alpha<2/\rho(H)$ for
gradient descent; bound $\rho(H)$ by Gershgorin.

\PROBLEM{
Given $X\in\mathbb{R}^{n\times d}$, bound $\rho(H)$ using entries of
$H$, and provide a safe step size $\alpha$ without eigen-computation.
}
\MODEL{
\[
H=(h_{ij})=X^\top X,\quad h_{ij}=\sum_{k=1}^n x_{ki}x_{kj}.
\]
}
\ASSUMPTIONS{
\begin{bullets}
\item $H$ symmetric positive semidefinite; gradient descent stability
requires $\alpha\in(0,2/\rho(H))$.
\end{bullets}
}
\varmapStart
\var{H}{Hessian $X^\top X$.}
\var{\alpha}{Step size.}
\var{R_i}{Row radii of $H$.}
\varmapEnd
\WHICHFORMULA{
Hermitian interval and spectral radius bounds (Formula 4).
}
\GOVERN{
\[
\rho(H)\le \max_i(|h_{ii}|+R_i),\quad
\alpha<\frac{2}{\max_i(|h_{ii}|+R_i)}.
\]
}
\INPUTS{$H=X^\top X$, entries $h_{ij}$ computed from $X$.}
\DERIVATION{
\begin{align*}
R_i&=\sum_{j\ne i}|h_{ij}|,\\
M&=\max_i(h_{ii}+R_i)\ (\text{nonnegative}),\\
\alpha&<2/M\ \text{is safe}.
\end{align*}
}
\RESULT{
A computable safe step size $\alpha<2/M$ avoiding spectral computation.
}
\UNITCHECK{
$h_{ii}$ and $R_i$ have squared units of $X$; $\alpha$ scales as inverse
of those units consistent with gradient descent.
}
\EDGECASES{
\begin{bullets}
\item If columns of $X$ orthogonal, $R_i=0$ and $M=\max_i h_{ii}$.
\end{bullets}
}
\ALTERNATE{
Use power iteration to approximate $\rho(H)$; Gershgorin gives certified
upper bound in one pass.
}
\VALIDATION{
\begin{bullets}
\item Compare convergence with $\alpha=1/M$ against a smaller $\alpha$;
both converge, larger saturates the bound.
\end{bullets}
}
\INTUITION{
Column correlations inflate $R_i$ and reduce the safe step size.
}

\section{Coding Demonstrations}

\CodeDemoPage{Verify Gershgorin Inclusion on 2x2 and 4x4 Matrices}
\PROBLEM{
Compute Gershgorin discs and verify that all eigenvalues lie within the
union. Provide a from-scratch 2x2 eigen-solver and a library variant for
general size.
}
\API{
\begin{bullets}
\item \inlinecode{def read_input(s) -> list} — parse flat list to matrix.
\item \inlinecode{def discs_row(A) -> list} — row discs centers/radii.
\item \inlinecode{def eig2(A) -> tuple} — 2x2 analytic eigenvalues.
\item \inlinecode{def solve_case(A) -> bool} — verify inclusion.
\item \inlinecode{def validate() -> None} — run assertions.
\item \inlinecode{def main() -> None} — orchestrate tests.
\end{bullets}
}
\INPUTS{
Square matrix $A$ as nested lists; sizes $2\times 2$ for from-scratch
eigenvalues; $4\times 4$ for library test.
}
\OUTPUTS{
Boolean flags confirming inclusion; printed summaries.
}
\FORMULA{
\[
\sigma(A)\subseteq \bigcup_i \{z:|z-a_{ii}|\le R_i\},\quad
R_i=\sum_{j\ne i}|a_{ij}|.
\]
}
\textbf{SOLUTION A — From Scratch (Mathematically Explicit Implementation)}
\begin{codepy}
from math import sqrt

def read_input(s):
    vals = [float(x) for x in s.split()]
    n = int(sqrt(len(vals)))
    A = [vals[i*n:(i+1)*n] for i in range(n)]
    return A

def discs_row(A):
    n = len(A)
    discs = []
    for i in range(n):
        c = A[i][i]
        R = sum(abs(A[i][j]) for j in range(n) if j != i)
        discs.append((c, R))
    return discs

def eig2(A):
    a, b = A[0][0], A[0][1]
    c, d = A[1][0], A[1][1]
    tr = a + d
    det = a*d - b*c
    disc = tr*tr - 4*det
    if disc >= 0:
        r = sqrt(disc)
        return ((tr + r)/2.0, (tr - r)/2.0)
    else:
        # complex conj pair; handle via real/imag parts
        r = sqrt(-disc)
        # return pair as complex
        return (complex(tr/2.0, r/2.0), complex(tr/2.0, -r/2.0))

def inside_discs(lam, discs):
    for c, R in discs:
        if abs(lam - c) <= R + 1e-12:
            return True
    return False

def solve_case(A):
    assert len(A) == 2 and len(A[0]) == 2
    discs = discs_row(A)
    l1, l2 = eig2(A)
    ok1 = inside_discs(l1, discs)
    ok2 = inside_discs(l2, discs)
    return ok1 and ok2

def validate():
    A = [[4.0, -1.0], [2.0, 3.0]]
    assert solve_case(A)
    B = [[1.0, 10.0], [0.1, 1.0]]
    assert solve_case(B)

def main():
    validate()
    print("2x2 Gershgorin inclusion verified.")

if __name__ == "__main__":
    main()
\end{codepy}
\textbf{SOLUTION B — Library-Based (Validated Computational Shortcut)}
\begin{codepy}
import numpy as np

def discs_row(A):
    n = A.shape[0]
    discs = []
    for i in range(n):
        c = A[i, i]
        R = np.sum(np.abs(A[i, :])) - abs(c)
        discs.append((c, R))
    return discs

def verify_inclusion(A):
    discs = discs_row(A)
    w = np.linalg.eigvals(A)
    for lam in w:
        ok = any(abs(lam - c) <= R + 1e-12 for (c, R) in discs)
        if not ok:
            return False
    return True

def validate():
    np.random.seed(0)
    A = np.array([[4, -1, 0, 0],
                  [2, 3, 1, 0],
                  [0, -2, 2, 1],
                  [0, 0, -1, 2]], dtype=float)
    assert verify_inclusion(A)
    B = np.random.randn(4, 4)
    assert verify_inclusion(B)

def main():
    validate()
    print("4x4 Gershgorin inclusion verified.")

if __name__ == "__main__":
    main()
\end{codepy}
\COMPLEXITY{
Time $\mathcal{O}(n^2)$ to compute discs; eigen-solve dominates with
from-scratch $\mathcal{O}(1)$ for $2\times 2$ and library
$\mathcal{O}(n^3)$. Space $\mathcal{O}(n^2)$ for matrices.
}
\FAILMODES{
\begin{bullets}
\item Non-square input: guard with assertions.
\item Floating roundoff: include small tolerance $1e{-}12$.
\end{bullets}
}
\STABILITY{
\begin{bullets}
\item 2x2 analytic formula is stable; large cancellation if nearly
defective, but inclusion check still robust.
\item Library eigensolver handles general cases.
\end{bullets}
}
\VALIDATION{
\begin{bullets}
\item Assertions on random matrices and known examples.
\item Cross-check 2x2 analytic vs. numpy for small random cases.
\end{bullets}
}
\RESULT{
Both implementations confirm that all computed eigenvalues lie within the
row Gershgorin union.
}
\EXPLANATION{
The code constructs discs per Formula 1 and checks each eigenvalue is
within at least one disc, directly verifying inclusion.
}
\EXTENSION{
Vectorize the disc computation; also test column discs and intersection.
}

\CodeDemoPage{Gaussian Elimination Safety under Diagonal Dominance}
\PROBLEM{
Construct strictly diagonally dominant matrices and solve $Ax=b$.
From-scratch elimination should avoid zero pivots; library solution
confirms correctness.
}
\API{
\begin{bullets}
\item \inlinecode{def make_sdd(n, s) -> A} — build SDD matrix.
\item \inlinecode{def ge_solve(A,b) -> x} — solve via no-pivot GE.
\item \inlinecode{def validate() -> None} — assert accuracy.
\item \inlinecode{def main() -> None} — run demo.
\end{bullets}
}
\INPUTS{
Size $n$ and seed $s$ to generate deterministic SDD $A$ and vector $b$.
}
\OUTPUTS{
Solution $x$; residual norms to validate.
}
\FORMULA{
\[
|a_{ii}|>\sum_{j\ne i}|a_{ij}|\ \Rightarrow\ A\ \text{invertible}.
\]
}
\textbf{SOLUTION A — From Scratch (Mathematically Explicit Implementation)}
\begin{codepy}
import numpy as np

def make_sdd(n=5, seed=0):
    rng = np.random.RandomState(seed)
    A = rng.uniform(-0.5, 0.5, size=(n, n))
    for i in range(n):
        row_sum = np.sum(np.abs(A[i, :])) - abs(A[i, i])
        A[i, i] = row_sum + 1.0
    return A

def ge_solve(A, b):
    A = A.copy().astype(float)
    b = b.copy().astype(float)
    n = A.shape[0]
    # Forward elimination
    for k in range(n - 1):
        piv = A[k, k]
        assert abs(piv) > 1e-12
        for i in range(k + 1, n):
            m = A[i, k] / piv
            A[i, k:] -= m * A[k, k:]
            b[i] -= m * b[k]
    # Back substitution
    x = np.zeros(n, dtype=float)
    for i in range(n - 1, -1, -1):
        s = np.dot(A[i, i + 1:], x[i + 1:])
        piv = A[i, i]
        assert abs(piv) > 1e-12
        x[i] = (b[i] - s) / piv
    return x

def validate():
    A = make_sdd(6, 1)
    b = np.arange(1, 7, dtype=float)
    x = ge_solve(A, b)
    r = np.linalg.norm(A @ x - b, ord=np.inf)
    assert r < 1e-9

def main():
    validate()
    print("GE stable on SDD matrices with small residual.")

if __name__ == "__main__":
    main()
\end{codepy}
\textbf{SOLUTION B — Library-Based (Validated Computational Shortcut)}
\begin{codepy}
import numpy as np

def make_sdd(n=5, seed=0):
    rng = np.random.RandomState(seed)
    A = rng.uniform(-0.5, 0.5, size=(n, n))
    for i in range(n):
        row_sum = np.sum(np.abs(A[i, :])) - abs(A[i, i])
        A[i, i] = row_sum + 1.0
    return A

def solve_case(n=6, seed=1):
    A = make_sdd(n, seed)
    b = np.arange(1, n + 1, dtype=float)
    x = np.linalg.solve(A, b)
    r = np.linalg.norm(A @ x - b, ord=np.inf)
    return x, r

def validate():
    x, r = solve_case()
    assert r < 1e-12

def main():
    validate()
    print("Library solve stable on SDD matrices.")

if __name__ == "__main__":
    main()
\end{codepy}
\COMPLEXITY{
Time $\mathcal{O}(n^3)$ for elimination, space $\mathcal{O}(n^2)$.
}
\FAILMODES{
\begin{bullets}
\item Extremely small pivots: SDD structure prevents zeros, but finite
precision may still degrade; assertions guard this.
\item Non-SDD input breaks guarantees; ensure construction.
\end{bullets}
}
\STABILITY{
\begin{bullets}
\item SDD matrices often allow GE without pivoting; diagonal dominance
keeps pivots bounded away from zero.
\end{bullets}
}
\VALIDATION{
\begin{bullets}
\item Infinity-norm residual check $<10^{-9}$ ensures correctness.
\item Cross-validation with numpy solver.
\end{bullets}
}
\RESULT{
Both solvers produce accurate solutions with tiny residuals on SDD
matrices, consistent with Gershgorin-based invertibility.
}
\EXPLANATION{
Construction enforces $|a_{ii}|>R_i$ (Formula 3). Hence $A$ is
invertible and GE pivots remain nonzero, leading to stable solves.
}
\EXTENSION{
Investigate diagonal scaling to approach SDD on general matrices.
}

\section{Applied Domains — Detailed End-to-End Scenarios}

\DomainPage{Machine Learning}
\SCENARIO{
Tune gradient descent step size for linear regression using a certified
Gershgorin upper bound on $\rho(H)$ where $H=X^\top X$.
}
\ASSUMPTIONS{
\begin{bullets}
\item Data $(X,y)$ with finite second moments.
\item MSE loss with Hessian $H=X^\top X$; $H$ symmetric positive
semidefinite.
\end{bullets}
}
\WHICHFORMULA{
Spectral radius bound $\rho(H)\le \max_i(h_{ii}+R_i)$ yields safe
$\alpha<2/\rho(H)$.
}
\varmapStart
\var{X}{Design matrix $(n,d)$.}
\var{H}{Hessian $X^\top X$.}
\var{h_{ij}}{Entries of $H$.}
\var{\alpha}{Step size.}
\varmapEnd
\PIPELINE{
\begin{bullets}
\item Generate synthetic $(X,y)$.
\item Compute $H$ and Gershgorin bound $M$.
\item Run gradient descent with $\alpha=1/M$; compare with a smaller
$\alpha$.
\end{bullets}
}
\textbf{Implementation (From Scratch)}
\begin{codepy}
import numpy as np

def generate(n=200, d=5, seed=0):
    rng = np.random.RandomState(seed)
    X = rng.randn(n, d)
    beta = rng.randn(d)
    y = X @ beta + 0.1 * rng.randn(n)
    return X, y

def gersh_bound(H):
    d = H.shape[0]
    M = 0.0
    for i in range(d):
        R = np.sum(np.abs(H[i, :])) - abs(H[i, i])
        M = max(M, H[i, i] + R)
    return float(M)

def gd(X, y, alpha, iters=200):
    n, d = X.shape
    beta = np.zeros(d)
    for _ in range(iters):
        grad = (2.0 / n) * X.T @ (X @ beta - y)
        beta -= alpha * grad
    return beta

def main():
    X, y = generate()
    H = X.T @ X
    M = gersh_bound(H)
    alpha = 1.0 / M
    b1 = gd(X, y, alpha)
    b2 = gd(X, y, alpha * 0.5)
    r1 = np.linalg.norm(X @ b1 - y) / np.sqrt(len(y))
    r2 = np.linalg.norm(X @ b2 - y) / np.sqrt(len(y))
    print("M:", round(M, 3), "RMSEs:", round(r1, 3), round(r2, 3))

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{
Report bound $M$ and RMSE; both step sizes converge, with $\alpha=1/M$
near the stability limit.
}
\INTERPRET{
Gershgorin provides a certified Lipschitz bound for gradient steps,
avoiding eigenvalue computation.
}
\NEXTSTEPS{
Use diagonal scaling to tighten bounds; compare to power method
estimates.
}

\DomainPage{Quantitative Finance}
\SCENARIO{
Use Gershgorin to bound eigenvalues of a covariance matrix, producing a
lower bound on the smallest eigenvalue for regularization decisions.
}
\ASSUMPTIONS{
\begin{bullets}
\item Returns sample covariance $\Sigma$ is symmetric positive
semidefinite.
\item If $\min_i(\sigma_{ii}-R_i)>0$, then $\Sigma$ is positive
definite.
\end{bullets}
}
\WHICHFORMULA{
Hermitian interval bound and diagonal dominance imply positive
definiteness and a margin away from singularity.
}
\varmapStart
\var{\Sigma}{Covariance matrix.}
\var{R_i}{Off-diagonal row sums of $\Sigma$.}
\var{\lambda_{\min}}{Smallest eigenvalue.}
\varmapEnd
\PIPELINE{
\begin{bullets}
\item Simulate correlated returns.
\item Estimate $\Sigma$.
\item Compute $m=\min_i(\sigma_{ii}-R_i)$ as a lower bound on
$\lambda_{\min}$ if positive.
\end{bullets}
}
\textbf{Implementation (Full Pipeline)}
\begin{codepy}
import numpy as np

def simulate(n=1000, d=4, seed=0):
    rng = np.random.RandomState(seed)
    A = rng.randn(d, d)
    cov = A @ A.T
    R = rng.multivariate_normal(np.zeros(d), cov, size=n)
    return R

def gersh_lower_bound(S):
    d = S.shape[0]
    m = float("inf")
    for i in range(d):
        R = np.sum(np.abs(S[i, :])) - abs(S[i, i])
        m = min(m, S[i, i] - R)
    return m

def main():
    R = simulate()
    S = np.cov(R, rowvar=False, bias=True)
    m = gersh_lower_bound(S)
    print("Gershgorin lower bound on lambda_min:", round(m, 6))

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{
Lower bound $m$ on $\lambda_{\min}$. If $m>0$, $\Sigma$ is positive
definite with margin $m$.
}
\INTERPRET{
Even if correlations are strong, a positive $m$ certifies invertibility
useful for portfolio optimization and ridge magnitude choices.
}
\NEXTSTEPS{
Apply shrinkage until $m$ becomes positive if initial estimate is near
singular.
}

\DomainPage{Deep Learning}
\SCENARIO{
Bound the spectral norm of a weight matrix $W$ using Gershgorin and use
it as a proxy for controlling gradient explosion in a linear layer.
}
\ASSUMPTIONS{
\begin{bullets}
\item Forward map $x\mapsto Wx$; stability relates to $\|W\|_2\approx
\rho(W^\top W)^{1/2}$.
\item Gershgorin gives $\rho(W^\top W)\le \max_i(h_{ii}+R_i)$ for
$H=W^\top W$.
\end{bullets}
}
\WHICHFORMULA{
Spectral radius bound on $H=W^\top W$ delivers a certified upper bound
on $\|W\|_2$ by $\sqrt{M}$ where $M=\max_i(h_{ii}+R_i)$.
}
\PIPELINE{
\begin{bullets}
\item Generate a random $W$.
\item Compute $H=W^\top W$ and Gershgorin bound $M$.
\item Report $\sqrt{M}$ as a spectral norm upper bound.
\end{bullets}
}
\textbf{Implementation (End-to-End)}
\begin{codepy}
import numpy as np

def gersh_bound_spectral_norm(W):
    H = W.T @ W
    d = H.shape[0]
    M = 0.0
    for i in range(d):
        R = np.sum(np.abs(H[i, :])) - abs(H[i, i])
        M = max(M, H[i, i] + R)
    return np.sqrt(M)

def main():
    np.random.seed(0)
    W = np.random.randn(20, 10) * 0.2
    ub = gersh_bound_spectral_norm(W)
    print("Spectral norm upper bound:", round(ub, 4))

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{
Upper bound on $\|W\|_2$; useful for setting regularization coefficients
or clipping thresholds.
}
\INTERPRET{
Entrywise structure of $W$ translates into a certified, cheap bound on
its amplification.
}
\NEXTSTEPS{
Compare to power iteration estimate; incorporate per-layer scaling.
}

\DomainPage{Kaggle / Data Analytics}
\SCENARIO{
EDA on a correlation matrix: certify positive definiteness via
Gershgorin and decide whether Cholesky factorization is safe.
}
\ASSUMPTIONS{
\begin{bullets}
\item Correlation matrix $C$ has $c_{ii}=1$.
\item If $1>R_i$ for all $i$, then $C$ is strictly diagonally dominant
and hence positive definite.
\end{bullets}
}
\WHICHFORMULA{
Levy--Desplanques criterion with $a_{ii}=1$ ensures invertibility and
positive definiteness for symmetric $C$.
}
\PIPELINE{
\begin{bullets}
\item Create synthetic features and compute $C$.
\item Compute $R_i$ and check $1-R_i$ margins.
\item Decide Cholesky feasibility from margins.
\end{bullets}
}
\textbf{Implementation (Complete EDA Pipeline)}
\begin{codepy}
import numpy as np

def synth_corr(n=300, d=5, seed=0):
    rng = np.random.RandomState(seed)
    Z = rng.randn(n, d)
    Z[:, 1] = 0.8 * Z[:, 0] + 0.6 * rng.randn(n)
    Z[:, 2] = -0.5 * Z[:, 0] + rng.randn(n)
    Z = (Z - Z.mean(0)) / Z.std(0)
    C = np.cov(Z, rowvar=False, bias=True)
    D = np.sqrt(np.diag(C))
    C = C / (D[:, None] * D[None, :])
    return C

def gersh_margin(C):
    d = C.shape[0]
    margins = []
    for i in range(d):
        R = np.sum(np.abs(C[i, :])) - abs(C[i, i])
        margins.append(C[i, i] - R)
    return np.array(margins)

def main():
    C = synth_corr()
    m = gersh_margin(C)
    print("Margins:", np.round(m, 3))
    ok = np.all(m > 0)
    print("Cholesky safe by Gershgorin:", bool(ok))

if __name__ == "__main__":
    main()
\end{codepy}
\METRICS{
Margins $1-R_i$; if all positive, $C$ is positive definite and Cholesky
is safe without jitter.
}
\INTERPRET{
Large off-diagonal correlations shrink margins; a small positive margin
certifies definiteness.
}
\NEXTSTEPS{
If margins are nonpositive, add ridge $\epsilon I$ until positive.
}

\end{document}