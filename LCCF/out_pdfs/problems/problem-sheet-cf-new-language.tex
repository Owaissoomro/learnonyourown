% !TeX program = xelatex
\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{microtype}
\usepackage{setspace}\setstretch{1.05}
\usepackage{fontspec}
\setmainfont{Latin Modern Roman}
\setmonofont{Latin Modern Mono}[BoldFont={Latin Modern Mono},ItalicFont={Latin Modern Mono}]
\usepackage{amsmath,mathtools,amsthm}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\usepackage{unicode-math}\setmathfont{Latin Modern Math}\allowdisplaybreaks[4]
% --- overflow and alignment slack ---
\setlength{\jot}{7pt}
\sloppy\emergencystretch=8em\hfuzz=1pt\vfuzz=2pt\raggedbottom
% --- breakable math helpers ---
\newenvironment{BreakableEquation}{\begin{equation}\begin{aligned}}{\end{aligned}\end{equation}}
\newenvironment{BreakableEquation*}{\begin{equation*}\begin{aligned}}{\end{aligned}\end{equation*}}
\newenvironment{tightalign}{\begingroup\small\allowdisplaybreaks\begin{align}}{\end{align}\endgroup}

\usepackage{xcolor}
\usepackage{xurl} % better URL wrapping
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue]{hyperref}
\usepackage{fancyhdr}
\pagestyle{fancy}\fancyhf{}\lhead{\nouppercase{\leftmark}}\rhead{\thepage}\setlength{\headheight}{26pt}
\usepackage{enumitem,booktabs,tabularx}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\renewcommand{\arraystretch}{1.1}
\setlength{\parindent}{0pt}\setlength{\parskip}{8pt plus 2pt minus 1pt}

% Listings + upquote (no shell-escape needed)
\usepackage{listings}
\usepackage{upquote}
\lstdefinestyle{crisp}{
  basicstyle=\ttfamily\footnotesize,
  frame=single,
  breaklines=true,
  breakatwhitespace=false, % allow breaks inside long tokens
  tabsize=4,
  showstringspaces=false,
  numbers=left,
  numberstyle=\tiny,
  numbersep=8pt,
  keepspaces=true,
  columns=fullflexible,
  backgroundcolor=\color{black!02},
  aboveskip=8pt,
  belowskip=8pt
}
% Guarantee that 'python' exists as a language for listings
\lstdefinelanguage{python}{
  morekeywords={def,return,class,if,elif,else,for,while,try,except,raise,assert,pass,break,continue,lambda,nonlocal,global,yield,import,from,as,with,True,False,None},
  sensitive=true,
  morecomment=[l]\#,
  morestring=[b]",
  morestring=[b]'
}
% minted shim (robust; no shell-escape; uses listings' own environment)
\lstnewenvironment{minted}[2][]{\lstset{style=crisp,language=#2,#1}}{}

\usepackage[most]{tcolorbox}
\tcbset{colback=white,colframe=black!15,boxrule=0.4pt,arc=2pt,left=6pt,right=6pt,top=6pt,bottom=6pt,before skip=10pt,after skip=10pt,breakable}
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection}{0.6em}{}
\titlespacing*{\section}{0pt}{*2.0}{*1.0}

% ===== CONSISTENCY TOOLKIT (macros) =====
\newlist{ledger}{enumerate}{1}
\setlist[ledger]{label=\textbullet,leftmargin=2em,itemsep=2pt,topsep=6pt}
\newcommand{\LEDGER}[1]{\textbf{ARITHMETIC LEDGER:}\par\begin{ledger}#1\end{ledger}}

\newlist{algosteps}{enumerate}{1}
\setlist[algosteps]{label=\arabic*.,leftmargin=2em,itemsep=2pt,topsep=6pt}

\newlist{bullets}{itemize}{1}
\setlist[bullets]{label=--,leftmargin=1.6em,itemsep=2pt,topsep=4pt}

\newcommand{\varmapStart}{\textbf{VARIABLE MAPPING:}\par\begin{bullets}}
\newcommand{\var}[2]{\item $#1$ — #2}
\newcommand{\varmapEnd}{\end{bullets}}

\newcommand{\LINE}[2]{\par\noindent\textbf{#1:}~#2\par}
\newcommand{\WHAT}[1]{\LINE{WHAT}{#1}}
\newcommand{\WHY}[1]{\LINE{WHY}{#1}}
\newcommand{\HOW}[1]{\LINE{HOW}{#1}}
\newcommand{\ELI}[1]{\LINE{ELI5}{#1}}
\newcommand{\STATEMENT}[1]{\LINE{STATEMENT}{#1}}
\newcommand{\BREAKDOWN}[1]{\LINE{PROBLEM BREAKDOWN}{#1}}
\newcommand{\MODEL}[1]{\LINE{CANONICAL MATHEMATICAL MODEL}{#1}}
\newcommand{\ASSUMPTIONS}[1]{\LINE{ASSUMPTIONS}{#1}}
\newcommand{\INVARIANTS}[1]{\LINE{INVARIANTS}{#1}}
\newcommand{\WHICHFORMULA}[1]{\LINE{WHICH FORMULA \& WHY}{#1}}
\newcommand{\GOVERN}[1]{\LINE{GOVERNING EQUATION(S)}{#1}}
\newcommand{\INPUTS}[1]{\LINE{INPUTS}{#1}}
\newcommand{\OUTPUTS}[1]{\LINE{OUTPUTS}{#1}}
\newcommand{\SAMPLES}[1]{\LINE{SAMPLES}{#1}}
\newcommand{\RESULT}[1]{\LINE{RESULT}{#1}}
\newcommand{\COMPLEXITY}[1]{\LINE{TIME/SPACE COMPLEXITY}{#1}}
\newcommand{\MEMORY}[1]{\LINE{MEMORY FOOTPRINT}{#1}}
\newcommand{\CORRECTNESS}[1]{\LINE{CORRECTNESS SKETCH}{#1}}
\newcommand{\OPTIMALITY}[1]{\LINE{OPTIMALITY}{#1}}
\newcommand{\FAILMODES}[1]{\LINE{FAILURE MODES}{#1}}
\newcommand{\VALIDATION}[1]{\LINE{VALIDATION}{#1}}
\newcommand{\UNITCHECK}[1]{\LINE{UNIT CHECK}{#1}}
\newcommand{\EDGECASES}[1]{\LINE{EDGE CASES}{#1}}
\newcommand{\CHECKLIST}[1]{\LINE{CHECKLIST}{#1}}
\newcommand{\DERIV}[1]{\LINE{DERIVATION}{#1}}
\newcommand{\LEMMAHEAD}[1]{\LINE{SUPPORTING LEMMA}{#1}}
\newcommand{\PITFALLS}[1]{\LINE{PITFALLS}{#1}}

\usepackage{etoolbox}\pretocmd{\section}{\clearpage}{}{}

\newcommand{\FormulaPage}[2]{%
  \clearpage
  \section*{Formula #1 — #2}%
  \addcontentsline{toc}{section}{Formula #1 — #2}%
}
\newcommand{\ApproachPage}[2]{%
  \clearpage
  \subsection*{Approach #1 — #2}%
  \addcontentsline{toc}{subsection}{Approach #1 — #2}%
}

\begin{document}
\title{Interview Problem Sheet — New Language}
\date{\today}
\author{}
\maketitle
\tableofcontents
\clearpage

% === Notes macro (BODY-ONLY; do not alter the preamble) ===
% Prints exactly N blank pages with empty headers/footers, then leaves you on the last blank page.
\newcommand{\NotePages}[1]{%
  \clearpage
  \begingroup
  \newcount\NPi \newcount\NPn
  \NPi=0 \NPn=#1
  \loop\ifnum\NPi<\NPn
    \advance\NPi by 1
    \mbox{}\thispagestyle{empty}%
    \ifnum\NPi<\NPn\clearpage\fi
  \repeat
  \endgroup
}

% ============ 1. Problem & Metadata (own page) ============
\section{Problem \& Metadata}
\LINE{PLATFORM}{CF}
\LINE{URL}{\url{https://codeforces.com/problemset/problem/568/C}}
\LINE{DIFFICULTY / RATING}{2600}
\STATEMENT{Living in Byteland was good enough to begin with, but the good king decided to please his subjects and to introduce a national language. He gathered the best of wise men, and sent an expedition to faraway countries, so that they would find out all about how a language should be designed.

After some time, the wise men returned from the trip even wiser. They locked up for six months in the dining room, after which they said to the king: ``there are a lot of different languages, but almost all of them have letters that are divided into vowels and consonants; in a word, vowels and consonants must be combined correctly.''

There are very many rules, all of them have exceptions, but our language will be deprived of such defects! We propose to introduce a set of formal rules of combining vowels and consonants, and include in the language all the words that satisfy them.

The rules of composing words are:
\begin{itemize}
\item The letters are divided into vowels and consonants in some certain way;
\item All words have a length of exactly $n$;
\item There are $m$ rules of the form $(\text{pos}_1, t_1, \text{pos}_2, t_2)$. Each rule is: if the position $\text{pos}_1$ has a letter of type $t_1$, then the position $\text{pos}_2$ has a letter of type $t_2$.
\end{itemize}

You are given some string $s$ of length $n$, it is not necessarily a correct word of the new language. Among all the words of the language that are lexicographically not smaller than the string $s$, find the minimal one in lexicographic order.

Input:
The first line contains a single line consisting of letters \texttt{V} (Vowel) and \texttt{C} (Consonant), determining which letters are vowels and which letters are consonants. The length of this string $l$ is the size of the alphabet of the new language ($1 \le l \le 26$). The first $l$ letters of the English alphabet are used as the letters of the alphabet of the new language. If the $i$-th character of the string equals to \texttt{V}, then the corresponding letter is a vowel, otherwise it is a consonant.

The second line contains two integers $n, m$ ($1 \le n \le 200$, $0 \le m \le 4n(n - 1)$) — the number of letters in a single word and the number of rules, correspondingly.

Next $m$ lines describe $m$ rules of the language in the following format: $\text{pos}_1, t_1, \text{pos}_2, t_2$ ($1 \le \text{pos}_1, \text{pos}_2 \le n$, $\text{pos}_1 \ne \text{pos}_2$, $t_1, t_2 \in \{\text{'V'}, \text{'C'}\}$).

The last line contains string $s$ of length $n$, consisting of the first $l$ small letters of the English alphabet.

It is guaranteed that no two rules are the same.

Output:
Print a smallest word of the language that is lexicographically not smaller than $s$. If such a word does not exist (for example, if the language has no words at all), print ``-1'' (without the quotes).

Note:
In the first test word ``aa'' is not a word of the language, but word ``ab'' is.

In the second test out of all four possibilities only word ``bb'' is not a word of a language, but all other words are lexicographically less, so there is no answer.

In the third test, due to the last rule, ``abac'' does not belong to the language (``a'' is a vowel, ``c'' is a consonant). The only word with prefix ``ab'' that meets the given rules is ``abaa''. But it is less than ``abac'', so the answer will be ``acaa''.}
\BREAKDOWN{Encode positions as boolean variables ``is vowel?'' and rules as implications between literals. Then search the lexicographically minimal word $\ge s$ by building it left-to-right with backtracking, checking extendability via 2-SAT implication-closure at each choice.}
\ELI{Treat each position as needing either a vowel or a consonant, obeying ``if-then'' rules; pick letters from smallest to largest while ensuring the remaining positions can still be filled.}
\NotePages{3}

% ============ 2. IO Contract (own page) ============
\section{IO Contract}
\INPUTS{A string of length $l$ over \{\texttt{V},\texttt{C}\}; integers $n, m$; $m$ rules of the form $\text{pos}_1~t_1~\text{pos}_2~t_2$; and a string $s$ of length $n$ over the first $l$ lowercase letters.}
\OUTPUTS{One string of length $n$ — the lexicographically smallest valid word that is $\ge s$, or \texttt{-1} if none exists.}
\SAMPLES{Example (customized):\\
1) Input: V C mapping for $l{=}2$; $n{=}2, m{=}1$, rule $1~\text{V}~2~\text{C}$; $s=\text{``aa''}$. Output: \texttt{ab}.\\
2) If rules force contradiction for all words, output \texttt{-1}.}
\NotePages{3}

% ============ 3. Canonical Mathematical Model (own page) ============
\section{Canonical Mathematical Model}
\MODEL{Let variables $x_i \in \{\text{V},\text{C}\}$ denote the type (vowel/consonant) at position $i \in \{1,\ldots,n\}$. For each rule $(p_1,t_1,p_2,t_2)$, add implication $[x_{p_1}{=}t_1] \Rightarrow [x_{p_2}{=}t_2]$. Letters are the first $l$ lowercase letters; each letter $a_k$ has fixed type $\tau(a_k)\in\{\text{V},\text{C}\}$.}
\varmapStart
\var{x_i}{type at position $i$ (V or C)}
\var{t_1,t_2}{types in a rule, each in $\{\text{V},\text{C}\}$}
\var{\tau(a)}{type of letter $a$ from the alphabet}
\var{s}{lower bound string}
\var{w}{candidate answer string}
\varmapEnd
\GOVERN{
\[
\begin{aligned}
&\text{For each rule }(p_1,t_1,p_2,t_2): && (x_{p_1}{=}t_1) \Rightarrow (x_{p_2}{=}t_2), \\
&\text{Lex constraint:} && w \ge s \text{ lexicographically}, \\
&\text{Per-position consistency:} && \tau(w_i) = x_i \quad \forall i.
\end{aligned}
\]
}
\ASSUMPTIONS{Only the first $l$ letters are used; each letter has a fixed type. Implications are between positions, not letters.}
\INVARIANTS{If a literal is chosen true, all literals it implies must also be true. No variable can have both $x_i{=}\text{V}$ and $x_i{=}\text{C}$ simultaneously.}
\NotePages{3}

% ============ 4. Approach A — Baseline (own page) ============
\section{Approach A — Baseline}
\ApproachPage{A}{Brute Force / Direct}
\WHICHFORMULA{Model each position $i$ as binary (V/C). Enumerate all words $\ge s$ in lexicographic order and test constraints by implication closure.}
\ASSUMPTIONS{Feasible only for tiny $n$; used for validation and intuition.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Enumerate words $w$ in nondecreasing lex order starting at $s$.
\item Map $w$ to types $x_i=\tau(w_i)$ and check all implications transitively.
\item Return the first valid $w$ or \texttt{-1} if none.
\end{algosteps}
\COMPLEXITY{Exponential in $n$; only suitable for tiny instances.}
\[
\begin{aligned}
T(n) &= O(l^n) \\
S(n) &= O(n+m).
\end{aligned}
\]
\CORRECTNESS{By exhaustive enumeration in lex order, the first valid word is the minimal one.}
\EDGECASES{Empty rule set; all letters same type; $s$ already invalid but answer exists; no answer at all.}
\textbf{Code (Baseline)}
\begin{minted}{python}
import sys

def read_input():
    return sys.stdin.read().strip().splitlines()

def brute_solve(vowel_mask, n, m, rules, s):
    # Precompute type of each letter
    l = len(vowel_mask)
    is_vowel = [c == 'V' for c in vowel_mask]
    # Build implication adjacency between literals: id = 2*pos + (1 if V else 0)
    # rules: (p1, t1, p2, t2)
    N = 2 * n
    adj = [[] for _ in range(N)]
    def lit_id(pos, isV):
        return 2*pos + (1 if isV else 0)
    def add_imp(p1, t1, p2, t2):
        u = lit_id(p1, t1 == 'V')
        v = lit_id(p2, t2 == 'V')
        adj[u].append(v)
        # contrapositive: not v -> not u
        adj[v ^ 1].append(u ^ 1)
    for (p1, t1, p2, t2) in rules:
        add_imp(p1-1, t1, p2-1, t2)

    # fast closure check via DFS from a set of literals
    def is_extendable(assign_lits):
        # gather all literals implied by the asserted literals
        seen = [False]*N
        stack = []
        for l in assign_lits:
            if not seen[l]:
                seen[l] = True
                stack.append(l)
        while stack:
            u = stack.pop()
            for v in adj[u]:
                if not seen[v]:
                    seen[v] = True
                    stack.append(v)
        # conflict if both literals of a variable are seen
        for i in range(n):
            if seen[2*i] and seen[2*i+1]:
                return False
        return True

    letters = [chr(ord('a') + i) for i in range(l)]

    # Generate words in lex order starting from s (tiny only!)
    # Recursive generator with pruning by extendability on types
    best = None
    def dfs(i, prefix, assign_lits):
        nonlocal best
        if best is not None:
            return
        if i == n:
            best = prefix
            return
        lb = s[i] if prefix == s[:i] else 'a'
        for ch in letters:
            if ch < lb:
                continue
            lit = 2*i + (1 if is_vowel[ord(ch)-97] else 0)
            new_assign = assign_lits + [lit]
            if is_extendable(new_assign):
                dfs(i+1, prefix + ch, new_assign)
                if best is not None:
                    return

    dfs(0, "", [])
    return best if best is not None else "-1"

def solve_all():
    data = read_input()
    if not data:
        return
    it = iter(data)
    vowel_mask = next(it).strip()
    n, m = map(int, next(it).split())
    rules = []
    for _ in range(m):
        parts = next(it).split()
        p1, t1, p2, t2 = int(parts[0]), parts[1], int(parts[2]), parts[3]
        rules.append((p1, t1, p2, t2))
    s = next(it).strip()
    ans = brute_solve(vowel_mask, n, m, rules, s)
    sys.stdout.write(ans + "\n")

if __name__ == "__main__":
    # Tiny sanity checks (baseline is only for very small n)
    inp = """VC
2 1
1 V 2 C
aa
"""
    out = []
    sys.setrecursionlimit(10000)
    def run_io(s):
        from io import StringIO
        bak_stdin, bak_stdout = sys.stdin, sys.stdout
        try:
            sys.stdin, sys.stdout = StringIO(s), StringIO()
            solve_all()
            return sys.stdout.getvalue()
        finally:
            sys.stdin, sys.stdout = bak_stdin, bak_stdout
    res = run_io(inp).strip()
    assert res == "ab"
    inp2 = """V
3 0
abc
"""
    # Only 'a' exists; 'b' and 'c' unavailable => impossible (since l=1), but s must be length n over first l letters; here invalid test skipped.
    print("OK")
\end{minted}
\VALIDATION{Validated on a tiny rule set where ``aa'' is invalid but ``ab'' is valid.}
\NotePages{3}

% ============ 5. Approach B — Improved (own page) ============
\section{Approach B — Improved}
\ApproachPage{B}{2-SAT With SCC Feasibility Checks}
\WHICHFORMULA{Encode each rule $(p_1,t_1,p_2,t_2)$ as an implication between literals and its contrapositive. Feasibility is decided by SCC on the implication graph; unit choices (fixing a type at a position) are additional implications.}
\ASSUMPTIONS{We can rebuild SCC per trial only for small sizes; in practice we avoid full rebuilds via precomputed closure in Approach C.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Build the 2-SAT implication graph on $2n$ literals and compute SCCs for feasibility.
\item Construct the answer from left to right with backtracking: at each position try letters in increasing order consistent with the current lex lower bound.
\item For each tentative letter, add a unit clause and check feasibility via SCC; accept if extendable, otherwise try next letter or backtrack.
\end{algosteps}
\COMPLEXITY{Each feasibility check via SCC is $O(n+m)$. In the worst case up to $O(nl)$ checks, total $O((n+m)nl)$.}
\[
\begin{aligned}
T(n) &\approx O((n+m)\,n\,l) \\
\end{aligned}
\]
\CORRECTNESS{2-SAT SCC decides extendability of partial assignments; lexicographically minimal is obtained by trying letters in increasing order with backtracking.}
\textbf{Code (Improved)}
\begin{minted}{python}
import sys

def read_input():
    return sys.stdin.read().strip().splitlines()

def scc_build(N, adj):
    sys.setrecursionlimit(1000000)
    radj = [[] for _ in range(N)]
    for u in range(N):
        for v in adj[u]:
            radj[v].append(u)
    vis = [False]*N
    order = []
    def dfs1(u):
        vis[u] = True
        for v in adj[u]:
            if not vis[v]:
                dfs1(v)
        order.append(u)
    for u in range(N):
        if not vis[u]:
            dfs1(u)
    comp = [-1]*N
    def dfs2(u, cid):
        comp[u] = cid
        for v in radj[u]:
            if comp[v] == -1:
                dfs2(v, cid)
    cid = 0
    for u in reversed(order):
        if comp[u] == -1:
            dfs2(u, cid)
            cid += 1
    return comp, cid

def improved_solve(vowel_mask, n, m, rules, s):
    l = len(vowel_mask)
    is_vowel = [c == 'V' for c in vowel_mask]
    N = 2*n
    def lit_id(pos, isV):
        return 2*pos + (1 if isV else 0)
    base_adj = [[] for _ in range(N)]
    def add_imp(p1, t1, p2, t2):
        u = lit_id(p1, t1 == 'V')
        v = lit_id(p2, t2 == 'V')
        base_adj[u].append(v)
        base_adj[v ^ 1].append(u ^ 1)
    for (p1, t1, p2, t2) in rules:
        add_imp(p1-1, t1, p2-1, t2)

    letters = [chr(ord('a') + i) for i in range(l)]
    # Backtracking with SCC feasibility for units
    ans = ['?']*n
    stack = []
    pos = 0
    pivot = -1  # first index where ans[idx] > s[idx], else -1
    cand_lists = []
    idx_lists = []
    while True:
        if pos == n:
            return "".join(ans)
        if pos == len(cand_lists):
            lb = s[pos] if pivot == -1 else 'a'
            cand = [ch for ch in letters if ch >= lb]
            cand_lists.append(cand)
            idx_lists.append(0)
        cand = cand_lists[pos]
        iref = idx_lists[pos]
        progressed = False
        while iref < len(cand):
            ch = cand[iref]
            # Build graph with unit clauses from chosen prefix + this choice
            adj = [nbrs[:] for nbrs in base_adj]
            for i_prev in range(pos):
                t = 'V' if is_vowel[ord(ans[i_prev])-97] else 'C'
                u = lit_id(i_prev, t == 'V')
                adj[u ^ 1].append(u)  # unit: not u -> u
            tcur = 'V' if is_vowel[ord(ch)-97] else 'C'
            ucur = lit_id(pos, tcur == 'V')
            adj[ucur ^ 1].append(ucur)
            comp, cc = scc_build(N, adj)
            ok = True
            for i in range(n):
                if comp[2*i] == comp[2*i+1]:
                    ok = False
                    break
            if ok:
                ans[pos] = ch
                idx_lists[pos] = iref + 1
                stack.append((pos, pivot))
                if pivot == -1 and ch > s[pos]:
                    pivot = pos
                pos += 1
                progressed = True
                break
            else:
                iref += 1
        if not progressed:
            # backtrack
            if not stack:
                return "-1"
            cand_lists[pos] = []
            idx_lists[pos] = 0
            pos, pivot = stack.pop()
            # advance at this pos
            iref = idx_lists[pos]
            idx_lists[pos] = iref  # will be incremented on next loop
            # try next candidate at this pos
            # reset deeper state
            for k in range(pos+1, len(cand_lists)):
                cand_lists[k] = []
                idx_lists[k] = 0
            # bump iref for current level
            # set ans placeholder to allow recompute
            ans[pos] = '?'
            # move to loop which will try next
            # also, if we had set pivot at this pos, recompute pivot from stack state (already handled)

def solve_all():
    data = read_input()
    if not data:
        return
    it = iter(data)
    vowel_mask = next(it).strip()
    n, m = map(int, next(it).split())
    rules = []
    for _ in range(m):
        parts = next(it).split()
        p1, t1, p2, t2 = int(parts[0]), parts[1], int(parts[2]), parts[3]
        rules.append((p1, t1, p2, t2))
    s = next(it).strip()
    ans = improved_solve(vowel_mask, n, m, rules, s)
    sys.stdout.write(ans + "\n")

if __name__ == "__main__":
    # Small asserts
    def run_io(s):
        from io import StringIO
        bak_stdin, bak_stdout = sys.stdin, sys.stdout
        try:
            sys.stdin, sys.stdout = StringIO(s), StringIO()
            solve_all()
            return sys.stdout.getvalue()
        finally:
            sys.stdin, sys.stdout = bak_stdin, bak_stdout
    inp = """VC
2 1
1 V 2 C
aa
"""
    assert run_io(inp).strip() == "ab"
    inp2 = """V
2 0
aa
"""
    assert run_io(inp2).strip() == "aa"
    print("OK")
\end{minted}
\VALIDATION{Checked simple cases: trivial rules, and a rule forcing the second letter to be a consonant when the first is a vowel.}
\NotePages{3}

% ============ 6. Approach C — Optimal (own page) ============
\section{Approach C — Optimal}
\ApproachPage{C}{2-SAT With SCC Condensation and Bitset Reachability}
\WHICHFORMULA{Compute SCCs once on the base implication graph, build the DAG of components, and precompute for each component the set of literals it reaches (bitset). Then perform lexicographic DFS with backtracking, extending a bitset of forced literals using OR of precomputed closures to test consistency in $O(n)$ per try.}
\ASSUMPTIONS{Graph size is bounded ($2n \le 400$); Python integer bitsets suffice for fast closure OR operations.}
\textbf{Algorithm Steps}
\begin{algosteps}
\item Build implication graph for $2n$ literals: $(p_1,t_1)\Rightarrow(p_2,t_2)$ and $\lnot(p_2,t_2)\Rightarrow\lnot(p_1,t_1)$.
\item Compute SCCs and the condensation DAG. For each component $c$, compute a bitset mask of all literal-nodes reachable from $c$ (including itself) by DP over the DAG in reverse topological order.
\item Maintain a stack with the current bitset of implied literals. At position $i$, generate candidate letters in increasing order respecting the current lex lower bound (either $s[i]$ or \texttt{a}).
\item For a candidate letter $ch$ at $i$, compute new\_mask = cur\_mask OR closure\_mask of literal $(i,\tau(ch))$. If new\_mask contains both literals for any variable, reject; else accept and proceed. Backtrack if exhausted.
\end{algosteps}
\OPTIMALITY{First-found solution under this search is lexicographically minimal because we expand choices in increasing lex order and only prune infeasible prefixes using exact extendability conditions from implication closures.}
\COMPLEXITY{SCC and DAG preprocessing is $O(n+m)$. Each trial letter reduces to bitset OR and an $O(n)$ conflict scan. Total trials $O(nl)$ in typical/pruned cases.}
\[
\begin{aligned}
T(n) &\approx O(n+m) + O(nl \cdot n) = O(nm + n^2 l) \text{ in worst analysis; in practice, fast via bitsets}, \\
S(n) &= O(n + m) \text{ for graph} + O(n) \text{ for bitsets}.
\end{aligned}
\]
\textbf{Code (Final Submission)}
\begin{minted}{python}
import sys

def read_input():
    return sys.stdin.read().strip().splitlines()

def kosaraju_scc(N, adj):
    sys.setrecursionlimit(1_000_000)
    radj = [[] for _ in range(N)]
    for u in range(N):
        for v in adj[u]:
            radj[v].append(u)
    vis = [False]*N
    order = []
    def dfs1(u):
        vis[u] = True
        for v in adj[u]:
            if not vis[v]:
                dfs1(v)
        order.append(u)
    for u in range(N):
        if not vis[u]:
            dfs1(u)
    comp = [-1]*N
    def dfs2(u, cid):
        comp[u] = cid
        for v in radj[u]:
            if comp[v] == -1:
                dfs2(v, cid)
    cid = 0
    for u in reversed(order):
        if comp[u] == -1:
            dfs2(u, cid)
            cid += 1
    return comp, cid

def solve_case(vowel_mask, n, m, rules, s):
    l = len(vowel_mask)
    is_vowel_letter = [c == 'V' for c in vowel_mask]
    N = 2 * n
    def lit_id(pos, isV):
        return 2*pos + (1 if isV else 0)
    # Build base implication graph
    adj = [[] for _ in range(N)]
    def add_imp(p1, t1, p2, t2):
        u = lit_id(p1, t1 == 'V')
        v = lit_id(p2, t2 == 'V')
        adj[u].append(v)
        adj[v ^ 1].append(u ^ 1)
    for (p1, t1, p2, t2) in rules:
        add_imp(p1-1, t1, p2-1, t2)
    # Precompute SCC and condensation DAG
    comp, C = kosaraju_scc(N, adj)
    # If base graph already contradicts without units (rare due to no unit), still check:
    for i in range(n):
        if comp[2*i] == comp[2*i+1]:
            return "-1"
    dag = [set() for _ in range(C)]
    comp_nodes_mask = [0]*C
    for u in range(N):
        cu = comp[u]
        comp_nodes_mask[cu] |= (1 << u)
        for v in adj[u]:
            cv = comp[v]
            if cu != cv:
                dag[cu].add(cv)
    # Topo order by Kahn
    indeg = [0]*C
    for u in range(C):
        for v in dag[u]:
            indeg[v] += 1
    from collections import deque
    dq = deque([u for u in range(C) if indeg[u] == 0])
    topo = []
    while dq:
        u = dq.popleft()
        topo.append(u)
        for v in dag[u]:
            indeg[v] -= 1
            if indeg[v] == 0:
                dq.append(v)
    # DP: reachable nodes mask for each component
    reach_nodes_mask = [0]*C
    for u in reversed(topo):
        mask = comp_nodes_mask[u]
        for v in dag[u]:
            mask |= reach_nodes_mask[v]
        reach_nodes_mask[u] = mask
    # Closure bitset for each literal node
    lit_closure = [0]*N
    for u in range(N):
        lit_closure[u] = reach_nodes_mask[comp[u]]
    # Letters
    letters = [chr(ord('a') + i) for i in range(l)]
    # Backtracking with bitset closures
    ans = ['?']*n
    cur_mask_stack = [0]  # mask for current prefix closures
    pivot_stack = [-1]
    pos = 0
    # per-depth candidate lists and indices
    cand_lists = []
    idx_lists = []
    while True:
        if pos == n:
            return "".join(ans)
        cur_mask = cur_mask_stack[-1]
        pivot = pivot_stack[-1]
        if pos == len(cand_lists):
            lb = s[pos] if pivot == -1 else 'a'
            cand = [ch for ch in letters if ch >= lb]
            cand_lists.append(cand)
            idx_lists.append(0)
        cand = cand_lists[pos]
        iref = idx_lists[pos]
        progressed = False
        while iref < len(cand):
            ch = cand[iref]
            t_isV = is_vowel_letter[ord(ch) - 97]
            lit = 2*pos + (1 if t_isV else 0)
            new_mask = cur_mask | lit_closure[lit]
            # conflict check
            conflict = False
            mm = new_mask
            for i in range(n):
                if ((mm >> (2*i)) & 3) == 3:
                    conflict = True
                    break
            if not conflict:
                # accept
                ans[pos] = ch
                cur_mask_stack.append(new_mask)
                new_pivot = pivot if pivot != -1 else (pos if ch > s[pos] else -1)
                pivot_stack.append(new_pivot)
                idx_lists[pos] = iref + 1
                pos += 1
                progressed = True
                break
            iref += 1
        if not progressed:
            # backtrack
            if pos == 0:
                return "-1"
            # clear deeper states
            if len(cand_lists) > pos:
                cand_lists[pos] = []
                idx_lists[pos] = 0
            pos -= 1
            # undo one level
            cur_mask_stack.pop()
            pivot_stack.pop()
            # resume at this position with next candidate
            # ans[pos] will be overwritten on next success
    # unreachable

def solve_all():
    data = read_input()
    if not data:
        return
    it = iter(data)
    vowel_mask = next(it).strip()
    n, m = map(int, next(it).split())
    rules = []
    for _ in range(m):
        parts = next(it).split()
        p1, t1, p2, t2 = int(parts[0]), parts[1], int(parts[2]), parts[3]
        rules.append((p1, t1, p2, t2))
    s = next(it).strip()
    ans = solve_case(vowel_mask, n, m, rules, s)
    sys.stdout.write(ans + "\n")

if __name__ == "__main__":
    # Exactly 3 asserts
    def run_io(s):
        from io import StringIO
        bak_stdin, bak_stdout = sys.stdin, sys.stdout
        try:
            sys.stdin, sys.stdout = StringIO(s), StringIO()
            solve_all()
            return sys.stdout.getvalue().strip()
        finally:
            sys.stdin, sys.stdout = bak_stdin, bak_stdout
    # 1) Classic tiny: if position 1 is vowel => position 2 consonant; s = "aa" => answer "ab"
    inp1 = """VC
2 1
1 V 2 C
aa
"""
    assert run_io(inp1) == "ab"
    # 2) No rules: answer is at least s
    inp2 = """VCV
4 0
abac
"""
    assert run_io(inp2) == "abac"
    # 3) Force contradictions making "-1" (small crafted):
    # Rules: 1 V -> 2 V and 2 V -> 1 C; also 1 C -> 2 C and 2 C -> 1 V.
    # This forces x1 != x2 and x1 == x2 simultaneously -> impossible.
    inp3 = """VC
2 4
1 V 2 V
2 V 1 C
1 C 2 C
2 C 1 V
aa
"""
    assert run_io(inp3) == "-1"
\end{minted}
\VALIDATION{Three asserts: a rule that forbids ``aa'', a trivial case with no rules, and a small contradictory system with no solution.}
\RESULT{The printed string is the minimal valid word $\ge s$, or \texttt{-1} if no valid word exists.}
\NotePages{3}

% ============ 7. Testing & Final Reference Implementation (own page) ============
\section{Testing \& Final Reference Implementation}
\LINE{TEST PLAN}{Unit tests on tiny instances; random small graphs to cross-check against a slow brute force; edge cases like all vowels or all consonants; contradictions.}
\LINE{CROSS-CHECKS}{Compare the optimal solver against the brute-force baseline for $n \le 6$ and small alphabets; ensure agreement on feasibility and lexicographic minimality.}
\LINE{EDGE-CASE GENERATOR}{Generate random rules and verify the solver never outputs a string violating any implication; also verify lex bound $\ge s$.}
\begin{minted}{python}
# Deterministic generators for boundaries, degenerates, adversarials
import random

def gen_random_case(seed=0, l=3, n=5, m=6):
    random.seed(seed)
    vowel_mask = ''.join(random.choice('VC') for _ in range(l))
    rules = set()
    def pick_type():
        return random.choice(['V','C'])
    while len(rules) < m:
        p1 = random.randint(1, n)
        p2 = random.randint(1, n)
        if p1 == p2: 
            continue
        t1, t2 = pick_type(), pick_type()
        rules.add((p1, t1, p2, t2))
    rules = list(rules)
    letters = [chr(ord('a') + i) for i in range(l)]
    s = ''.join(random.choice(letters) for _ in range(n))
    return vowel_mask, n, len(rules), rules, s

# Cross-check improved vs final on tiny randoms by integrating their solvers if needed.
\end{minted}
\textbf{Reference Code (Ready to Submit)}
\begin{minted}{python}
import sys
from collections import deque

def read_input():
    return sys.stdin.read().strip().splitlines()

def kosaraju_scc(N, adj):
    sys.setrecursionlimit(1_000_000)
    radj = [[] for _ in range(N)]
    for u in range(N):
        for v in adj[u]:
            radj[v].append(u)
    vis = [False]*N
    order = []
    def dfs1(u):
        vis[u] = True
        for v in adj[u]:
            if not vis[v]:
                dfs1(v)
        order.append(u)
    for u in range(N):
        if not vis[u]:
            dfs1(u)
    comp = [-1]*N
    def dfs2(u, cid):
        comp[u] = cid
        for v in radj[u]:
            if comp[v] == -1:
                dfs2(v, cid)
    cid = 0
    for u in reversed(order):
        if comp[u] == -1:
            dfs2(u, cid)
            cid += 1
    return comp, cid

def solve_case(vowel_mask, n, m, rules, s):
    l = len(vowel_mask)
    is_vowel_letter = [c == 'V' for c in vowel_mask]
    N = 2 * n
    def lit_id(pos, isV):
        return 2*pos + (1 if isV else 0)
    # Build base implication graph
    adj = [[] for _ in range(N)]
    def add_imp(p1, t1, p2, t2):
        u = lit_id(p1, t1 == 'V')
        v = lit_id(p2, t2 == 'V')
        adj[u].append(v)
        adj[v ^ 1].append(u ^ 1)
    for (p1, t1, p2, t2) in rules:
        add_imp(p1-1, t1, p2-1, t2)
    # SCC and condensation
    comp, C = kosaraju_scc(N, adj)
    for i in range(n):
        if comp[2*i] == comp[2*i+1]:
            return "-1"
    dag = [set() for _ in range(C)]
    comp_nodes_mask = [0]*C
    for u in range(N):
        cu = comp[u]
        comp_nodes_mask[cu] |= (1 << u)
        for v in adj[u]:
            cv = comp[v]
            if cu != cv:
                dag[cu].add(cv)
    indeg = [0]*C
    for u in range(C):
        for v in dag[u]:
            indeg[v] += 1
    dq = deque([u for u in range(C) if indeg[u] == 0])
    topo = []
    while dq:
        u = dq.popleft()
        topo.append(u)
        for v in dag[u]:
            indeg[v] -= 1
            if indeg[v] == 0:
                dq.append(v)
    reach_nodes_mask = [0]*C
    for u in reversed(topo):
        mask = comp_nodes_mask[u]
        for v in dag[u]:
            mask |= reach_nodes_mask[v]
        reach_nodes_mask[u] = mask
    lit_closure = [0]*N
    for u in range(N):
        lit_closure[u] = reach_nodes_mask[comp[u]]
    letters = [chr(ord('a') + i) for i in range(l)]
    ans = ['?']*n
    cur_mask_stack = [0]
    pivot_stack = [-1]
    pos = 0
    cand_lists = []
    idx_lists = []
    while True:
        if pos == n:
            return "".join(ans)
        cur_mask = cur_mask_stack[-1]
        pivot = pivot_stack[-1]
        if pos == len(cand_lists):
            lb = s[pos] if pivot == -1 else 'a'
            cand = [ch for ch in letters if ch >= lb]
            cand_lists.append(cand)
            idx_lists.append(0)
        cand = cand_lists[pos]
        iref = idx_lists[pos]
        progressed = False
        while iref < len(cand):
            ch = cand[iref]
            t_isV = is_vowel_letter[ord(ch) - 97]
            lit = 2*pos + (1 if t_isV else 0)
            new_mask = cur_mask | lit_closure[lit]
            conflict = False
            mm = new_mask
            for i in range(n):
                if ((mm >> (2*i)) & 3) == 3:
                    conflict = True
                    break
            if not conflict:
                ans[pos] = ch
                cur_mask_stack.append(new_mask)
                new_pivot = pivot if pivot != -1 else (pos if ch > s[pos] else -1)
                pivot_stack.append(new_pivot)
                idx_lists[pos] = iref + 1
                pos += 1
                progressed = True
                break
            iref += 1
        if not progressed:
            if pos == 0:
                return "-1"
            pos -= 1
            cur_mask_stack.pop()
            pivot_stack.pop()
            # Continue at this pos with next candidate on next iteration

def solve_all():
    data = read_input()
    if not data:
        return
    it = iter(data)
    vowel_mask = next(it).strip()
    n, m = map(int, next(it).split())
    rules = []
    for _ in range(m):
        parts = next(it).split()
        p1, t1, p2, t2 = int(parts[0]), parts[1], int(parts[2]), parts[3]
        rules.append((p1, t1, p2, t2))
    s = next(it).strip()
    print(solve_case(vowel_mask, n, m, rules, s))

if __name__ == "__main__":
    # Reference asserts
    def run_io(s):
        from io import StringIO
        bak_stdin, bak_stdout = sys.stdin, sys.stdout
        try:
            sys.stdin, sys.stdout = StringIO(s), StringIO()
            solve_all()
            return sys.stdout.getvalue().strip()
        finally:
            sys.stdin, sys.stdout = bak_stdin, bak_stdout
    a = run_io("""VC
2 1
1 V 2 C
aa
""")
    assert a == "ab"
    b = run_io("""VCV
4 0
abac
""")
    assert b == "abac"
    c = run_io("""VC
2 4
1 V 2 V
2 V 1 C
1 C 2 C
2 C 1 V
aa
""")
    assert c == "-1"
    print("OK")
\end{minted}
\NotePages{3}

% ============ 8. Review & Pitfalls (own page) ============
\section{Review \& Pitfalls}
\WHAT{Find the lexicographically minimal word $\ge s$ that satisfies implication rules between vowel/consonant types per position.}
\WHY{Combines 2-SAT reasoning with lexicographic construction/backtracking — a common interview pattern blending logic constraints with greedy search.}
\CHECKLIST{
\begin{bullets}
\item Build implication graph correctly: both rule and its contrapositive.
\item SCC once; check base contradictions.
\item Precompute closure masks per literal via DAG DP.
\item Maintain current forced mask; test new letters by OR and conflict scan.
\item Respect lex bound with pivot handling.
\end{bullets}
}
\EDGECASES{
\begin{bullets}
\item All letters are vowels or all are consonants.
\item No rules at all (answer is $s$).
\item $s$ already invalid but a valid word $\ge s$ exists.
\item No valid word exists (contradictory rules).
\item $l{=}1$ (single-letter alphabet).
\item Early pivot vs. long equal prefix.
\end{bullets}
}
\PITFALLS{
\begin{bullets}
\item Forgetting the contrapositive edge $\lnot b \Rightarrow \lnot a$.
\item Mixing up literal indexing; ensure opposite literal is $id \oplus 1$.
\item Missing self-inclusion in closure masks.
\item Recomputing SCC per try (too slow) instead of using precomputed closures.
\item Not enforcing lex lower bound while exploring candidates.
\item Mishandling pivot when backtracking.
\end{bullets}
}
\FAILMODES{Naive brute force explodes; rebuilding SCC per step may TLE; ignoring lex constraints yields strings $< s$. The closure-based check prunes infeasible prefixes in $O(n)$ per try and guarantees extendability.}
\ELI{Treat each position as needing a vowel or consonant. The rules are ``if position $i$ is vowel, then position $j$ must be consonant'', etc. Precompute all knock-on effects. Then, try to place the smallest possible letter at each position while ensuring the rest can still be filled; backtrack only when necessary.}
\NotePages{3}

\end{document}